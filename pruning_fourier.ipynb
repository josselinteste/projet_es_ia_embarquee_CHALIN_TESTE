{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz7un4mk6EPO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Data augmentation\n",
        "# -----------------------------\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "    transforms.RandomErasing(p=0.2)\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Exemple avec CIFAR-10\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=train_transforms, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=test_transforms, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Modèle\n",
        "# -----------------------------\n",
        "def get_model_improved(device='cpu'):\n",
        "    model = nn.Sequential(\n",
        "    # Bloc 1\n",
        "    nn.Conv2d(3, 32, kernel_size=4, padding=1, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "\n",
        "    nn.Conv2d(32, 32, kernel_size=4, padding=1, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Dropout2d(0.2),\n",
        "\n",
        "    # Bloc 2\n",
        "    nn.Conv2d(32, 64, kernel_size=4, padding=1, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "\n",
        "    nn.Conv2d(64, 64, kernel_size=4, padding=1, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "    nn.Dropout2d(0.3),\n",
        "\n",
        "    # Bloc 3\n",
        "    nn.Conv2d(64, 128, kernel_size=4, padding=1, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(128),\n",
        "\n",
        "    nn.Conv2d(128, 128, kernel_size=1, padding=0, bias=True),  # bottleneck\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.AdaptiveAvgPool2d((1,1)),\n",
        "\n",
        "    nn.Flatten(),\n",
        "\n",
        "    # Classifier compact\n",
        "    nn.Linear(128, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(128, 10)\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "    return model, loss_fn, optimizer, scheduler\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Entraînement + Early stopping + Tracking\n",
        "# -----------------------------\n",
        "def train_model(model, loss_fn, optimizer, scheduler, train_loader, val_loader, device='cpu', epochs=30, patience=5):\n",
        "    best_val_loss = np.inf\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Historique pour les courbes\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = loss_fn(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * X.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        train_loss = running_loss / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                outputs = model(X)\n",
        "                loss = loss_fn(outputs, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += y.size(0)\n",
        "                correct += (predicted == y).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        val_loss /= total\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Enregistrement\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
        "              f\"Train loss: {train_loss:.4f} | Train acc: {train_acc:.2f}% | \"\n",
        "              f\"Val loss: {val_loss:.4f} | Val acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss > best_val_loss - 1e-3:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "        else:\n",
        "            patience_counter = 0\n",
        "            best_val_loss = val_loss\n",
        "\n",
        "    # -----------------------------\n",
        "    # 4. Affichage des courbes\n",
        "    # -----------------------------\n",
        "    epochs_range = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
        "    plt.plot(epochs_range, history['val_loss'], label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss évolution')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(epochs_range, history['val_acc'], label='Val Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy ')\n",
        "    plt.title('Accuracy évolution')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Lancement\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model, loss_fn, optimizer, scheduler = get_model_improved(device)\n",
        "train_model(model, loss_fn, optimizer, scheduler, train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")\n",
        "files.download(\"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvxloP_xpeU"
      },
      "source": [
        "**INTERPOLATION DU FILTRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGYfASukxtuA"
      },
      "outputs": [],
      "source": [
        "from scipy.interpolate import RegularGridInterpolator\n",
        "\n",
        "def interpolate_filter(filter_weights, smooth_factor=50):\n",
        "    \"\"\"Interpolation cubique bilinéaire pour passer du filtre discret à une fonction continue\"\"\"\n",
        "    h, w = filter_weights.shape\n",
        "    y = np.arange(h)\n",
        "    x = np.arange(w)\n",
        "    interp_func = RegularGridInterpolator((y, x), filter_weights, method='cubic')\n",
        "    ynew = np.linspace(0, h-1, smooth_factor)\n",
        "    xnew = np.linspace(0, w-1, smooth_factor)\n",
        "    X, Y = np.meshgrid(xnew, ynew)\n",
        "    points = np.array([Y.ravel(), X.ravel()]).T\n",
        "    Zsmooth = interp_func(points).reshape(smooth_factor, smooth_factor)\n",
        "    return Zsmooth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI3eqSuFxubf"
      },
      "source": [
        "**Projection dans schwartz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA0CEZ2Vx3AF"
      },
      "outputs": [],
      "source": [
        "def project_to_schwartz(Zsmooth, sigma=None):\n",
        "    \"\"\"Projette un filtre interpolé dans un espace proche de S(R^2) via une fenêtre gaussienne\"\"\"\n",
        "    H, W = Zsmooth.shape\n",
        "    if sigma is None:\n",
        "        sigma = min(H, W) / 2\n",
        "    y = np.arange(H) - H/2\n",
        "    x = np.arange(W) - W/2\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    gauss_window = np.exp(-(X**2 + Y**2) / (2*sigma**2))\n",
        "    Z_schwartz = Zsmooth * gauss_window\n",
        "    return Z_schwartz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8bfJzHt1uFQ"
      },
      "source": [
        "**Mesure de régularité**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFS613_Wx7NN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def gaussian_window(shape, sigma=1.0, center=None):\n",
        "    \"\"\"Fenêtre gaussienne normalisée 2D\"\"\"\n",
        "    n, m = shape\n",
        "    if center is None:\n",
        "        center = (n//2, m//2)\n",
        "    y = np.arange(n) - center[0]\n",
        "    x = np.arange(m) - center[1]\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    g = np.exp(-(X**2 + Y**2)/(2*sigma**2))\n",
        "    g /= np.sqrt(np.sum(g**2))\n",
        "    return g\n",
        "\n",
        "def local_sobolev_gauss_3D(h, block_size=(5,5), alpha=2, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Calcule la régularité locale de sous-blocs d'un filtre 2D\n",
        "    avec fenêtre gaussienne et pondération Sobolev.\n",
        "\n",
        "    Retour :\n",
        "    - reg_map : matrice de régularité locale\n",
        "    \"\"\"\n",
        "    n, m = h.shape\n",
        "    bh, bw = block_size\n",
        "    reg_map = np.zeros((n - bh + 1, m - bw + 1))\n",
        "\n",
        "    for i in range(n - bh + 1):\n",
        "        for j in range(m - bw + 1):\n",
        "            block = h[i:i+bh, j:j+bw]\n",
        "            g = gaussian_window(block.shape, sigma=sigma)\n",
        "            block_win = block * g\n",
        "\n",
        "            H = np.fft.fft2(block_win)\n",
        "            H = np.fft.fftshift(H)\n",
        "\n",
        "            u = np.fft.fftshift(np.fft.fftfreq(bh))\n",
        "            v = np.fft.fftshift(np.fft.fftfreq(bw))\n",
        "            U, V = np.meshgrid(u, v, indexing='ij')\n",
        "\n",
        "            freq_weight = (1 + U**2 + V**2)**alpha\n",
        "            reg_map[i,j] = np.sum(freq_weight * np.abs(H)**2)\n",
        "\n",
        "    return reg_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_7Fds61Q10"
      },
      "source": [
        "**Récupération des poids réguliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90sq5XIUxeBg"
      },
      "outputs": [],
      "source": [
        "def graphcut_filter_surface(Zsmooth, percentile):\n",
        "    \"\"\"\n",
        "    Conserve uniquement les valeurs les plus petites (en valeur absolue)\n",
        "    selon un seuil basé sur le percentile.\n",
        "    #\n",
        "    Zsmooth : surface lissée (2D numpy array)\n",
        "    percentile : pourcentage de valeurs à conserver (les plus petites)\n",
        "    \"\"\"\n",
        "    threshold = np.percentile(np.abs(Zsmooth), percentile)\n",
        "    mask = np.abs(Zsmooth) <= threshold  # True là où on garde\n",
        "    Zcut = np.where(mask, Zsmooth, np.nan)  # NaN pour visualiser les trous\n",
        "    return Zcut, mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjFLTC0414E0"
      },
      "source": [
        "Mesure de valeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ky5RZdD13Sm"
      },
      "outputs": [],
      "source": [
        "def magnitude_mesure(Zcut):\n",
        "    \"\"\"\n",
        "    Calcule la somme des valeurs absolues de Zcut.\n",
        "    Les NaN sont traités comme des zéros.\n",
        "    \"\"\"\n",
        "    return np.nansum(np.abs(Zcut))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPbX5jqYDHnS"
      },
      "outputs": [],
      "source": [
        "from scipy import ndimage\n",
        "def ultimate_graphcut_filter_analysis_reg(filter_weights):\n",
        "  \"\"\"\n",
        "  Calcule la régularité totale d'un filtre\n",
        "  #\n",
        "  filter_weights : poids d'un filtre donné\n",
        "  \"\"\"\n",
        "  Zsmooth = interpolate_filter(filter_weights)\n",
        "  Z_schwartz = project_to_schwartz(Zsmooth)\n",
        "  reg_map = local_sobolev_gauss_3D(Zsmooth, block_size=(5,5), alpha=2, sigma=58)\n",
        "  Zcut, mask = graphcut_filter_surface(reg_map, percentile=80) #Pourcentage à modifier \n",
        "  return magnitude_mesure(Zcut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp20qDf12KYW"
      },
      "source": [
        "**Classement des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgwbKDtt6rmd",
        "outputId": "a11c6456-b498-4095-941a-70b4ea92f71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Couche 1/6...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "   Couche 2/6...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "   Couche 3/6...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n"
          ]
        }
      ],
      "source": [
        "from scipy.interpolate import RegularGridInterpolator\n",
        "import torch\n",
        "\n",
        "conv_layers = [module for module in model.modules() if isinstance(module, nn.Conv2d)]\n",
        "\n",
        "filter_ranking = {}\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "\n",
        "for m_idx, conv_layer in enumerate(conv_layers):\n",
        "    print(f\"   Couche {m_idx+1}/{len(conv_layers)}...\")\n",
        "\n",
        "    # Vérification si la couche est un bottleneck\n",
        "    # Si la couche est un bottleneck, on la saute\n",
        "    # Le bottleneck est une convolution 1x1 après une couche de plus grande taille, on suppose que c'est un critère ici\n",
        "    if conv_layer.kernel_size == (1, 1):\n",
        "        print(f\"   Couche {m_idx+1} est un bottleneck, on passe.\")\n",
        "        continue\n",
        "\n",
        "    filter_ranking[m_idx] = {}\n",
        "\n",
        "    out_channels, in_channels, h, w = conv_layer.weight.shape\n",
        "\n",
        "    for oc in range(out_channels):\n",
        "        print(oc)\n",
        "        filter_ranking[m_idx][oc] = {}\n",
        "        for ic in range(in_channels):\n",
        "            print(ic)\n",
        "\n",
        "            # 1. Récupère les poids du filtre\n",
        "            filter_weights = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
        "\n",
        "            #2. Calcule la régularité du filtre\n",
        "            base_importance = ultimate_graphcut_filter_analysis_reg(filter_weights)\n",
        "\n",
        "            # 3. Peuple le dictionnaire à l'indice de la couche et du filtre correspondant, la valeur étant la mesure de régularité\n",
        "            filter_ranking[m_idx][oc][ic] = float(base_importance)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"filter_ranking.json\", \"w\") as f: \n",
        "    json.dump(filter_ranking, f, indent=4)\n",
        "from google.colab import files\n",
        "files.download(\"filter_ranking.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYv_f--Fr1hi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_filter_ranking_combined(filter_ranking):\n",
        "    \"\"\"\n",
        "    Affiche tous les filtres de toutes les couches dans un seul graphe,\n",
        "    avec une ligne rouge séparant les couches.\n",
        "\n",
        "    Args:\n",
        "        filter_ranking : dict[layer_idx][out_ch][in_ch] = score\n",
        "    \"\"\"\n",
        "    all_scores = []\n",
        "    layer_boundaries = []\n",
        "    current_idx = 0\n",
        "\n",
        "    # Parcourir les couches\n",
        "    for l_idx in sorted(filter_ranking.keys()):\n",
        "        layer_dict = filter_ranking[l_idx]\n",
        "        # Moyenne sur les canaux d'entrée pour chaque filtre de sortie\n",
        "        out_scores = [np.mean(list(layer_dict[oc].values())) for oc in sorted(layer_dict.keys())]\n",
        "        all_scores.extend(out_scores)\n",
        "        current_idx += len(out_scores)\n",
        "        layer_boundaries.append(current_idx)  # position pour la ligne rouge\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.bar(range(len(all_scores)), all_scores)\n",
        "    plt.xlabel(\"Filtres (toutes couches concaténées)\")\n",
        "    plt.ylabel(\"Score d'importance moyen\")\n",
        "    plt.title(\"Importance des filtres par couche\")\n",
        "\n",
        "    # Tracer les lignes rouges pour séparer les couches\n",
        "    for b in layer_boundaries[:-1]:  # pas besoin de la dernière\n",
        "        plt.axvline(x=b-0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "uRTxF81tr4bU",
        "outputId": "e43ab912-d12d-4650-8b47-af8de039b6fb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_filter_ranking_combined(filter_ranking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Récupération des données enregistrés**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Récupération des poids du modèle\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # récupérer le fichier de poids .pth\n",
        "model.load_state_dict(torch.load('model_weights.pth', map_location='cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AGS60Uf9RwYI",
        "outputId": "95e54c59-1017-4aed-ad18-1cc16600c0c4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f9b143a5-5eb5-415b-8bca-d8ec932faa2c\", \"regularite_80.json\", 70579)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Récupération du dictionnaire\n",
        "import json\n",
        "uploaded = files.upload()  # récupérer le fichier de poids .pth\n",
        "with open(\"dictionnaire.json\", \"w\") as f:\n",
        "    json.dump(filter_ranking, f, indent=4)\n",
        "from google.colab import files\n",
        "files.download(\"dictionnaire.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg-VzejFbTq"
      },
      "source": [
        "**Pruning du modèle*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8xk3vXFuog"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def prune_model_by_filters_removal(model, top_indices_list, input_size=(3, 32, 32)):\n",
        "    \"\"\"\n",
        "    VERSION CORRIGÉE: Supprime réellement les filtres pour réduire les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle PyTorch nn.Sequential\n",
        "        top_indices_list: [(layer_idx, out_ch, in_ch), ...] - filtres à CONSERVER\n",
        "        input_size: taille d'entrée (channels, height, width)\n",
        "\n",
        "    Returns:\n",
        "        Modèle pruné avec moins de paramètres\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model_copy = copy.deepcopy(model)\n",
        "\n",
        "    # Organiser les filtres à conserver par couche\n",
        "    filters_to_keep = defaultdict(set)\n",
        "    for layer_idx, out_ch, in_ch in top_indices_list:\n",
        "        filters_to_keep[layer_idx].add(out_ch)\n",
        "\n",
        "    # Convertir en listes triées\n",
        "    for layer_idx in filters_to_keep:\n",
        "        filters_to_keep[layer_idx] = sorted(list(filters_to_keep[layer_idx]))\n",
        "\n",
        "    new_layers = []\n",
        "    conv_layers = [i for i, layer in enumerate(model_copy) if isinstance(layer, nn.Conv2d)]\n",
        "    prev_kept_channels = None\n",
        "\n",
        "    for i, layer in enumerate(model_copy):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Trouver l'index de cette couche conv\n",
        "            conv_idx = conv_layers.index(i)\n",
        "\n",
        "            # Déterminer les canaux de sortie à conserver\n",
        "            if conv_idx in filters_to_keep:\n",
        "                keep_out_channels = filters_to_keep[conv_idx]\n",
        "            else:\n",
        "                # Si pas spécifié, garder tous les canaux\n",
        "                keep_out_channels = list(range(layer.out_channels))\n",
        "\n",
        "            # Déterminer les canaux d'entrée\n",
        "            if conv_idx == 0:\n",
        "                # Première couche: garder tous les canaux d'entrée (RGB)\n",
        "                new_in_channels = layer.in_channels\n",
        "                keep_in_channels = list(range(layer.in_channels))\n",
        "            else:\n",
        "                # Couches suivantes: s'adapter aux canaux conservés de la couche précédente\n",
        "                new_in_channels = len(prev_kept_channels) if prev_kept_channels else layer.in_channels\n",
        "                keep_in_channels = prev_kept_channels if prev_kept_channels else list(range(layer.in_channels))\n",
        "\n",
        "            new_out_channels = len(keep_out_channels)\n",
        "\n",
        "            # Créer la nouvelle couche Conv2d RÉDUITE\n",
        "            new_conv = nn.Conv2d(\n",
        "                in_channels=new_in_channels,\n",
        "                out_channels=new_out_channels,\n",
        "                kernel_size=layer.kernel_size,\n",
        "                stride=layer.stride,\n",
        "                padding=layer.padding,\n",
        "                bias=(layer.bias is not None)\n",
        "            ).to(device)\n",
        "\n",
        "            # Copier uniquement les poids des filtres conservés\n",
        "            with torch.no_grad():\n",
        "                for new_out_idx, old_out_idx in enumerate(keep_out_channels):\n",
        "                    for new_in_idx, old_in_idx in enumerate(keep_in_channels):\n",
        "                        new_conv.weight[new_out_idx, new_in_idx] = layer.weight[old_out_idx, old_in_idx]\n",
        "\n",
        "                    if layer.bias is not None:\n",
        "                        new_conv.bias[new_out_idx] = layer.bias[old_out_idx]\n",
        "\n",
        "            new_layers.append(new_conv)\n",
        "            prev_kept_channels = keep_out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            # Adapter BatchNorm aux canaux conservés\n",
        "            if prev_kept_channels is not None:\n",
        "                new_bn = nn.BatchNorm2d(len(prev_kept_channels)).to(device)\n",
        "                with torch.no_grad():\n",
        "                    for new_idx, old_idx in enumerate(prev_kept_channels):\n",
        "                        new_bn.weight[new_idx] = layer.weight[old_idx]\n",
        "                        new_bn.bias[new_idx] = layer.bias[old_idx]\n",
        "                        new_bn.running_mean[new_idx] = layer.running_mean[old_idx]\n",
        "                        new_bn.running_var[new_idx] = layer.running_var[old_idx]\n",
        "                new_layers.append(new_bn)\n",
        "            else:\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            # Ajuster la première couche Linear après Flatten\n",
        "            if len([l for l in new_layers if isinstance(l, nn.Linear)]) == 0:\n",
        "                # Calculer la nouvelle taille après les couches conv\n",
        "                new_input_features = calculate_linear_input_size(new_layers, input_size)\n",
        "\n",
        "                new_linear = nn.Linear(\n",
        "                    in_features=new_input_features,\n",
        "                    out_features=layer.out_features,\n",
        "                    bias=(layer.bias is not None)\n",
        "                ).to(device)\n",
        "\n",
        "                # Copier les poids (avec adaptation de taille)\n",
        "                with torch.no_grad():\n",
        "                    min_features = min(new_input_features, layer.in_features)\n",
        "                    new_linear.weight[:, :min_features] = layer.weight[:, :min_features]\n",
        "                    if layer.bias is not None:\n",
        "                        new_linear.bias[:] = layer.bias[:]\n",
        "\n",
        "                new_layers.append(new_linear)\n",
        "            else:\n",
        "                # Autres couches Linear: copier tel quel\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "        else:\n",
        "            # Autres couches (ReLU, MaxPool, Dropout, Flatten)\n",
        "            new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "    return nn.Sequential(*new_layers).to(device)\n",
        "\n",
        "def calculate_linear_input_size(conv_layers, input_size):\n",
        "    \"\"\"\n",
        "    Calcule la taille d'entrée pour la première couche Linear\n",
        "    en simulant une passe avant à travers les couches conv.\n",
        "    \"\"\"\n",
        "    channels, h, w = input_size\n",
        "\n",
        "    for layer in conv_layers:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Calculer nouvelle taille après convolution\n",
        "            kernel_size = layer.kernel_size[0] if isinstance(layer.kernel_size, tuple) else layer.kernel_size\n",
        "            stride = layer.stride[0] if isinstance(layer.stride, tuple) else layer.stride\n",
        "            padding = layer.padding[0] if isinstance(layer.padding, tuple) else layer.padding\n",
        "\n",
        "            h = (h + 2*padding - kernel_size) // stride + 1\n",
        "            w = (w + 2*padding - kernel_size) // stride + 1\n",
        "            channels = layer.out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.MaxPool2d):\n",
        "            kernel_size = layer.kernel_size\n",
        "            stride = layer.stride if layer.stride else kernel_size\n",
        "            h = h // stride\n",
        "            w = w // stride\n",
        "\n",
        "    return channels * h * w\n",
        "\n",
        "def structured_channel_pruning(model, importance_dict, keep_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Pruning structuré: supprime des canaux entiers basé sur leur importance moyenne.\n",
        "    Plus efficace pour réduire réellement les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle à pruner\n",
        "        importance_dict: dict[layer][out_ch][in_ch] = importance\n",
        "        keep_ratio: fraction de canaux à conserver (0.5 = 50%)\n",
        "    \"\"\"\n",
        "    # Calculer l'importance moyenne par canal de sortie\n",
        "    channel_importance = {}\n",
        "\n",
        "    for layer_idx in importance_dict:\n",
        "        channel_importance[layer_idx] = {}\n",
        "        for out_ch in importance_dict[layer_idx]:\n",
        "            # Moyenne d'importance sur tous les canaux d'entrée pour ce canal de sortie\n",
        "            avg_importance = np.mean(list(importance_dict[layer_idx][out_ch].values()))\n",
        "            channel_importance[layer_idx][out_ch] = avg_importance\n",
        "\n",
        "    # Sélectionner les top canaux pour chaque couche\n",
        "    top_indices = []\n",
        "    for layer_idx in channel_importance:\n",
        "        # Trier par importance décroissante\n",
        "        channels_by_importance = sorted(\n",
        "            channel_importance[layer_idx].items(),\n",
        "            key=lambda x: x[1],\n",
        "            reverse=False\n",
        "        )\n",
        "\n",
        "        # Garder le top keep_ratio\n",
        "        n_keep = max(1, int(len(channels_by_importance) * keep_ratio))\n",
        "        top_channels = [ch for ch, _ in channels_by_importance[:n_keep]]\n",
        "\n",
        "        # Créer les indices pour tous les canaux d'entrée de ces canaux de sortie\n",
        "        for out_ch in top_channels:\n",
        "            for in_ch in importance_dict[layer_idx][out_ch]:\n",
        "                top_indices.append((layer_idx, out_ch, in_ch))\n",
        "\n",
        "    return top_indices\n",
        "\n",
        "def test_effective_pruning(model, importance_dict, trn_dl, val_dl, loss_fn, keep_ratios=[0.8]):\n",
        "    \"\"\"\n",
        "    Test de pruning avec réduction EFFECTIVE des paramètres.\n",
        "    \"\"\"\n",
        "    print(\"Test de Pruning avec Réduction Effective des Paramètres\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Baseline\n",
        "    orig_params = sum(p.numel() for p in model.parameters())\n",
        "    orig_loss, orig_acc = evaluate_model(model, val_dl, loss_fn)\n",
        "\n",
        "    print(f\"Modèle original: {orig_acc:.4f} accuracy, {orig_params:,} paramètres\")\n",
        "    print()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for keep_ratio in keep_ratios:\n",
        "        print(f\"Test avec keep_ratio = {keep_ratio} ({keep_ratio*100:.0f}% des canaux)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            # Pruning structuré par canaux\n",
        "            top_indices = structured_channel_pruning(model, importance_dict, keep_ratio)\n",
        "            print(f\"Filtres sélectionnés: {len(top_indices)}\")\n",
        "\n",
        "            # Appliquer le pruning EFFECTIF\n",
        "            pruned_model = prune_model_by_filters_removal(model, top_indices, input_size=(3, 32, 32))\n",
        "\n",
        "            # Vérifier la réduction\n",
        "            pruned_params = sum(p.numel() for p in pruned_model.parameters())\n",
        "            actual_reduction = (orig_params - pruned_params) / orig_params * 100\n",
        "\n",
        "            print(f\"Paramètres avant: {orig_params:,}\")\n",
        "            print(f\"Paramètres après: {pruned_params:,}\")\n",
        "            print(f\"Réduction RÉELLE: {actual_reduction:.1f}%\")\n",
        "\n",
        "            # Test du modèle pruné\n",
        "            val_loss_before, val_acc_before = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "            print(f\"Accuracy avant fine-tuning: {val_acc_before:.4f}\")\n",
        "\n",
        "            # Fine-tuning\n",
        "            print(\"Fine-tuning...\")\n",
        "            pruned_model = fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=5, lr=1e-3)\n",
        "\n",
        "            val_loss_final, val_acc_final = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "\n",
        "            accuracy_retention = (val_acc_final / orig_acc) * 100\n",
        "            compression_ratio = orig_params / pruned_params\n",
        "\n",
        "            print(f\"Accuracy finale: {val_acc_final:.4f}\")\n",
        "            print(f\"Rétention accuracy: {accuracy_retention:.1f}%\")\n",
        "            print(f\"Ratio de compression: {compression_ratio:.1f}x\")\n",
        "            print()\n",
        "\n",
        "            results.append({\n",
        "                'keep_ratio': keep_ratio,\n",
        "                'actual_reduction': actual_reduction,\n",
        "                'final_accuracy': val_acc_final,\n",
        "                'accuracy_retention': accuracy_retention,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'pruned_params': pruned_params\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur avec keep_ratio {keep_ratio}: {e}\")\n",
        "            print()\n",
        "\n",
        "    # Résumé des résultats\n",
        "    print(\"RÉSUMÉ DES RÉSULTATS\")\n",
        "    print(\"=\"*40)\n",
        "    for r in results:\n",
        "        print(f\"Keep {r['keep_ratio']*100:.0f}%: {r['actual_reduction']:.1f}% réduction, \"\n",
        "              f\"{r['accuracy_retention']:.1f}% accuracy, {r['compression_ratio']:.1f}x compression\")\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "# Fonction d'évaluation (si pas déjà définie)\n",
        "def evaluate_model(model, val_dl, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            device = next(model.parameters()).device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += x.size(0)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "def fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=10, lr=1e-4):\n",
        "    \"\"\"Fine-tune le modèle pruné pour récupérer l'accuracy.\"\"\"\n",
        "    from torch.optim import Adam\n",
        "\n",
        "    device = next(pruned_model.parameters()).device\n",
        "    optimizer = Adam(pruned_model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pruned_model.train()\n",
        "        for x, y in trn_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = pruned_model(x)\n",
        "            loss = loss_fn(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation check\n",
        "        val_loss, val_acc = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "        if epoch == 0 or (epoch + 1) % 2 == 0:\n",
        "            print(f\"  Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    return pruned_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyvjgo6gajdQ",
        "outputId": "798fec4d-c6ef-47af-a292-f6bb73c17803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de Pruning avec Réduction Effective des Paramètres\n",
            "============================================================\n",
            "Modèle original: 0.8405 accuracy, 282,826 paramètres\n",
            "\n",
            "Test avec keep_ratio = 0.8 (80% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 12299\n",
            "Paramètres avant: 282,826\n",
            "Paramètres après: 676,042\n",
            "Réduction RÉELLE: -139.0%\n",
            "Erreur avec keep_ratio 0.8: mat1 and mat2 shapes cannot be multiplied (128x128 and 3200x128)\n",
            "\n",
            "RÉSUMÉ DES RÉSULTATS\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "model_test = copy.deepcopy(model)\n",
        "pruned_model = test_effective_pruning(model_test,filter_ranking,train_loader, val_loader, loss_fn) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
