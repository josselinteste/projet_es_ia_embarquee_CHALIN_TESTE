{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP697LuRwBgo",
        "outputId": "032406b7-c25a-46b3-f1e9-8d3813418556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "import torch\n",
        "data_folder = '/content/' # This can be any directory you want to download FMNIST to\n",
        "fmnist = datasets.CIFAR10(data_folder, download=True, train=True)\n",
        "\n",
        "tr_images = fmnist.data\n",
        "tr_targets = fmnist.targets\n",
        "\n",
        "val_fmnist = datasets.CIFAR10(data_folder, download=True, train=False)\n",
        "val_images = val_fmnist.data\n",
        "val_targets = val_fmnist.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cuyLuLPwCeA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, images, targets, device='cpu'):\n",
        "        # Convertir les tableaux NumPy en tenseurs PyTorch\n",
        "        images = torch.from_numpy(images).float() / 255.0\n",
        "        targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "        # CIFAR10 : images en 3x32x32, format (N, H, W, C) -> (N, C, H, W)\n",
        "        images = images.permute(0, 3, 1, 2)\n",
        "\n",
        "        self.x = images\n",
        "        self.y = targets\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        x = self.x[ix].to(self.device)\n",
        "        y = self.y[ix].to(self.device)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHGn69pmwFCk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_model(device='cpu'):\n",
        "    model = nn.Sequential(\n",
        "        # Bloc 1\n",
        "        nn.Conv2d(3, 16, kernel_size=5, padding=2, bias=True),  # 64 → 16\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16, 16, kernel_size=5, padding=2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.MaxPool2d(2),  # 32x32 → 16x16\n",
        "\n",
        "        # Bloc 2\n",
        "        nn.Conv2d(16, 32, kernel_size=5, padding=2, bias=True),  # 128 → 32\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),  # 16x16 → 8x8\n",
        "\n",
        "        # Bloc 3\n",
        "        nn.Conv2d(32, 32, kernel_size=5, padding=2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),  # 8x8 → 4x4\n",
        "\n",
        "        # Classificateur\n",
        "        nn.Flatten(),              # 32 * 4 * 4 = 512\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(64, 10)\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    return model, loss_fn, optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F8B-MtQwIrx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oABLdS0NwJQx"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    train = CIFAR10Dataset(tr_images, tr_targets)\n",
        "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    val = CIFAR10Dataset(val_images, val_targets)\n",
        "    val_dl = DataLoader(val, batch_size=len(val_images), shuffle=True)\n",
        "    return trn_dl, val_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGA7dXVLwLO5",
        "outputId": "2afdc39c-d662-4417-a9b4-6d2bccaf01c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]           1,216\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "            Conv2d-4           [-1, 16, 32, 32]           6,416\n",
            "              ReLU-5           [-1, 16, 32, 32]               0\n",
            "         Dropout2d-6           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
            "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]          12,832\n",
            "             ReLU-10           [-1, 32, 16, 16]               0\n",
            "        Dropout2d-11           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
            "        MaxPool2d-13             [-1, 32, 8, 8]               0\n",
            "           Conv2d-14             [-1, 32, 8, 8]          25,632\n",
            "             ReLU-15             [-1, 32, 8, 8]               0\n",
            "        Dropout2d-16             [-1, 32, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 32, 8, 8]              64\n",
            "        MaxPool2d-18             [-1, 32, 4, 4]               0\n",
            "          Flatten-19                  [-1, 512]               0\n",
            "           Linear-20                  [-1, 128]          65,664\n",
            "             ReLU-21                  [-1, 128]               0\n",
            "          Dropout-22                  [-1, 128]               0\n",
            "           Linear-23                   [-1, 64]           8,256\n",
            "             ReLU-24                   [-1, 64]               0\n",
            "          Dropout-25                   [-1, 64]               0\n",
            "           Linear-26                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 120,858\n",
            "Trainable params: 120,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.25\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 1.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Définir le device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Charger les données\n",
        "trn_dl, val_dl = get_data()\n",
        "\n",
        "# Initialiser le modèle\n",
        "model, loss_fn, optimizer = get_model(device=device)\n",
        "\n",
        "# Afficher un résumé du modèle\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))  # CIFAR10 : 3 canaux, 32x32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c43c5VK8wOVy"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    prediction = model(x)\n",
        "    batch_loss = loss_fn(prediction, y)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return batch_loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    max_values, argmaxes = prediction.max(-1)\n",
        "    is_correct = argmaxes == y\n",
        "    return is_correct.cpu().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8s7IsyUwR-Q"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def val_loss(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    val_loss = loss_fn(prediction, y)\n",
        "    return val_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-blw4yXLwTnb",
        "outputId": "ed0e70b8-f0a2-4690-b436-626078582d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "for epoch in range(6):\n",
        "    print(epoch)\n",
        "    train_epoch_losses, train_epoch_accuracies = [], []\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
        "        train_epoch_losses.append(batch_loss)\n",
        "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
        "\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        is_correct = accuracy(x, y, model)\n",
        "        train_epoch_accuracies.extend(is_correct)\n",
        "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
        "\n",
        "    for ix, batch in enumerate(iter(val_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        val_is_correct = accuracy(x, y, model)\n",
        "        validation_loss = val_loss(x, y, model)\n",
        "    val_epoch_accuracy = np.mean(val_is_correct)\n",
        "\n",
        "    train_losses.append(train_epoch_loss)\n",
        "    train_accuracies.append(train_epoch_accuracy)\n",
        "    val_losses.append(validation_loss)\n",
        "    val_accuracies.append(val_epoch_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvxloP_xpeU"
      },
      "source": [
        "**INTERPOLATION DU FILTRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGYfASukxtuA"
      },
      "outputs": [],
      "source": [
        "def interpolate_filter(filter_weights, smooth_factor=50):\n",
        "    \"\"\"Interpolation cubique bilinéaire pour passer du filtre discret à une fonction continue\"\"\"\n",
        "    h, w = filter_weights.shape\n",
        "    y = np.arange(h)\n",
        "    x = np.arange(w)\n",
        "    interp_func = RegularGridInterpolator((y, x), filter_weights, method='cubic')\n",
        "    ynew = np.linspace(0, h-1, smooth_factor)\n",
        "    xnew = np.linspace(0, w-1, smooth_factor)\n",
        "    X, Y = np.meshgrid(xnew, ynew)\n",
        "    points = np.array([Y.ravel(), X.ravel()]).T\n",
        "    Zsmooth = interp_func(points).reshape(smooth_factor, smooth_factor)\n",
        "    return Zsmooth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI3eqSuFxubf"
      },
      "source": [
        "**Projection dans schwartz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA0CEZ2Vx3AF"
      },
      "outputs": [],
      "source": [
        "def project_to_schwartz(Zsmooth, sigma=None):\n",
        "    \"\"\"Projette un filtre interpolé dans un espace proche de S(R^2) via une fenêtre gaussienne\"\"\"\n",
        "    H, W = Zsmooth.shape\n",
        "    if sigma is None:\n",
        "        sigma = min(H, W) / 2\n",
        "    y = np.arange(H) - H/2\n",
        "    x = np.arange(W) - W/2\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    gauss_window = np.exp(-(X**2 + Y**2) / (2*sigma**2))\n",
        "    Z_schwartz = Zsmooth * gauss_window\n",
        "    return Z_schwartz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8bfJzHt1uFQ"
      },
      "source": [
        "**Mesure de régularité**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFS613_Wx7NN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def gaussian_window(shape, sigma=1.0, center=None):\n",
        "    \"\"\"Fenêtre gaussienne normalisée 2D\"\"\"\n",
        "    n, m = shape\n",
        "    if center is None:\n",
        "        center = (n//2, m//2)\n",
        "    y = np.arange(n) - center[0]\n",
        "    x = np.arange(m) - center[1]\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    g = np.exp(-(X**2 + Y**2)/(2*sigma**2))\n",
        "    g /= np.sqrt(np.sum(g**2))\n",
        "    return g\n",
        "\n",
        "def local_sobolev_gauss_3D(h, block_size=(5,5), alpha=2, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Calcule la régularité locale de sous-blocs d'un filtre 2D\n",
        "    avec fenêtre gaussienne et pondération Sobolev.\n",
        "\n",
        "    Retour :\n",
        "    - reg_map : matrice de régularité locale\n",
        "    \"\"\"\n",
        "    n, m = h.shape\n",
        "    bh, bw = block_size\n",
        "    reg_map = np.zeros((n - bh + 1, m - bw + 1))\n",
        "\n",
        "    for i in range(n - bh + 1):\n",
        "        for j in range(m - bw + 1):\n",
        "            block = h[i:i+bh, j:j+bw]\n",
        "            g = gaussian_window(block.shape, sigma=sigma)\n",
        "            block_win = block * g\n",
        "\n",
        "            H = np.fft.fft2(block_win)\n",
        "            H = np.fft.fftshift(H)\n",
        "\n",
        "            u = np.fft.fftshift(np.fft.fftfreq(bh))\n",
        "            v = np.fft.fftshift(np.fft.fftfreq(bw))\n",
        "            U, V = np.meshgrid(u, v, indexing='ij')\n",
        "\n",
        "            freq_weight = (1 + U**2 + V**2)**alpha\n",
        "            reg_map[i,j] = np.sum(freq_weight * np.abs(H)**2)\n",
        "\n",
        "    return reg_map\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_7Fds61Q10"
      },
      "source": [
        "**Récupération des poids réguliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90sq5XIUxeBg"
      },
      "outputs": [],
      "source": [
        "def graphcut_filter_surface(Zsmooth, percentile=20):\n",
        "    \"\"\"\n",
        "    Conserve uniquement les valeurs les plus petites (en valeur absolue)\n",
        "    selon un seuil basé sur le percentile.\n",
        "    #\n",
        "    Zsmooth : surface lissée (2D numpy array)\n",
        "    percentile : pourcentage de valeurs à conserver (les plus petites)\n",
        "    \"\"\"\n",
        "    threshold = np.percentile(np.abs(Zsmooth), percentile)\n",
        "    mask = np.abs(Zsmooth) >= threshold  # True là où on garde\n",
        "    Zcut = np.where(mask, Zsmooth, np.nan)  # NaN pour visualiser les trous\n",
        "    return Zcut, mask\n",
        "\n",
        "# Application sur reg_map\n",
        "#Zcut, mask = graphcut_filter_surface(reg_map, percentile=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjFLTC0414E0"
      },
      "source": [
        "Mesure de valeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ky5RZdD13Sm"
      },
      "outputs": [],
      "source": [
        "def magnitude_mesure(Zcut):\n",
        "    \"\"\"\n",
        "    Calcule la somme des valeurs absolues de Zcut.\n",
        "    Les NaN sont traités comme des zéros.\n",
        "    \"\"\"\n",
        "    return np.nansum(np.abs(Zcut))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkpoBSxo8Ef6"
      },
      "outputs": [],
      "source": [
        "def ultimate_graphcut_filter_analysis_magn(filter_weights):\n",
        "  Zsmooth = interpolate_filter(filter_weights)\n",
        "  Z_schwartz = project_to_schwartz(Zsmooth)\n",
        "  reg_map = local_sobolev_gauss_3D(Zsmooth, block_size=(5,5), alpha=2, sigma=1.0)\n",
        "  Zcut, mask = graphcut_filter_surface(Z_schwartz, percentile=20)\n",
        "\n",
        "\n",
        "# Appliquer sur Z_schwartz\n",
        "\n",
        "\n",
        "  return magnitude_mesure(Zcut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp20qDf12KYW"
      },
      "source": [
        "**Classement des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgwbKDtt6rmd",
        "outputId": "d8721890-3bb8-44e4-f010-d3db1816811e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Couche 1/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "   Couche 2/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "   Couche 3/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "   Couche 4/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n"
          ]
        }
      ],
      "source": [
        "from scipy.interpolate import RegularGridInterpolator\n",
        "conv_layers = [module for module in model.modules() if isinstance(module, nn.Conv2d)]\n",
        "\n",
        "filter_ranking = {}\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "\n",
        "for m_idx, conv_layer in enumerate(conv_layers):\n",
        "    print(f\"   Couche {m_idx+1}/{len(conv_layers)}...\")\n",
        "    filter_ranking[m_idx] = {}\n",
        "\n",
        "    out_channels, in_channels, h, w = conv_layer.weight.shape\n",
        "\n",
        "    for oc in range(out_channels):\n",
        "        print(oc)\n",
        "        filter_ranking[m_idx][oc] = {}\n",
        "        for ic in range(in_channels):\n",
        "            print(ic)\n",
        "                # 1. Importance GraphCut multi-échelle + structurelle\n",
        "            filter_weights = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
        "            base_importance = ultimate_graphcut_filter_analysis_magn(filter_weights)\n",
        "\n",
        "                # 2. Correction contextuelle (redondance)\n",
        "            #redundancy_factor = contextual_redundancy_check(conv_layer, oc, ic)\n",
        "\n",
        "                # 3. Score final\n",
        "            #final_importance = base_importance * redundancy_factor\n",
        "            filter_ranking[m_idx][oc][ic] = float(base_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjCKJdwqyTtc"
      },
      "outputs": [],
      "source": [
        "filter_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYv_f--Fr1hi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_filter_ranking_combined(filter_ranking):\n",
        "    \"\"\"\n",
        "    Affiche tous les filtres de toutes les couches dans un seul graphe,\n",
        "    avec une ligne rouge séparant les couches.\n",
        "\n",
        "    Args:\n",
        "        filter_ranking : dict[layer_idx][out_ch][in_ch] = score\n",
        "    \"\"\"\n",
        "    all_scores = []\n",
        "    layer_boundaries = []\n",
        "    current_idx = 0\n",
        "\n",
        "    # Parcourir les couches\n",
        "    for l_idx in sorted(filter_ranking.keys()):\n",
        "        layer_dict = filter_ranking[l_idx]\n",
        "        # Moyenne sur les canaux d'entrée pour chaque filtre de sortie\n",
        "        out_scores = [np.mean(list(layer_dict[oc].values())) for oc in sorted(layer_dict.keys())]\n",
        "        all_scores.extend(out_scores)\n",
        "        current_idx += len(out_scores)\n",
        "        layer_boundaries.append(current_idx)  # position pour la ligne rouge\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.bar(range(len(all_scores)), all_scores)\n",
        "    plt.xlabel(\"Filtres (toutes couches concaténées)\")\n",
        "    plt.ylabel(\"Score d'importance moyen\")\n",
        "    plt.title(\"Importance des filtres par couche\")\n",
        "\n",
        "    # Tracer les lignes rouges pour séparer les couches\n",
        "    for b in layer_boundaries[:-1]:  # pas besoin de la dernière\n",
        "        plt.axvline(x=b-0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRTxF81tr4bU"
      },
      "outputs": [],
      "source": [
        "plot_filter_ranking_combined(filter_ranking)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1n4xHA7AqbN"
      },
      "outputs": [],
      "source": [
        "plot_filter_ranking_combined(filter_ranking)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXAz5Fg9entf"
      },
      "outputs": [],
      "source": [
        "filter_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxw1vTDg15WY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(filter_ranking, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtoD_SR1FFG7"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "model_test = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtB4MCV6FXgU"
      },
      "source": [
        "**Sélection des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5lUEDEW9J1V"
      },
      "outputs": [],
      "source": [
        "def keep_top_percentile_filters(filter_ranking, percentile):\n",
        "    \"\"\"\n",
        "    Keeps the top 'percentile' of filters based on their base_importance score.\n",
        "\n",
        "    Args:\n",
        "        filter_ranking (dict): A dictionary containing the ranking of filters.\n",
        "                               Expected format: {layer_idx: {out_channel_idx: {in_channel_idx: base_importance}}}\n",
        "        percentile (int): The percentile to keep (e.g., 10 for top 10%).\n",
        "\n",
        "    Returns:\n",
        "        dict: A new dictionary containing only the top percentile filters.\n",
        "    \"\"\"\n",
        "    all_importances = []\n",
        "    # Collect all base_importance values\n",
        "    for layer_idx, out_channels in filter_ranking.items():\n",
        "        for out_channel_idx, in_channels in out_channels.items():\n",
        "            for in_channel_idx, importance in in_channels.items():\n",
        "                # Only consider non-NaN importance values\n",
        "                if not np.isnan(importance):\n",
        "                    all_importances.append(importance)\n",
        "\n",
        "    if not all_importances:\n",
        "        print(\"No valid importance values found.\")\n",
        "        return {}\n",
        "\n",
        "    # Calculate the threshold based on the percentile\n",
        "    threshold = np.percentile(all_importances, 100 - percentile) # Keep values >= threshold\n",
        "\n",
        "    # Create a new dictionary with only the top percentile filters\n",
        "    top_filters_ranking = {}\n",
        "    for layer_idx, out_channels in filter_ranking.items():\n",
        "        top_filters_ranking[layer_idx] = {}\n",
        "        for out_channel_idx, in_channels in out_channels.items():\n",
        "            top_filters_ranking[layer_idx][out_channel_idx] = {}\n",
        "            for in_channel_idx, importance in in_channels.items():\n",
        "                if not np.isnan(importance) and importance >= threshold:\n",
        "                    top_filters_ranking[layer_idx][out_channel_idx][in_channel_idx] = importance\n",
        "\n",
        "    return top_filters_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1pVbhwylbrF"
      },
      "outputs": [],
      "source": [
        "top_list = keep_top_percentile_filters(filter_ranking,40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg-VzejFbTq"
      },
      "source": [
        "**Pruning du modèle*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8xk3vXFuog"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def prune_model_by_filters_removal(model, top_indices_list, input_size=(3, 32, 32)):\n",
        "    \"\"\"\n",
        "    VERSION CORRIGÉE: Supprime réellement les filtres pour réduire les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle PyTorch nn.Sequential\n",
        "        top_indices_list: [(layer_idx, out_ch, in_ch), ...] - filtres à CONSERVER\n",
        "        input_size: taille d'entrée (channels, height, width)\n",
        "\n",
        "    Returns:\n",
        "        Modèle pruné avec moins de paramètres\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model_copy = copy.deepcopy(model)\n",
        "\n",
        "    # Organiser les filtres à conserver par couche\n",
        "    filters_to_keep = defaultdict(set)\n",
        "    for layer_idx, out_ch, in_ch in top_indices_list:\n",
        "        filters_to_keep[layer_idx].add(out_ch)\n",
        "\n",
        "    # Convertir en listes triées\n",
        "    for layer_idx in filters_to_keep:\n",
        "        filters_to_keep[layer_idx] = sorted(list(filters_to_keep[layer_idx]))\n",
        "\n",
        "    new_layers = []\n",
        "    conv_layers = [i for i, layer in enumerate(model_copy) if isinstance(layer, nn.Conv2d)]\n",
        "    prev_kept_channels = None\n",
        "\n",
        "    for i, layer in enumerate(model_copy):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Trouver l'index de cette couche conv\n",
        "            conv_idx = conv_layers.index(i)\n",
        "\n",
        "            # Déterminer les canaux de sortie à conserver\n",
        "            if conv_idx in filters_to_keep:\n",
        "                keep_out_channels = filters_to_keep[conv_idx]\n",
        "            else:\n",
        "                # Si pas spécifié, garder tous les canaux\n",
        "                keep_out_channels = list(range(layer.out_channels))\n",
        "\n",
        "            # Déterminer les canaux d'entrée\n",
        "            if conv_idx == 0:\n",
        "                # Première couche: garder tous les canaux d'entrée (RGB)\n",
        "                new_in_channels = layer.in_channels\n",
        "                keep_in_channels = list(range(layer.in_channels))\n",
        "            else:\n",
        "                # Couches suivantes: s'adapter aux canaux conservés de la couche précédente\n",
        "                new_in_channels = len(prev_kept_channels) if prev_kept_channels else layer.in_channels\n",
        "                keep_in_channels = prev_kept_channels if prev_kept_channels else list(range(layer.in_channels))\n",
        "\n",
        "            new_out_channels = len(keep_out_channels)\n",
        "\n",
        "            # Créer la nouvelle couche Conv2d RÉDUITE\n",
        "            new_conv = nn.Conv2d(\n",
        "                in_channels=new_in_channels,\n",
        "                out_channels=new_out_channels,\n",
        "                kernel_size=layer.kernel_size,\n",
        "                stride=layer.stride,\n",
        "                padding=layer.padding,\n",
        "                bias=(layer.bias is not None)\n",
        "            ).to(device)\n",
        "\n",
        "            # Copier uniquement les poids des filtres conservés\n",
        "            with torch.no_grad():\n",
        "                for new_out_idx, old_out_idx in enumerate(keep_out_channels):\n",
        "                    for new_in_idx, old_in_idx in enumerate(keep_in_channels):\n",
        "                        new_conv.weight[new_out_idx, new_in_idx] = layer.weight[old_out_idx, old_in_idx]\n",
        "\n",
        "                    if layer.bias is not None:\n",
        "                        new_conv.bias[new_out_idx] = layer.bias[old_out_idx]\n",
        "\n",
        "            new_layers.append(new_conv)\n",
        "            prev_kept_channels = keep_out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            # Adapter BatchNorm aux canaux conservés\n",
        "            if prev_kept_channels is not None:\n",
        "                new_bn = nn.BatchNorm2d(len(prev_kept_channels)).to(device)\n",
        "                with torch.no_grad():\n",
        "                    for new_idx, old_idx in enumerate(prev_kept_channels):\n",
        "                        new_bn.weight[new_idx] = layer.weight[old_idx]\n",
        "                        new_bn.bias[new_idx] = layer.bias[old_idx]\n",
        "                        new_bn.running_mean[new_idx] = layer.running_mean[old_idx]\n",
        "                        new_bn.running_var[new_idx] = layer.running_var[old_idx]\n",
        "                new_layers.append(new_bn)\n",
        "            else:\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            # Ajuster la première couche Linear après Flatten\n",
        "            if len([l for l in new_layers if isinstance(l, nn.Linear)]) == 0:\n",
        "                # Calculer la nouvelle taille après les couches conv\n",
        "                new_input_features = calculate_linear_input_size(new_layers, input_size)\n",
        "\n",
        "                new_linear = nn.Linear(\n",
        "                    in_features=new_input_features,\n",
        "                    out_features=layer.out_features,\n",
        "                    bias=(layer.bias is not None)\n",
        "                ).to(device)\n",
        "\n",
        "                # Copier les poids (avec adaptation de taille)\n",
        "                with torch.no_grad():\n",
        "                    min_features = min(new_input_features, layer.in_features)\n",
        "                    new_linear.weight[:, :min_features] = layer.weight[:, :min_features]\n",
        "                    if layer.bias is not None:\n",
        "                        new_linear.bias[:] = layer.bias[:]\n",
        "\n",
        "                new_layers.append(new_linear)\n",
        "            else:\n",
        "                # Autres couches Linear: copier tel quel\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "        else:\n",
        "            # Autres couches (ReLU, MaxPool, Dropout, Flatten)\n",
        "            new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "    return nn.Sequential(*new_layers).to(device)\n",
        "\n",
        "def calculate_linear_input_size(conv_layers, input_size):\n",
        "    \"\"\"\n",
        "    Calcule la taille d'entrée pour la première couche Linear\n",
        "    en simulant une passe avant à travers les couches conv.\n",
        "    \"\"\"\n",
        "    channels, h, w = input_size\n",
        "\n",
        "    for layer in conv_layers:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Calculer nouvelle taille après convolution\n",
        "            kernel_size = layer.kernel_size[0] if isinstance(layer.kernel_size, tuple) else layer.kernel_size\n",
        "            stride = layer.stride[0] if isinstance(layer.stride, tuple) else layer.stride\n",
        "            padding = layer.padding[0] if isinstance(layer.padding, tuple) else layer.padding\n",
        "\n",
        "            h = (h + 2*padding - kernel_size) // stride + 1\n",
        "            w = (w + 2*padding - kernel_size) // stride + 1\n",
        "            channels = layer.out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.MaxPool2d):\n",
        "            kernel_size = layer.kernel_size\n",
        "            stride = layer.stride if layer.stride else kernel_size\n",
        "            h = h // stride\n",
        "            w = w // stride\n",
        "\n",
        "    return channels * h * w\n",
        "\n",
        "def structured_channel_pruning(model, importance_dict, keep_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Pruning structuré: supprime des canaux entiers basé sur leur importance moyenne.\n",
        "    Plus efficace pour réduire réellement les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle à pruner\n",
        "        importance_dict: dict[layer][out_ch][in_ch] = importance\n",
        "        keep_ratio: fraction de canaux à conserver (0.5 = 50%)\n",
        "    \"\"\"\n",
        "    # Calculer l'importance moyenne par canal de sortie\n",
        "    channel_importance = {}\n",
        "\n",
        "    for layer_idx in importance_dict:\n",
        "        channel_importance[layer_idx] = {}\n",
        "        for out_ch in importance_dict[layer_idx]:\n",
        "            # Moyenne d'importance sur tous les canaux d'entrée pour ce canal de sortie\n",
        "            avg_importance = np.mean(list(importance_dict[layer_idx][out_ch].values()))\n",
        "            channel_importance[layer_idx][out_ch] = avg_importance\n",
        "\n",
        "    # Sélectionner les top canaux pour chaque couche\n",
        "    top_indices = []\n",
        "    for layer_idx in channel_importance:\n",
        "        # Trier par importance décroissante\n",
        "        channels_by_importance = sorted(\n",
        "            channel_importance[layer_idx].items(),\n",
        "            key=lambda x: x[1],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Garder le top keep_ratio\n",
        "        n_keep = max(1, int(len(channels_by_importance) * keep_ratio))\n",
        "        top_channels = [ch for ch, _ in channels_by_importance[:n_keep]]\n",
        "\n",
        "        # Créer les indices pour tous les canaux d'entrée de ces canaux de sortie\n",
        "        for out_ch in top_channels:\n",
        "            for in_ch in importance_dict[layer_idx][out_ch]:\n",
        "                top_indices.append((layer_idx, out_ch, in_ch))\n",
        "\n",
        "    return top_indices\n",
        "\n",
        "def test_effective_pruning(model, importance_dict, trn_dl, val_dl, loss_fn, keep_ratios=[0.8, 0.6, 0.4, 0.2]):\n",
        "    \"\"\"\n",
        "    Test de pruning avec réduction EFFECTIVE des paramètres.\n",
        "    \"\"\"\n",
        "    print(\"Test de Pruning avec Réduction Effective des Paramètres\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Baseline\n",
        "    orig_params = sum(p.numel() for p in model.parameters())\n",
        "    orig_loss, orig_acc = evaluate_model(model, val_dl, loss_fn)\n",
        "\n",
        "    print(f\"Modèle original: {orig_acc:.4f} accuracy, {orig_params:,} paramètres\")\n",
        "    print()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for keep_ratio in keep_ratios:\n",
        "        print(f\"Test avec keep_ratio = {keep_ratio} ({keep_ratio*100:.0f}% des canaux)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            # Pruning structuré par canaux\n",
        "            top_indices = structured_channel_pruning(model, importance_dict, keep_ratio)\n",
        "            print(f\"Filtres sélectionnés: {len(top_indices)}\")\n",
        "\n",
        "            # Appliquer le pruning EFFECTIF\n",
        "            pruned_model = prune_model_by_filters_removal(model, top_indices, input_size=(3, 32, 32))\n",
        "\n",
        "            # Vérifier la réduction\n",
        "            pruned_params = sum(p.numel() for p in pruned_model.parameters())\n",
        "            actual_reduction = (orig_params - pruned_params) / orig_params * 100\n",
        "\n",
        "            print(f\"Paramètres avant: {orig_params:,}\")\n",
        "            print(f\"Paramètres après: {pruned_params:,}\")\n",
        "            print(f\"Réduction RÉELLE: {actual_reduction:.1f}%\")\n",
        "\n",
        "            # Test du modèle pruné\n",
        "            val_loss_before, val_acc_before = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "            print(f\"Accuracy avant fine-tuning: {val_acc_before:.4f}\")\n",
        "\n",
        "            # Fine-tuning\n",
        "            print(\"Fine-tuning...\")\n",
        "            pruned_model = fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=5, lr=1e-3)\n",
        "\n",
        "            val_loss_final, val_acc_final = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "\n",
        "            accuracy_retention = (val_acc_final / orig_acc) * 100\n",
        "            compression_ratio = orig_params / pruned_params\n",
        "\n",
        "            print(f\"Accuracy finale: {val_acc_final:.4f}\")\n",
        "            print(f\"Rétention accuracy: {accuracy_retention:.1f}%\")\n",
        "            print(f\"Ratio de compression: {compression_ratio:.1f}x\")\n",
        "            print()\n",
        "\n",
        "            results.append({\n",
        "                'keep_ratio': keep_ratio,\n",
        "                'actual_reduction': actual_reduction,\n",
        "                'final_accuracy': val_acc_final,\n",
        "                'accuracy_retention': accuracy_retention,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'pruned_params': pruned_params\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur avec keep_ratio {keep_ratio}: {e}\")\n",
        "            print()\n",
        "\n",
        "    # Résumé des résultats\n",
        "    print(\"RÉSUMÉ DES RÉSULTATS\")\n",
        "    print(\"=\"*40)\n",
        "    for r in results:\n",
        "        print(f\"Keep {r['keep_ratio']*100:.0f}%: {r['actual_reduction']:.1f}% réduction, \"\n",
        "              f\"{r['accuracy_retention']:.1f}% accuracy, {r['compression_ratio']:.1f}x compression\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Fonction d'évaluation (si pas déjà définie)\n",
        "def evaluate_model(model, val_dl, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            device = next(model.parameters()).device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += x.size(0)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "def fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=10, lr=1e-4):\n",
        "    \"\"\"Fine-tune le modèle pruné pour récupérer l'accuracy.\"\"\"\n",
        "    from torch.optim import Adam\n",
        "\n",
        "    device = next(pruned_model.parameters()).device\n",
        "    optimizer = Adam(pruned_model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pruned_model.train()\n",
        "        for x, y in trn_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = pruned_model(x)\n",
        "            loss = loss_fn(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation check\n",
        "        val_loss, val_acc = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "        if epoch == 0 or (epoch + 1) % 2 == 0:\n",
        "            print(f\"  Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "# Usage example:\n",
        "# Remplacer votre appel par:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyvjgo6gajdQ"
      },
      "outputs": [],
      "source": [
        "test_effective_pruning(model_test,filter_ranking,trn_dl, val_dl, loss_fn) #gardant 50 plus régulière"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70nA-O9NAxG2"
      },
      "outputs": [],
      "source": [
        "test_effective_pruning(model_test,filter_ranking,trn_dl, val_dl, loss_fn) #gardant 20 plus régulière"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}