{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvxloP_xpeU"
      },
      "source": [
        "**INTERPOLATION DU FILTRE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les codes ci-dessous permettent d'abord d'interpoler le filtre de dimension 4x4 vers une dimension 50x50. \n",
        "Ensuite, le filtre est projet√© dans l'espace de Schwartz. Explication dans le rapport."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGYfASukxtuA"
      },
      "outputs": [],
      "source": [
        "from scipy.interpolate import RegularGridInterpolator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "# -----------------------------\n",
        "# 1. Interpolation du filtre\n",
        "# -----------------------------\n",
        "def interpolate_filter(filter_weights, smooth_factor=50):\n",
        "    \"\"\"Interpolation cubique bilin√©aire pour passer du filtre discret √† une fonction continue\n",
        "    retour : \n",
        "    - Zsmooth : filtre projet√© en dimension 50x50\n",
        "    \"\"\"\n",
        "    h, w = filter_weights.shape\n",
        "    y = np.arange(h)\n",
        "    x = np.arange(w)\n",
        "    interp_func = RegularGridInterpolator((y, x), filter_weights, method='cubic')\n",
        "    ynew = np.linspace(0, h-1, smooth_factor)\n",
        "    xnew = np.linspace(0, w-1, smooth_factor)\n",
        "    X, Y = np.meshgrid(xnew, ynew)\n",
        "    points = np.array([Y.ravel(), X.ravel()]).T\n",
        "    Zsmooth = interp_func(points).reshape(smooth_factor, smooth_factor)\n",
        "    return Zsmooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA0CEZ2Vx3AF"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 2. Projection dans l'espace de Schwartz\n",
        "# -----------------------------\n",
        "def project_to_schwartz(Zsmooth, sigma=None):\n",
        "    \"\"\"Projette un filtre interpol√© dans un espace proche de S(R^2) via une fen√™tre gaussienne\n",
        "    retour : \n",
        "    - Z_schwartz : filtre projet√© dans l'espace de Schwartz \n",
        "    \"\"\"\n",
        "    H, W = Zsmooth.shape\n",
        "    if sigma is None:\n",
        "        sigma = min(H, W) / 2\n",
        "    y = np.arange(H) - H/2\n",
        "    x = np.arange(W) - W/2\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    gauss_window = np.exp(-(X**2 + Y**2) / (2*sigma**2))\n",
        "    Z_schwartz = Zsmooth * gauss_window\n",
        "    return Z_schwartz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8bfJzHt1uFQ"
      },
      "source": [
        "**NORME DE SOBOLEV : MESURE DE REGULARITE** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le code ci-dessous permet de d√©finir la norme de Sobolev utilis√© pour mesure la r√©gularit√© des filtres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFS613_Wx7NN"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 1. D√©finition de la fen√™tre Gausienne utilis√©e pour la d√©finition de la norme locale\n",
        "# -----------------------------\n",
        "def gaussian_window(shape, sigma=1.0, center=None):\n",
        "    \"\"\"Fen√™tre gaussienne normalis√©e 2D\n",
        "    retour : \n",
        "    - g : la fen√™tre gausienne\n",
        "    \"\"\"\n",
        "    n, m = shape\n",
        "    if center is None:\n",
        "        center = (n//2, m//2)\n",
        "    y = np.arange(n) - center[0]\n",
        "    x = np.arange(m) - center[1]\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    g = np.exp(-(X**2 + Y**2)/(2*sigma**2))\n",
        "    g /= np.sqrt(np.sum(g**2))\n",
        "    return g\n",
        "# -----------------------------\n",
        "# 2. D√©finition de la norme de Sobolev locale\n",
        "# -----------------------------\n",
        "def local_sobolev_gauss_3D(h, block_size=(5,5), alpha=2, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Calcule la r√©gularit√© locale de sous-blocs d'un filtre 2D\n",
        "    avec fen√™tre gaussienne et pond√©ration Sobolev.\n",
        "\n",
        "    retour :\n",
        "    - reg_map : matrice de r√©gularit√© locale\n",
        "    \"\"\"\n",
        "    n, m = h.shape\n",
        "    bh, bw = block_size\n",
        "    reg_map = np.zeros((n - bh + 1, m - bw + 1))\n",
        "\n",
        "    for i in range(n - bh + 1):\n",
        "        for j in range(m - bw + 1):\n",
        "            block = h[i:i+bh, j:j+bw]\n",
        "            g = gaussian_window(block.shape, sigma=sigma)\n",
        "            block_win = block * g\n",
        "\n",
        "            H = np.fft.fft2(block_win)\n",
        "            H = np.fft.fftshift(H)\n",
        "\n",
        "            u = np.fft.fftshift(np.fft.fftfreq(bh))\n",
        "            v = np.fft.fftshift(np.fft.fftfreq(bw))\n",
        "            U, V = np.meshgrid(u, v, indexing='ij')\n",
        "\n",
        "            freq_weight = (1 + U**2 + V**2)**alpha\n",
        "            reg_map[i,j] = np.sum(freq_weight * np.abs(H)**2)\n",
        "\n",
        "    return reg_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_7Fds61Q10"
      },
      "source": [
        "**TRAITEMENT DES POIDS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Une fois la norme d√©finit, il nous d√©finissons une methode de comparaison des filtres sur la base de cette derni√®re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90sq5XIUxeBg"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 1. Fonction de s√©lection (utiliser pour d√©finir le P)\n",
        "# -----------------------------\n",
        "def graphcut_filter_surface(Zsmooth, percentile):\n",
        "    \"\"\"\n",
        "    Conserve uniquement les valeurs les plus petites (en valeur absolue)\n",
        "    selon un seuil bas√© sur le percentile d'un filtre donn√©\n",
        "    \n",
        "    retour : \n",
        "    - Zcut : filtre conservant seuleument les poids de r√©gularit√© appartenant au percentile de r√©gularit√© donn√©\n",
        "    - mask : masque cr√©e suite au filtrage\n",
        "    \"\"\"\n",
        "    threshold = np.percentile(np.abs(Zsmooth), percentile)\n",
        "    mask = np.abs(Zsmooth) <= threshold  # True l√† o√π on garde\n",
        "    Zcut = np.where(mask, Zsmooth, np.nan)  # NaN pour visualiser les trous\n",
        "    return Zcut, mask\n",
        "def magnitude_mesure(Zcut):\n",
        "    \"\"\"\n",
        "    Calcule la somme des valeurs absolues de Zcut.\n",
        "    Les NaN sont trait√©s comme des z√©ros.\n",
        "    \"\"\"\n",
        "    return np.nansum(np.abs(Zcut))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPbX5jqYDHnS"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 2. Calcule de la r√©gularit√© sur l'ensemble du filtre\n",
        "# -----------------------------\n",
        "def ultimate_graphcut_filter_analysis_reg(filter_weights):\n",
        "  \"\"\"\n",
        "  Calcule la r√©gularit√© totale d'un filtre en se basant sur la mesure locale\n",
        "  \n",
        "  retour : \n",
        "  - valeur de la r√©gularit√© du filtre\n",
        "  \"\"\"\n",
        "  Zsmooth = interpolate_filter(filter_weights)\n",
        "  Z_schwartz = project_to_schwartz(Zsmooth)\n",
        "  reg_map = local_sobolev_gauss_3D(Zsmooth, block_size=(5,5), alpha=2, sigma=58)\n",
        "  Zcut, mask = graphcut_filter_surface(reg_map, percentile=80) #Pourcentage √† modifier \n",
        "  return magnitude_mesure(Zcut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp20qDf12KYW"
      },
      "source": [
        "**CLASSEMENT DES FILTRES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Une fois la norme √©tablit, nous parcourons l'ensemble des filtres de l'ensemble des couches de convolution afin de classe les filtres selon la valeur de la norme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgwbKDtt6rmd",
        "outputId": "a11c6456-b498-4095-941a-70b4ea92f71d"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 1. Classement des filtres selon leur valeur de r√©gularit√©\n",
        "# -----------------------------\n",
        "conv_layers = [module for module in model.modules() if isinstance(module, nn.Conv2d)]\n",
        "\n",
        "filter_ranking = {}\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "\n",
        "for m_idx, conv_layer in enumerate(conv_layers):\n",
        "    print(f\"   Couche {m_idx+1}/{len(conv_layers)}...\")\n",
        "\n",
        "    # V√©rification si la couche est un bottleneck\n",
        "    # Si la couche est un bottleneck, on la saute\n",
        "    # Le bottleneck est une convolution 1x1 apr√®s une couche de plus grande taille, on suppose que c'est un crit√®re ici\n",
        "    if conv_layer.kernel_size == (1, 1):\n",
        "        print(f\"   Couche {m_idx+1} est un bottleneck, on passe.\")\n",
        "        continue\n",
        "\n",
        "    filter_ranking[m_idx] = {}\n",
        "\n",
        "    out_channels, in_channels, h, w = conv_layer.weight.shape\n",
        "\n",
        "    for oc in range(out_channels):\n",
        "        print(oc)\n",
        "        filter_ranking[m_idx][oc] = {}\n",
        "        for ic in range(in_channels):\n",
        "            print(ic)\n",
        "\n",
        "            # 1. R√©cup√®re les poids du filtre\n",
        "            filter_weights = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
        "\n",
        "            #2. Calcule la r√©gularit√© du filtre\n",
        "            base_importance = ultimate_graphcut_filter_analysis_reg(filter_weights)\n",
        "\n",
        "            # 3. Peuple le dictionnaire √† l'indice de la couche et du filtre correspondant, la valeur √©tant la mesure de r√©gularit√©\n",
        "            filter_ranking[m_idx][oc][ic] = float(base_importance)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 2. Enregistrement du dictionnaire\n",
        "# -----------------------------\n",
        "import json \n",
        "with open(\"filter_ranking.json\", \"w\") as f: \n",
        "    json.dump(filter_ranking, f, indent=4)\n",
        "from google.colab import files\n",
        "files.download(\"filter_ranking.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**PRUNING DU MODELE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg-VzejFbTq"
      },
      "source": [
        "Une fois le dictionnaire de classement des filtres r√©cup√©r√©, nous prunons notre mod√®le en conservant un pourcentage fixe des filtres les plus r√©guliers. Nous reconstruisons ainsi un mod√®le plus l√©ger que nous r√©-entrainons ensuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keep_top_percentile_filters(filter_ranking, percentile):\n",
        "    \"\"\"\n",
        "    Keeps the top 'percentile' of filters based on their base_importance score.\n",
        "\n",
        "    Args:\n",
        "        filter_ranking (dict): A dictionary containing the ranking of filters.\n",
        "                               Expected format: {layer_idx: {out_channel_idx: {in_channel_idx: base_importance}}}\n",
        "        percentile (int): The percentile to keep (e.g., 10 for top 10%).\n",
        "\n",
        "    Returns:\n",
        "        dict: A new dictionary containing only the top percentile filters.\n",
        "    \"\"\"\n",
        "    all_importances = []\n",
        "    # Collect all base_importance values\n",
        "    for layer_idx, out_channels in filter_ranking.items():\n",
        "        for out_channel_idx, in_channels in out_channels.items():\n",
        "            for in_channel_idx, importance in in_channels.items():\n",
        "                # Only consider non-NaN importance values\n",
        "                if not np.isnan(importance):\n",
        "                    all_importances.append(importance)\n",
        "\n",
        "    if not all_importances:\n",
        "        print(\"No valid importance values found.\")\n",
        "        return {}\n",
        "\n",
        "    # Calculate the threshold based on the percentile\n",
        "    threshold = np.percentile(all_importances, 100 - percentile) # Keep values >= threshold\n",
        "\n",
        "    # Create a new dictionary with only the top percentile filters\n",
        "    top_filters_ranking = {}\n",
        "    for layer_idx, out_channels in filter_ranking.items():\n",
        "        top_filters_ranking[layer_idx] = {}\n",
        "        for out_channel_idx, in_channels in out_channels.items():\n",
        "            top_filters_ranking[layer_idx][out_channel_idx] = {}\n",
        "            for in_channel_idx, importance in in_channels.items():\n",
        "                if not np.isnan(importance) and importance <= threshold:\n",
        "                    top_filters_ranking[layer_idx][out_channel_idx][in_channel_idx] = importance\n",
        "\n",
        "    return top_filters_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8xk3vXFuog"
      },
      "outputs": [],
      "source": [
        "def structured_channel_pruning(model, importance_dict, keep_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Pruning structur√© bas√© sur la r√©gularit√© (petites valeurs = plus r√©gulier = garder).\n",
        "\n",
        "    Returns:\n",
        "        dict[layer_idx] = [list of output channels to keep]\n",
        "    \"\"\"\n",
        "    print(f\"\\n  DEBUG: importance_dict a {len(importance_dict)} couches\")\n",
        "\n",
        "    channel_importance = {}\n",
        "\n",
        "    for layer_idx in importance_dict:\n",
        "        channel_importance[layer_idx] = {}\n",
        "        for out_ch in importance_dict[layer_idx]:\n",
        "            avg_regularity = np.mean(list(importance_dict[layer_idx][out_ch].values()))\n",
        "            channel_importance[layer_idx][out_ch] = avg_regularity\n",
        "\n",
        "    channels_to_keep = {}\n",
        "\n",
        "    for layer_idx in channel_importance:\n",
        "        # Tri croissant : plus petites valeurs (plus r√©gulier) en premier\n",
        "        channels_by_regularity = sorted(\n",
        "            channel_importance[layer_idx].items(),\n",
        "            key=lambda x: x[1],\n",
        "            reverse=False\n",
        "        )\n",
        "\n",
        "        total_channels = len(channels_by_regularity)\n",
        "        n_keep = max(1, int(total_channels * keep_ratio))\n",
        "\n",
        "        \n",
        "        kept_channel_indices = sorted([int(ch) for ch, _ in channels_by_regularity[:n_keep]])\n",
        "\n",
        "       \n",
        "        channels_to_keep[int(layer_idx)] = kept_channel_indices\n",
        "\n",
        "        \n",
        "        print(f\"  Layer {int(layer_idx)}: garde {n_keep}/{total_channels} canaux -> {kept_channel_indices[:5]}{'...' if len(kept_channel_indices) > 5 else ''}\")\n",
        "\n",
        "        \n",
        "        if n_keep == total_channels:\n",
        "            print(f\"    ‚ö†Ô∏è  ATTENTION: On garde 100% des canaux de la couche {layer_idx}!\")\n",
        "\n",
        "    return channels_to_keep\n",
        "\n",
        "\n",
        "def calculate_output_size_after_layer(layer, h, w, channels):\n",
        "    \"\"\"Calcule la taille de sortie apr√®s une couche\"\"\"\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        kernel_size = layer.kernel_size[0] if isinstance(layer.kernel_size, tuple) else layer.kernel_size\n",
        "        stride = layer.stride[0] if isinstance(layer.stride, tuple) else layer.stride\n",
        "        padding = layer.padding[0] if isinstance(layer.padding, tuple) else layer.padding\n",
        "\n",
        "        h = (h + 2*padding - kernel_size) // stride + 1\n",
        "        w = (w + 2*padding - kernel_size) // stride + 1\n",
        "        channels = layer.out_channels\n",
        "\n",
        "    elif isinstance(layer, nn.MaxPool2d):\n",
        "        kernel_size = layer.kernel_size\n",
        "        stride = layer.stride if layer.stride else kernel_size\n",
        "        h = h // stride\n",
        "        w = w // stride\n",
        "\n",
        "    elif isinstance(layer, nn.AdaptiveAvgPool2d):\n",
        "        # AdaptiveAvgPool force la sortie √† une taille fixe\n",
        "        if isinstance(layer.output_size, tuple):\n",
        "            h, w = layer.output_size\n",
        "        else:\n",
        "            h = w = layer.output_size\n",
        "\n",
        "    return h, w, channels\n",
        "\n",
        "\n",
        "def prune_model_by_channel_removal(model, channels_to_keep, input_size=(3, 32, 32)):\n",
        "    \"\"\"\n",
        "    Supprime des canaux entiers du mod√®le.\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model_copy = copy.deepcopy(model)\n",
        "\n",
        "    print(f\"\\n  DEBUG prune_model: channels_to_keep = {channels_to_keep}\")\n",
        "\n",
        "    new_layers = []\n",
        "    conv_layers = [i for i, layer in enumerate(model_copy) if isinstance(layer, nn.Conv2d)]\n",
        "\n",
        "    print(f\"  Couches Conv trouv√©es aux indices: {conv_layers}\")\n",
        "\n",
        "    prev_kept_channels = None\n",
        "\n",
        "    for i, layer in enumerate(model_copy):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            conv_idx = conv_layers.index(i)\n",
        "\n",
        "            # Canaux de sortie √† garder\n",
        "            keep_out_channels = channels_to_keep.get(conv_idx, list(range(layer.out_channels)))\n",
        "\n",
        "            print(f\"  Conv {conv_idx} (indice {i}): {layer.out_channels} canaux -> garde {len(keep_out_channels)} canaux\")\n",
        "\n",
        "            # Canaux d'entr√©e\n",
        "            if conv_idx == 0:\n",
        "                keep_in_channels = list(range(layer.in_channels))\n",
        "            else:\n",
        "                keep_in_channels = prev_kept_channels if prev_kept_channels else list(range(layer.in_channels))\n",
        "\n",
        "            # Cr√©er nouvelle couche\n",
        "            new_conv = nn.Conv2d(\n",
        "                in_channels=len(keep_in_channels),\n",
        "                out_channels=len(keep_out_channels),\n",
        "                kernel_size=layer.kernel_size,\n",
        "                stride=layer.stride,\n",
        "                padding=layer.padding,\n",
        "                bias=(layer.bias is not None)\n",
        "            ).to(device)\n",
        "\n",
        "            print(f\"    Nouvelle Conv: in={len(keep_in_channels)}, out={len(keep_out_channels)}\")\n",
        "\n",
        "            # Copier les poids\n",
        "            with torch.no_grad():\n",
        "                for new_out_idx, old_out_idx in enumerate(keep_out_channels):\n",
        "                    for new_in_idx, old_in_idx in enumerate(keep_in_channels):\n",
        "                        new_conv.weight[new_out_idx, new_in_idx] = layer.weight[old_out_idx, old_in_idx]\n",
        "                    if layer.bias is not None:\n",
        "                        new_conv.bias[new_out_idx] = layer.bias[old_out_idx]\n",
        "\n",
        "            new_layers.append(new_conv)\n",
        "            prev_kept_channels = keep_out_channels\n",
        "\n",
        "            # ‚úÖ V√©rification: s'assurer que la r√©duction a bien eu lieu\n",
        "            if len(keep_out_channels) == layer.out_channels:\n",
        "                print(f\"    ‚ö†Ô∏è  AUCUNE r√©duction pour Conv {conv_idx}!\")\n",
        "            else:\n",
        "                reduction = (1 - len(keep_out_channels) / layer.out_channels) * 100\n",
        "                print(f\"    ‚úÖ R√©duction de {reduction:.1f}% pour Conv {conv_idx}\")\n",
        "\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            if prev_kept_channels is not None:\n",
        "                new_bn = nn.BatchNorm2d(len(prev_kept_channels)).to(device)\n",
        "                with torch.no_grad():\n",
        "                    for new_idx, old_idx in enumerate(prev_kept_channels):\n",
        "                        new_bn.weight[new_idx] = layer.weight[old_idx]\n",
        "                        new_bn.bias[new_idx] = layer.bias[old_idx]\n",
        "                        new_bn.running_mean[new_idx] = layer.running_mean[old_idx]\n",
        "                        new_bn.running_var[new_idx] = layer.running_var[old_idx]\n",
        "                new_layers.append(new_bn)\n",
        "            else:\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            # V√©rifier si c'est la premi√®re Linear apr√®s les conv\n",
        "            if len([l for l in new_layers if isinstance(l, nn.Linear)]) == 0:\n",
        "                # Calculer la taille r√©elle apr√®s toutes les couches conv\n",
        "                channels, h, w = input_size\n",
        "\n",
        "                for prev_layer in new_layers:\n",
        "                    h, w, channels = calculate_output_size_after_layer(prev_layer, h, w, channels)\n",
        "\n",
        "                new_input_features = channels * h * w\n",
        "\n",
        "                print(f\"  Linear input: {new_input_features} (channels={channels}, h={h}, w={w})\")\n",
        "\n",
        "                new_linear = nn.Linear(\n",
        "                    in_features=new_input_features,\n",
        "                    out_features=layer.out_features,\n",
        "                    bias=(layer.bias is not None)\n",
        "                ).to(device)\n",
        "\n",
        "                # Initialiser al√©atoirement (pas de copie des poids car taille incompatible)\n",
        "                with torch.no_grad():\n",
        "                    nn.init.kaiming_normal_(new_linear.weight)\n",
        "                    if layer.bias is not None:\n",
        "                        new_linear.bias.zero_()\n",
        "\n",
        "                new_layers.append(new_linear)\n",
        "            else:\n",
        "                # Autres Linear: copier tel quel\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "        else:\n",
        "            # Autres couches (ReLU, MaxPool, Dropout, Flatten, AdaptiveAvgPool)\n",
        "            new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "    return nn.Sequential(*new_layers).to(device)\n",
        "\n",
        "\n",
        "def test_effective_pruning(model, importance_dict, trn_dl, val_dl, loss_fn,\n",
        "                          keep_ratios=[0.9, 0.8, 0.7, 0.6, 0.5],\n",
        "                          return_best=True):\n",
        "    \"\"\"\n",
        "    Test de pruning avec r√©duction effective des param√®tres.\n",
        "\n",
        "    Args:\n",
        "        return_best: Si True, retourne le meilleur mod√®le (meilleur compromis accuracy/compression)\n",
        "\n",
        "    Returns:\n",
        "        Si return_best=True: (best_model, results)\n",
        "        Sinon: results\n",
        "    \"\"\"\n",
        "    print(\"Test de Pruning avec R√©duction Effective des Param√®tres\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Baseline\n",
        "    orig_params = sum(p.numel() for p in model.parameters())\n",
        "    orig_loss, orig_acc = evaluate_model(model, val_dl, loss_fn)\n",
        "\n",
        "    print(f\"Mod√®le original: {orig_acc:.4f} accuracy, {orig_params:,} param√®tres\\n\")\n",
        "\n",
        "    results = []\n",
        "    best_model = None\n",
        "    best_score = -float('inf')\n",
        "\n",
        "    for keep_ratio in keep_ratios:\n",
        "        print(f\"Test avec keep_ratio = {keep_ratio} ({keep_ratio*100:.0f}% des canaux)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            # Pruning structur√©\n",
        "            channels_to_keep = structured_channel_pruning(model, importance_dict, keep_ratio)\n",
        "\n",
        "            # Afficher le nombre de canaux gard√©s par couche\n",
        "            total_kept = sum(len(chs) for chs in channels_to_keep.values())\n",
        "            print(f\"  Total canaux gard√©s: {total_kept}\")\n",
        "\n",
        "            # Appliquer le pruning\n",
        "            pruned_model = prune_model_by_channel_removal(model, channels_to_keep, input_size=(3, 32, 32))\n",
        "\n",
        "            # V√©rifier la r√©duction\n",
        "            pruned_params = sum(p.numel() for p in pruned_model.parameters())\n",
        "            actual_reduction = (orig_params - pruned_params) / orig_params * 100\n",
        "\n",
        "            print(f\"\\nParam√®tres avant: {orig_params:,}\")\n",
        "            print(f\"Param√®tres apr√®s: {pruned_params:,}\")\n",
        "            print(f\"R√©duction R√âELLE: {actual_reduction:.1f}%\")\n",
        "\n",
        "            # Test avant fine-tuning\n",
        "            val_loss_before, val_acc_before = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "            print(f\"Accuracy avant fine-tuning: {val_acc_before:.4f}\")\n",
        "\n",
        "            # Fine-tuning\n",
        "            print(\"Fine-tuning...\")\n",
        "            pruned_model = fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=5, lr=1e-3)\n",
        "\n",
        "            val_loss_final, val_acc_final = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "            accuracy_retention = (val_acc_final / orig_acc) * 100\n",
        "            compression_ratio = orig_params / pruned_params if pruned_params > 0 else 0\n",
        "\n",
        "            print(f\"Accuracy finale: {val_acc_final:.4f}\")\n",
        "            print(f\"R√©tention accuracy: {accuracy_retention:.1f}%\")\n",
        "            print(f\"Ratio de compression: {compression_ratio:.2f}x\\n\")\n",
        "\n",
        "            # Calculer un score pour trouver le meilleur mod√®le\n",
        "            # Score = accuracy_retention * log(compression_ratio)\n",
        "            # Favorise un bon √©quilibre entre accuracy et compression\n",
        "            import math\n",
        "            score = accuracy_retention * math.log(compression_ratio + 1)\n",
        "\n",
        "            results.append({\n",
        "                'keep_ratio': keep_ratio,\n",
        "                'actual_reduction': actual_reduction,\n",
        "                'final_accuracy': val_acc_final,\n",
        "                'accuracy_retention': accuracy_retention,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'pruned_params': pruned_params,\n",
        "                'model': pruned_model,  # ‚úÖ Sauvegarder le mod√®le\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "            # Garder le meilleur mod√®le\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_model = pruned_model\n",
        "                print(f\"    üèÜ Nouveau meilleur mod√®le! (score: {score:.2f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            print(f\"Erreur: {e}\")\n",
        "            traceback.print_exc()\n",
        "            print()\n",
        "\n",
        "    # R√©sum√©\n",
        "    if results:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"R√âSUM√â DES R√âSULTATS\")\n",
        "        print(\"=\"*60)\n",
        "        for r in results:\n",
        "            marker = \"üèÜ\" if r['model'] == best_model else \"  \"\n",
        "            print(f\"{marker} Keep {r['keep_ratio']*100:.0f}%: {r['actual_reduction']:.1f}% r√©duction, \"\n",
        "                  f\"{r['accuracy_retention']:.1f}% accuracy, {r['compression_ratio']:.2f}x compression\")\n",
        "\n",
        "    if return_best:\n",
        "        return best_model, results\n",
        "    else:\n",
        "        return results\n",
        "\n",
        "\n",
        "def evaluate_model(model, val_dl, loss_fn):\n",
        "    \"\"\"√âvalue le mod√®le\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            device = next(model.parameters()).device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += x.size(0)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "\n",
        "def fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=5, lr=1e-3):\n",
        "    \"\"\"Fine-tune le mod√®le prun√©\"\"\"\n",
        "    from torch.optim import Adam\n",
        "\n",
        "    device = next(pruned_model.parameters()).device\n",
        "    optimizer = Adam(pruned_model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pruned_model.train()\n",
        "        for x, y in trn_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = pruned_model(x)\n",
        "            loss = loss_fn(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        val_loss, val_acc = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "        if epoch == 0 or (epoch + 1) % 2 == 0:\n",
        "            print(f\"  Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    return pruned_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyvjgo6gajdQ",
        "outputId": "798fec4d-c6ef-47af-a292-f6bb73c17803"
      },
      "outputs": [],
      "source": [
        "model_test = copy.deepcopy(model) \n",
        "pruned_model = test_effective_pruning(model_test,filter_ranking,train_loader, val_loader, loss_fn) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
