{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================================================================\n",
    "# CALCUL DES SCORES POUR CHAQUE MÉTHODE\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_magnitude_ranking(model):\n",
    "    \"\"\"\n",
    "    Pruning par magnitude (L1 norm) - baseline classique\n",
    "    Les filtres avec petite norme L1 sont considérés moins importants\n",
    "    \"\"\"\n",
    "    print(\"Calcul du ranking par magnitude L1...\")\n",
    "    filter_ranking = {}\n",
    "    conv_layers = [m for m in model.modules() if isinstance(m, nn.Conv2d)]\n",
    "\n",
    "    for m_idx, conv_layer in enumerate(conv_layers):\n",
    "        filter_ranking[m_idx] = {}\n",
    "        out_channels, in_channels = conv_layer.weight.shape[:2]\n",
    "\n",
    "        for oc in range(out_channels):\n",
    "            filter_ranking[m_idx][oc] = {}\n",
    "            for ic in range(in_channels):\n",
    "                weight = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
    "                # Score = norme L1 (somme des valeurs absolues)\n",
    "                score = np.abs(weight).sum()\n",
    "                filter_ranking[m_idx][oc][ic] = score\n",
    "\n",
    "    return filter_ranking\n",
    "\n",
    "\n",
    "def calculate_l2_magnitude_ranking(model):\n",
    "    \"\"\"\n",
    "    Pruning par magnitude L2 (norme euclidienne)\n",
    "    Variante du pruning par magnitude\n",
    "    \"\"\"\n",
    "    print(\"Calcul du ranking par magnitude L2...\")\n",
    "    filter_ranking = {}\n",
    "    conv_layers = [m for m in model.modules() if isinstance(m, nn.Conv2d)]\n",
    "\n",
    "    for m_idx, conv_layer in enumerate(conv_layers):\n",
    "        filter_ranking[m_idx] = {}\n",
    "        out_channels, in_channels = conv_layer.weight.shape[:2]\n",
    "\n",
    "        for oc in range(out_channels):\n",
    "            filter_ranking[m_idx][oc] = {}\n",
    "            for ic in range(in_channels):\n",
    "                weight = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
    "                # Score = norme L2\n",
    "                score = np.sqrt(np.sum(weight**2))\n",
    "                filter_ranking[m_idx][oc][ic] = score\n",
    "\n",
    "    return filter_ranking\n",
    "\n",
    "\n",
    "def calculate_variance_ranking(model):\n",
    "    \"\"\"\n",
    "    Pruning par variance\n",
    "    Les filtres avec faible variance sont considérés moins informatifs\n",
    "    \"\"\"\n",
    "    print(\"Calcul du ranking par variance...\")\n",
    "    filter_ranking = {}\n",
    "    conv_layers = [m for m in model.modules() if isinstance(m, nn.Conv2d)]\n",
    "\n",
    "    for m_idx, conv_layer in enumerate(conv_layers):\n",
    "        filter_ranking[m_idx] = {}\n",
    "        out_channels, in_channels = conv_layer.weight.shape[:2]\n",
    "\n",
    "        for oc in range(out_channels):\n",
    "            filter_ranking[m_idx][oc] = {}\n",
    "            for ic in range(in_channels):\n",
    "                weight = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
    "                # Score = variance des poids\n",
    "                score = np.var(weight)\n",
    "                filter_ranking[m_idx][oc][ic] = score\n",
    "\n",
    "    return filter_ranking\n",
    "\n",
    "\n",
    "def calculate_random_ranking(model, seed=42):\n",
    "    \"\"\"\n",
    "    Pruning aléatoire - baseline pour vérifier que les autres méthodes\n",
    "    font mieux que le hasard\n",
    "    \"\"\"\n",
    "    print(\"Calcul du ranking aléatoire...\")\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    filter_ranking = {}\n",
    "    conv_layers = [m for m in model.modules() if isinstance(m, nn.Conv2d)]\n",
    "\n",
    "    for m_idx, conv_layer in enumerate(conv_layers):\n",
    "        filter_ranking[m_idx] = {}\n",
    "        out_channels, in_channels = conv_layer.weight.shape[:2]\n",
    "\n",
    "        for oc in range(out_channels):\n",
    "            filter_ranking[m_idx][oc] = {}\n",
    "            for ic in range(in_channels):\n",
    "                # Score aléatoire entre 0 et 1\n",
    "                score = np.random.random()\n",
    "                filter_ranking[m_idx][oc][ic] = score\n",
    "\n",
    "    return filter_ranking\n",
    "\n",
    "\n",
    "def calculate_entropy_ranking(model):\n",
    "    \"\"\"\n",
    "    Pruning par entropie - mesure de la distribution des poids\n",
    "    Filtres avec faible entropie (poids similaires) sont moins informatifs\n",
    "    \"\"\"\n",
    "    print(\"Calcul du ranking par entropie...\")\n",
    "    filter_ranking = {}\n",
    "    conv_layers = [m for m in model.modules() if isinstance(m, nn.Conv2d)]\n",
    "\n",
    "    for m_idx, conv_layer in enumerate(conv_layers):\n",
    "        filter_ranking[m_idx] = {}\n",
    "        out_channels, in_channels = conv_layer.weight.shape[:2]\n",
    "\n",
    "        for oc in range(out_channels):\n",
    "            filter_ranking[m_idx][oc] = {}\n",
    "            for ic in range(in_channels):\n",
    "                weight = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
    "\n",
    "                # Normaliser pour avoir une distribution\n",
    "                weight_abs = np.abs(weight.flatten())\n",
    "                weight_norm = weight_abs / (weight_abs.sum() + 1e-10)\n",
    "\n",
    "                # Calculer l'entropie\n",
    "                entropy = -np.sum(weight_norm * np.log(weight_norm + 1e-10))\n",
    "                filter_ranking[m_idx][oc][ic] = entropy\n",
    "\n",
    "    return filter_ranking\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION DE COMPARAISON GLOBALE\n",
    "# ============================================================================\n",
    "\n",
    "def compare_pruning_methods(model, trn_dl, val_dl, loss_fn,\n",
    "                            filter_ranking_topological=None,\n",
    "                            keep_ratios=[0.8, 0.6, 0.4, 0.2],\n",
    "                            fine_tune_epochs=5):\n",
    "    \"\"\"\n",
    "    Compare différentes méthodes de pruning\n",
    "\n",
    "    Args:\n",
    "        model: modèle PyTorch entraîné\n",
    "        trn_dl, val_dl: dataloaders train/validation\n",
    "        loss_fn: fonction de perte\n",
    "        filter_ranking_topological: votre ranking topologique (optionnel)\n",
    "        keep_ratios: ratios de filtres à conserver\n",
    "        fine_tune_epochs: nombre d'époques de fine-tuning\n",
    "\n",
    "    Returns:\n",
    "        dict avec résultats pour chaque méthode\n",
    "    \"\"\"\n",
    "\n",
    "    # Baseline : performance du modèle original\n",
    "    print(\"=\"*80)\n",
    "    print(\"ÉVALUATION DU MODÈLE ORIGINAL\")\n",
    "    print(\"=\"*80)\n",
    "    orig_params = sum(p.numel() for p in model.parameters())\n",
    "    orig_loss, orig_acc = evaluate_model(model, val_dl, loss_fn)\n",
    "    print(f\"Accuracy: {orig_acc:.4f}\")\n",
    "    print(f\"Paramètres: {orig_params:,}\\n\")\n",
    "\n",
    "    # Définir les méthodes à tester\n",
    "    methods = {\n",
    "        'L1 Magnitude': calculate_magnitude_ranking,\n",
    "        'L2 Magnitude': calculate_l2_magnitude_ranking,\n",
    "        'Variance': calculate_variance_ranking,\n",
    "        'Entropy': calculate_entropy_ranking,\n",
    "        'Random': calculate_random_ranking,\n",
    "    }\n",
    "\n",
    "    if filter_ranking_topological is not None:\n",
    "        methods['Topological (Sobolev)'] = lambda m: filter_ranking_topological\n",
    "\n",
    "    # Stocker tous les résultats\n",
    "    all_results = {}\n",
    "\n",
    "    # Tester chaque méthode\n",
    "    for method_name, ranking_function in methods.items():\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"MÉTHODE: {method_name}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        try:\n",
    "            # Calculer le ranking (sauf si déjà fourni)\n",
    "            if method_name == 'Topological (Sobolev)' and filter_ranking_topological is not None:\n",
    "                ranking = filter_ranking_topological\n",
    "            else:\n",
    "                ranking = ranking_function(copy.deepcopy(model))\n",
    "\n",
    "            # Tester le pruning avec cette méthode\n",
    "            model_copy = copy.deepcopy(model)\n",
    "            results = test_effective_pruning(\n",
    "                model_copy,\n",
    "                ranking,\n",
    "                trn_dl,\n",
    "                val_dl,\n",
    "                loss_fn,\n",
    "                keep_ratios=keep_ratios\n",
    "            )\n",
    "\n",
    "            all_results[method_name] = results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur avec {method_name}: {e}\")\n",
    "            all_results[method_name] = None\n",
    "\n",
    "    # ========================================================================\n",
    "    # TABLEAU COMPARATIF FINAL\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TABLEAU COMPARATIF - RETENTION D'ACCURACY (%)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Header\n",
    "    header = \"Méthode\".ljust(25)\n",
    "    for ratio in keep_ratios:\n",
    "        header += f\"Keep {int(ratio*100)}%\".rjust(12)\n",
    "    print(header)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    # Lignes pour chaque méthode\n",
    "    for method_name in methods.keys():\n",
    "        if all_results[method_name] is None:\n",
    "            continue\n",
    "\n",
    "        line = method_name.ljust(25)\n",
    "        for ratio in keep_ratios:\n",
    "            result = [r for r in all_results[method_name] if r['keep_ratio'] == ratio]\n",
    "            if result:\n",
    "                acc_ret = result[0]['accuracy_retention']\n",
    "                line += f\"{acc_ret:10.1f}%\".rjust(12)\n",
    "            else:\n",
    "                line += \"N/A\".rjust(12)\n",
    "        print(line)\n",
    "\n",
    "    # ========================================================================\n",
    "    # GRAPHIQUE DE COMPARAISON\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSE PAR RATIO DE COMPRESSION\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for ratio in keep_ratios:\n",
    "        print(f\"\\n--- Keep {int(ratio*100)}% des filtres ---\")\n",
    "\n",
    "        results_at_ratio = []\n",
    "        for method_name in methods.keys():\n",
    "            if all_results[method_name] is None:\n",
    "                continue\n",
    "            result = [r for r in all_results[method_name] if r['keep_ratio'] == ratio]\n",
    "            if result:\n",
    "                results_at_ratio.append({\n",
    "                    'method': method_name,\n",
    "                    'acc_retention': result[0]['accuracy_retention'],\n",
    "                    'compression': result[0]['compression_ratio']\n",
    "                })\n",
    "\n",
    "        # Trier par accuracy retention\n",
    "        results_at_ratio.sort(key=lambda x: x['acc_retention'], reverse=True)\n",
    "\n",
    "        for i, res in enumerate(results_at_ratio):\n",
    "            rank = \"🥇\" if i == 0 else \"🥈\" if i == 1 else \"🥉\" if i == 2 else f\"{i+1}.\"\n",
    "            print(f\"{rank} {res['method']:25s}: {res['acc_retention']:5.1f}% \"\n",
    "                  f\"(compression {res['compression']:.1f}x)\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # STATISTIQUES GLOBALES\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STATISTIQUES GLOBALES\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for method_name in methods.keys():\n",
    "        if all_results[method_name] is None:\n",
    "            continue\n",
    "\n",
    "        accs = [r['accuracy_retention'] for r in all_results[method_name]]\n",
    "        print(f\"\\n{method_name}:\")\n",
    "        print(f\"  Moyenne: {np.mean(accs):.1f}%\")\n",
    "        print(f\"  Min: {np.min(accs):.1f}%\")\n",
    "        print(f\"  Max: {np.max(accs):.1f}%\")\n",
    "        print(f\"  Écart-type: {np.std(accs):.1f}%\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FONCTION HELPER POUR ÉVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(model, val_dl, loss_fn):\n",
    "    \"\"\"Évalue le modèle sur le dataset de validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
    "            total_correct += (pred.argmax(1) == y).sum().item()\n",
    "            total_samples += x.size(0)\n",
    "\n",
    "    return total_loss / total_samples, total_correct / total_samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = compare_pruning_methods(\n",
    "        model=model,\n",
    "        trn_dl=train_loader,\n",
    "        val_dl=val_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        keep_ratios=[0.8, 0.6, 0.4, 0.2],\n",
    "        fine_tune_epochs=5\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
