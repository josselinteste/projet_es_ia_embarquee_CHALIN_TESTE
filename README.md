# D√©ploiement d‚Äôun mod√®le DNN pr√©entra√Æn√© sur le dataset CIFAR-10 pour microcontr√¥leur

Ce projet √©tudie le **d√©ploiement d‚Äôun mod√®le de classification** sur une cible embarqu√©e **STM32**.  

---

# üß© Sommaire 

## ‚öôÔ∏è Partie 1 ‚Äî D√©ploiement sur microcontr√¥leur

La seconde partie porte sur le **d√©ploiement du mod√®le con√ßu** sur la cible **STM32**.

### Contenu :
- **Fichiers d'analyse** des diff√©rents mod√®les obtenus gr√¢ce √† STM32-CUBE-AI dans le dossier **`Analyse mod√®le de base`**
- **Fichiers de d√©ploiement** pour le microcontr√¥leur ;  
- **Mod√®le converti** et pr√™t √† √™tre int√©gr√© sur la plateforme embarqu√©e.

---

## üß† Partie 2 ‚Äî Conception du mod√®le

Cette premi√®re partie concerne la **conception et l‚Äôoptimisation** du mod√®le via :
- l‚Äô√©laboration d‚Äôune **m√©thode de pruning**,  
- la **s√©lection d‚Äôune architecture personnalis√©e**,  
- et l‚Äô**√©valuation** de cette derni√®re sur le dataset **CIFAR-10**.

### Contenu :
- **`Pruning.pdf`** ‚Äî rapport d√©taillant la m√©thode de pruning et les choix d‚Äôarchitecture du nouveau mod√®le ;  (dossier *Pruning*) 
- **`pruning_modele.ipynb`** ‚Äî d√©monstration pratique de la m√©thode de pruning appliqu√©e au mod√®le. (dossier *Pruning*) 
- **`entrainement_evaluation.ipynb`** - code d'entrainement et d'√©valuation du mod√®le. 
- **`outils.ipynb`** - Ensemble de fonctions, pour la plupart absentes des autres notebooks, mais qui nous ont permis d‚Äôexplorer la m√©thode de **pruning** et son √©valuation.
- **`resultats_pruning.xlxs`** Tableau r√©capitulatif de l'ensemble des r√©sultats obtenus pour les diff√©rentes m√©thodes de pruning (dossier *Pruning*) 
- **`resultats_pruning_bruts.txt`** Document enregistrants l'ensemble des r√©sultats brutes pour les diff√©rentes m√©thodes de pruning (dossier *Pruning*) 
---


## üí£ Partie 3 - Attaque du mod√®le 

Cette troisi√®me partie porte sur l'attaque du mod√®le d√©ploy√© sur le microcontr√¥leur. 
### Contenu : 
üìÅ Structure du dossier
üîπ Racine

**`run_bfa_attack.py`**
Script principal ex√©cutant l‚Äôattaque BFA sur le mod√®le de base.
Contient les fonctions d‚Äôinitialisation, de gestion des poids, et de lancement de l‚Äôattaque.

**`run_bfa_pruned.py`**
Variante de l‚Äôattaque appliqu√©e sur le mod√®le d√©j√† prun√©.

**`run_bfa_attack_error.log`**
Fichier de log regroupant les erreurs et √©v√©nements rencontr√©s lors des ex√©cutions.

**`bfa_attack_vs_random.png`**
Graphique comparant les performances du mod√®le apr√®s attaque BFA et apr√®s attaque al√©atoire.

**`weights.pth`**
Poids initiaux du mod√®le avant toute attaque.

**`weights_attacked.pth`**
Poids du mod√®le apr√®s l‚Äôapplication de l‚Äôattaque BFA.

**`pruned_model.pth`**
Version all√©g√©e (apr√®s pruning) du mod√®le utilis√©e dans certains tests.

üîπ Dossier attack/

Contient les modules li√©s √† la mise en ≈ìuvre des attaques :

**`BFA.py`**
Impl√©mentation de la Bit-Flip Attack, permettant de cibler des bits sp√©cifiques dans les poids du mod√®le pour maximiser la d√©gradation des performances.

**`random_attack.py`**
Attaque de r√©f√©rence : applique des flips al√©atoires sur les bits des poids du mod√®le pour comparaison.

**`data_conversion.py`**
Outils de manipulation et de conversion des poids (float ‚Üî binaire) pour permettre l‚Äôinjection de fautes au niveau bit.

üìä R√©sultats et visualisations

Le graphique **`bfa_attack_vs_random.png`** illustre la diff√©rence d‚Äôimpact entre une attaque al√©atoire (Random) et une attaque dirig√©e (BFA), ciblant les bits les plus sensibles.

---

# üìñ Documentation

## Analyse du mod√®le existant


Cette analyse pr√©sente l'architecture VG11 modifi√©e et optimis√©e pour la classification d'images CIFAR-10. L'architecture VGG, introduite par Simonyan et Zisserman en 2014, utilise r√©seaux profonds avec exclusivement des filtres de convolutions de petite taille (3√ó3), principe qui est conserv√© dans cette adaptation.

### Caract√©ristiques principales

- **8 couches convolutionnelles** organis√©es en 6 blocs distincts qui extraient progressivement des features de plus en plus abstraites
- **Classificateur dense** √† 3 couches qui transforme les features extraites en pr√©dictions de classes
- **~1.34 millions de param√®tres** (optimis√© pour CIFAR-10, bien inf√©rieur aux 132M du VGG-11 original)
- **R√©gularisation moderne** : BatchNormalization pour la stabilit√© et SpatialDropout2D pour la robustesse



## üèóÔ∏è Architecture

### Philosophie de conception

L'architecture s'inspire du paradigme VGG classique avec des am√©liorations modernes adapt√©es aux d√©fis sp√©cifiques du dataset CIFAR-10 :

- **Filtres uniformes** : Noyaux 3√ó3 exclusivement, permettant un empilement profond avec un nombre de param√®tres r√©duit
- **Profondeur contr√¥l√©e** : 8 couches convolutionnelles, un compromis entre la capacit√© d'apprentissage et le risque de sur-apprentissage
- **R√©gularisation** : BatchNorm apr√®s chaque activation et SpatialDropout2D dans les blocs strat√©giques
- **Adaptation** : Optimis√©e pour images 32√ó32 pixels avec un nombre de filtres maximal de 128 (vs 512 dans VGG original)

### Structure hi√©rarchique

Le mod√®le suit une structure pyramidale √† 4 niveaux o√π les dimensions spatiales diminuent progressivement tandis que la profondeur des canaux augmente. Cette approche classique permet de capturer d'abord des d√©tails fins avec une haute r√©solution, puis des concepts de plus en plus abstraits :

1. **Bloc 1** : Extraction des caract√©ristiques de bas niveau (32 filtres) - d√©tection des contours, transitions de couleurs
2. **Bloc 2** : Consolidation des motifs √©l√©mentaires (32 filtres) avec premi√®re r√©duction spatiale
3. **Bloc 3** : Capture des motifs interm√©diaires (64 filtres) - textures, formes g√©om√©triques simples
4. **Bloc 4** : Approfondissement des features interm√©diaires (64 filtres) avec deuxi√®me r√©duction spatiale
5. **Bloc 5** : Extraction des caract√©ristiques de haut niveau (128 filtres) - parties d'objets, motifs complexes
6. **Bloc 6** : Raffinement final (128 filtres) avec r√©solution spatiale minimale



## üìä D√©tails de l'architecture

### Progression des caract√©ristiques

Le tableau ci-dessous montre l'√©volution des dimensions et de la complexit√© √† travers le r√©seau. On observe que le volume d'information cro√Æt initialement, puis d√©cro√Æt progressivement gr√¢ce aux op√©rations de max pooling :

| Bloc | Canaux entr√©e | Canaux sortie | Dimension spatiale | Volume total |
|------|---------------|---------------|--------------------|--------------| 
| 1 | 3 | 32 | 32√ó32 | 32,768 valeurs |
| 2 | 32 | 32 | 32√ó32 ‚Üí 16√ó16 | 8,192 valeurs |
| 3 | 32 | 64 | 16√ó16 | 16,384 valeurs |
| 4 | 64 | 64 | 16√ó16 ‚Üí 8√ó8 | 4,096 valeurs |
| 5 | 64 | 128 | 8√ó8 ‚Üí 4√ó4 | 2,048 valeurs |
| 6 | 128 | 128 | 4√ó4 ‚Üí 2√ó2 | 512 valeurs |

La progression montre une compensation intelligente : quand la r√©solution spatiale diminue de moiti√©, le nombre de canaux double, maintenant ainsi la capacit√© repr√©sentationnelle du r√©seau.

### Classificateur dense

Le classificateur adopte une architecture en pyramide invers√©e, contrastant avec la structure en entonnoir de la partie convolutionnelle. Cette expansion puis contraction permet de combiner richement les features extraites :

- **Flatten** : 512 dimensions (128 √ó 2 √ó 2), transformation du tenseur 3D en vecteur 1D
- **Dense 1** : 512 ‚Üí 1024 (ReLU + Dropout 0.3) - expansion pour cr√©er un espace de combinaisons riche
- **Dense 2** : 1024 ‚Üí 512 (ReLU + Dropout 0.3) - synth√®se et compression de l'information discriminante
- **Sortie** : 512 ‚Üí 10 (Softmax) - projection vers les 10 classes avec distribution de probabilit√©



## üîß Innovations architecturales

### BatchNormalization strat√©gique

Int√©gr√©e apr√®s chaque activation ReLU dans tous les blocs convolutionnels, la BatchNormalization normalise la distribution des activations en ajustant leur moyenne √† 0 et leur variance √† 1. Cette technique apporte plusieurs b√©n√©fices mesurables :

- **Stabiliser** la variance interne des activations, r√©duisant le ph√©nom√®ne d'Internal Covariate Shift
- **Acc√©l√©rer** la convergence durant l'entra√Ænement en permettant des learning rates plus √©lev√©s
- **R√©gulariser** implicitement le mod√®le gr√¢ce au bruit introduit par les statistiques de batch
- **Renforcer** la robustesse √† l'initialisation des poids, facilitant l'exp√©rimentation

La formule math√©matique appliqu√©e est : `xÃÇ = (x - Œº_batch) / ‚àö(œÉ¬≤_batch + Œµ)` suivie de `y = Œ≥ * xÃÇ + Œ≤`, o√π Œ≥ et Œ≤ sont des param√®tres apprenables qui permettent au r√©seau de retrouver la distribution originale si n√©cessaire.

### SpatialDropout2D

Am√©lioration significative par rapport au dropout classique, sp√©cifiquement con√ßue pour les architectures convolutionnelles. Le SpatialDropout2D d√©sactive al√©atoirement des feature maps enti√®res plut√¥t que des neurones individuels :

| Caract√©ristique | Dropout Classique | SpatialDropout2D |
|-----------------|-------------------|------------------|
| Unit√© de suppression | Neurones individuels | **Canaux complets** (25% avec taux 0.25) |
| Pr√©servation spatiale | ‚ùå Non | ‚úÖ Oui - maintient les corr√©lations spatiales |
| Corr√©lations locales | Perturb√©es par le bruit | Maintenues dans chaque feature map |
| Efficacit√© convolutionnelle | Limit√©e | Optimale pour les CNN |

Cette approche est plus efficace car les valeurs au sein d'une m√™me feature map sont fortement corr√©l√©es spatialement (elles proviennent du m√™me filtre). D√©sactiver des pixels al√©atoires ne forcerait pas le r√©seau √† d√©velopper des repr√©sentations robustes, alors que supprimer des canaux entiers oblige le r√©seau √† ne pas d√©pendre excessivement de certaines features sp√©cifiques.

### S√©quence des op√©rations

**S√©quence appliqu√©e** : Conv2D ‚Üí ReLU ‚Üí [SpatialDropout2D] ‚Üí BatchNorm ‚Üí [MaxPool2D]

Cette s√©quence pr√©sente l'avantage de normaliser les activations apr√®s application du dropout, stabilisant ainsi la distribution des donn√©es d'entr√©e de la couche suivante. L'activation ReLU est appliqu√©e avant la normalisation, ce qui permet de normaliser une distribution d√©j√† filtr√©e par la non-lin√©arit√©.



## üìà Distribution des param√®tres

### R√©partition par composant

Le tableau d√©taill√© ci-dessous montre la distribution compl√®te des param√®tres √† travers l'architecture. On observe un d√©s√©quilibre n vers les couches denses qui concentrent la majorit√© des param√®tres :

| Composant | Param√®tres | Pourcentage | Calcul d√©taill√© |
|-----------|------------|-------------|-----------------|
| **Couches Convolutionnelles** | **287,008** | **21.4%** | |
| Conv2D (3‚Üí32) | 896 | 0.07% | 3√ó3√ó3√ó32 + 32 biais |
| Conv2D (32‚Üí32) | 9,248 | 0.69% | 3√ó3√ó32√ó32 + 32 biais |
| Conv2D (32‚Üí64) | 18,496 | 1.38% | 3√ó3√ó32√ó64 + 64 biais |
| Conv2D (64‚Üí64) | 36,928 | 2.75% | 3√ó3√ó64√ó64 + 64 biais |
| Conv2D (64‚Üí128) | 73,856 | 5.50% | 3√ó3√ó64√ó128 + 128 biais |
| Conv2D (128‚Üí128) | 147,584 | 11.0% | 3√ó3√ó128√ó128 + 128 biais |
| **BatchNormalization** | **896** | **0.07%** | |
| BN (32 canaux) √ó 2 | 128 | 0.01% | (Œ≥ + Œ≤) √ó 32 √ó 2 blocs |
| BN (64 canaux) √ó 2 | 256 | 0.02% | (Œ≥ + Œ≤) √ó 64 √ó 2 blocs |
| BN (128 canaux) √ó 2 | 512 | 0.04% | (Œ≥ + Œ≤) √ó 128 √ó 2 blocs |
| **Couches Denses** | **1,055,242** | **78.6%** | |
| Dense (512‚Üí1024) | 525,312 | 39.1% | 512√ó1024 + 1024 biais |
| Dense (1024‚Üí512) | 524,800 | 39.1% | 1024√ó512 + 512 biais |
| Dense (512‚Üí10) | 5,130 | 0.38% | 512√ó10 + 10 biais |
| **TOTAL** | **~1,343,146** | **100%** | |

### Analyse de l'efficacit√©

**Observations critiques** r√©v√©lant les forces et faiblesses de l'architecture :

- **78.6%** des param√®tres concentr√©s dans seulement 3 couches denses du classificateur
- Les deux premi√®res couches denses contiennent √† elles seules plus de 1 million de param√®tres
- Cette concentration peut cr√©er un risque de sur-apprentissage dans le classificateur
- Les couches convolutionnelles ne repr√©sentent que **21.4%** des param√®tres mais effectuent l'essentiel du travail d'extraction de features
- La BatchNormalization ajoute un overhead param√©trique n√©gligeable (0.07%) pour un b√©n√©fice substantiel
- Meilleur √©quilibre que certaines architectures CNN basiques o√π les couches denses peuvent repr√©senter >90% des param√®tres



## ‚ö†Ô∏è Limitations et d√©fis

### Limitations architecturales

Malgr√© ses qualit√©s, l'architecture pr√©sente plusieurs limitations inh√©rentes √† sa conception s√©quentielle pure :

- **Absence de skip connections** : Contrairement aux architectures ResNet qui utilisent des connexions r√©siduelles, ce mod√®le peut souffrir de probl√®mes de gradient dans les couches profondes
- **Pooling agressif** : Quatre op√©rations de max pooling r√©duisent l'image de 32√ó32 √† 2√ó2, entra√Ænant une perte potentielle d'information spatiale fine qui pourrait √™tre discriminante
- **Architecture s√©quentielle** : Pas de parall√©lisation des branches comme dans Inception, limitant la diversit√© des features √† chaque niveau
- **Classificateur dense dominant** : 78.6% des param√®tres concentr√©s dans 3 couches denses peut cr√©er un goulot d'√©tranglement et un risque de sur-apprentissage localis√©

### D√©fis computationnels

Plusieurs aspects de l'architecture posent des probl√®mes  pratiques lors de l'entra√Ænement et du d√©ploiement :

- **M√©moire** : Les feature maps volumineuses des premi√®res couches (32√ó32√ó32) n√©cessitent une m√©moire GPU substantielle, surtout avec des batchs de grande taille
- **BatchNorm** : D√©pendance √† la taille du batch pour des statistiques fiables ; performance peut se d√©grader avec des batchs tr√®s petits (<16)
- **R√©gularisation** : √âquilibrage d√©licat entre dropout et BatchNorm n√©cessaire ; trop de r√©gularisation peut sous-fitter, pas assez peut sur-fitter
- **Temps d'inf√©rence** : Les couches denses massives ralentissent l'inf√©rence compar√© √† des architectures plus modernes avec Global Average Pooling


## üìö Conclusion

Ce mod√®le repr√©sente une **adaptation moderne et r√©ussie** du paradigme VGG pour CIFAR-10, avec plusieurs points forts identifi√©s :

‚úÖ **Architecture √©prouv√©e et stable** - Bas√©e sur VGG, une architecture qui a fait ses preuves depuis 2014  
‚úÖ **R√©gularisation multi-niveaux efficace** - Combinaison de SpatialDropout2D, BatchNorm et Dropout classique  
‚úÖ **Complexit√© param√©trique raisonnable** - 1.34M param√®tres offre un bon compromis capacit√©/g√©n√©ralisation  
‚úÖ **Performance √©lev√©** - 84% d'accuracy sur CIFAR-10  
 

---

# üìò D√©ploiement d‚Äôun mod√®le CIFAR-10 sur STM32L4R9AII6

---

## √âtude du microcontr√¥leur cible

Pour ce projet de d√©ploiement d‚Äôun mod√®le de r√©seau de neurones pr√©entra√Æn√© sur le jeu de donn√©es CIFAR-10, le choix du microcontr√¥leur joue un r√¥le essentiel. L‚Äôobjectif est d‚Äôobtenir une plateforme capable d‚Äôex√©cuter un mod√®le de classification d‚Äôimages tout en respectant les contraintes propres aux syst√®mes embarqu√©s, notamment en termes de m√©moire, de puissance de calcul et de consommation √©nerg√©tique.

Le microcontr√¥leur **STM32L4R9AII6**, bas√© sur un c≈ìur **ARM¬Æ Cortex¬Æ-M4**, a √©t√© retenu pour sa polyvalence et ses performances adapt√©es aux applications d‚Äôintelligence artificielle l√©g√®re.
Il dispose de **2 MiB de m√©moire Flash** et **192 KiB de RAM**, ce qui permet de stocker et d‚Äôex√©cuter des mod√®les de taille mod√©r√©e, surtout apr√®s quantification.

La carte int√®gre √©galement plusieurs p√©riph√©riques utiles au projet, tels qu‚Äôun **√©cran AMOLED tactile**, un **port microSD‚Ñ¢**, un **connecteur USB OTG**, ainsi qu‚Äôun **module de d√©bogage ST-LINK/V2-1** facilitant la programmation et l‚Äôanalyse des performances.

Cette plateforme offre une bonne base pour exp√©rimenter le d√©ploiement de mod√®les de vision embarqu√©e, gr√¢ce √† la compatibilit√© avec les outils logiciels de la suite **STM32Cube.AI**. Cet environnement permet de convertir et d‚Äôoptimiser le mod√®le afin de l‚Äôadapter aux ressources limit√©es du microcontr√¥leur, tout en conservant des performances acceptables.

---

## √âvaluation de l‚Äôembarquabilit√© du mod√®le initial

L‚Äô√©tape suivante du projet consiste √† √©valuer la possibilit√© d‚Äôex√©cuter le mod√®le de r√©seau de neurones initial sur le microcontr√¥leur choisi, en tenant compte des contraintes mat√©rielles de la carte STM32L4R9AII6.
Cette analyse vise √† d√©terminer si le mod√®le peut √™tre d√©ploy√© tel quel, ou s‚Äôil n√©cessite une adaptation pour respecter les limites de m√©moire, de puissance de calcul et de temps d‚Äôinf√©rence du syst√®me embarqu√©.

Pour cela, l‚Äôoutil **STM32Cube.AI** a √©t√© utilis√© afin de convertir le mod√®le pr√©entra√Æn√© (au format TensorFlow) en un format compatible avec la famille STM32.
Cet outil permet √©galement d‚Äôobtenir des estimations pr√©cises concernant la taille du mod√®le, la m√©moire RAM requise pour l‚Äôinf√©rence, le type d‚Äôop√©rations arithm√©tiques utilis√©es, ainsi que le nombre total d‚Äôop√©rations n√©cessaires √† l‚Äôex√©cution (en millions de multiplications-accumulations, ou **MACC**).

Dans un premier temps, le mod√®le a √©t√© analys√© sans compression, puis avec les trois niveaux de compression propos√©s par STM32Cube.AI : **Low**, **Medium** et **High**.
Ces niveaux reposent sur des techniques de quantification et de r√©duction de poids, permettant de r√©duire la taille m√©moire et le co√ªt de calcul, au prix d‚Äôune √©ventuelle perte de pr√©cision.

### R√©sultats des analyses

| Niveau de compression | Taille totale (Flash) | Poids (Weights) | M√©moire RAM totale | Nombre d‚Äôop√©rations (MACC) |           Type d‚Äôop√©rations principales | Observation                                  |
| --------------------: | --------------------: | --------------: | -----------------: | -------------------------: | --------------------------------------: | -------------------------------------------- |
|     **Aucune (None)** |               5,37 Mo |         5,12 Mo |           143,8 Ko |                   32,998 M |          96,5 % smul_f32_f32 (float 32) | Mod√®le trop volumineux pour la carte         |
|      **Faible (Low)** |               3,45 Mo |         3,33 Mo |           146,2 Ko |                   32,998 M |        Majorit√© d‚Äôop√©rations en float32 | Encore trop lourd pour la m√©moire Flash      |
|  **Moyenne (Medium)** |               1,72 Mo |         1,62 Mo |           152,1 Ko |                   32,998 M |  96,5 % smul_f32_f32, 3,2 % smul_f32_f4 | Compatible avec les ressources de la carte   |
|      **Forte (High)** |               1,27 Mo |         1,20 Mo |           147,4 Ko |                   32,998 M | Op√©rations fortement quantifi√©es (int8) | D√©ployable mais risque de perte de pr√©cision |

L‚Äôanalyse montre que le mod√®le non compress√© d√©passe largement les capacit√©s m√©moire de la carte STM32L4R9AII6, emp√™chant son ex√©cution directe. M√™me avec une compression faible, la taille du mod√®le reste sup√©rieure √† la limite de m√©moire Flash embarqu√©e.
Ce n‚Äôest qu‚Äô√† partir du niveau de compression moyen que le mod√®le devient compatible avec les **640 Ko de RAM** et la **m√©moire Flash de 2 Mo** de la carte.

Concernant le temps d‚Äôinf√©rence, l‚Äôanalyse du mod√®le indique environ **33 millions d‚Äôop√©rations (MACC)**, principalement des multiplications flottantes (**smul_f32_f32**).
Ce volume reste cons√©quent pour un microcontr√¥leur Cortex-M4 √† 120 MHz, mais **g√©rable apr√®s quantification et optimisation via CMSIS-NN**.
Le temps d‚Äôinf√©rence estim√© reste compatible avec une ex√©cution locale, mais trop √©lev√© pour du temps r√©el sans optimisation suppl√©mentaire.

Ainsi, le d√©ploiement sur STM32L4R9AII6 n‚Äôest pas possible tel quel : **le mod√®le initial est trop volumineux**.
Une **compression interm√©diaire (Medium)** est n√©cessaire pour rendre l‚Äôapplication r√©alisable.

---

## Conception du nouveau mod√®le

Voir partie *Conception du mod√®le* et l‚Äô√©tude associ√©e.

---

## Embarquabilit√© du mod√®le final et √©valuation

### Int√©gration dans un projet embarqu√©

#### ‚Ä¢ Mise en ≈ìuvre dans un environnement adapt√© (STM32CubeIDE, Arduino IDE, etc.)

L‚Äôenvironnement choisi pour l‚Äôint√©gration est **STM32CubeIDE** associ√© √† l‚Äôextension **X-CUBE-AI**.
Apr√®s avoir export√© le mod√®le entra√Æn√© (au format ONNX), X-CUBE-AI a g√©n√©r√© le code C n√©cessaire pour ex√©cuter le r√©seau sur la MCU.

X-CUBE-AI nous a aussi permis de valider l‚Äôembarquabilit√© de notre mod√®le, gr√¢ce √† l‚Äôinterface propos√©e dans le logiciel :

![Analyse du mod√®le final sur STM32](Image/analyse_modele_final_stm32.jpg)

On observe que le mod√®le respecte bien les limites mat√©rielles de la carte, avec une marge suffisante pour d‚Äôautres t√¢ches.

Le projet **CubeMX/STM32CubeIDE** a ensuite √©t√© utilis√© pour activer et configurer les p√©riph√©riques indispensables (UART, horloge, gestion m√©moire).
L‚Äôinitialisation du mod√®le est r√©alis√©e au d√©marrage par la fonction fournie par X-CUBE-AI, ce qui permet d‚Äôallouer les activations et de lier proprement les buffers d‚Äôentr√©e et de sortie au reste de l‚Äôapplication.

#### ‚Ä¢ Impl√©mentation de l‚Äôinf√©rence et tests avec des images CIFAR-10

L‚Äôimpl√©mentation embarqu√©e se compose de trois √©tapes simples :

1. Recevoir les donn√©es.
2. Lancer l‚Äôinf√©rence.
3. Renvoyer les r√©sultats.

Pour la communication, un **protocole UART** √©l√©mentaire garantit la synchronisation avant chaque transfert :
l‚Äôh√¥te envoie un octet de synchronisation et la cible r√©pond par un accus√©.
Les images pr√©-pr√©trait√©es sont transmises en **float32 little-endian** et r√©ordonn√©es selon le format attendu (CHW).

Sur la STM32, ces floats sont copi√©s dans le buffer d‚Äôentr√©e puis la fonction `ai_cifar10_run` ex√©cute l‚Äôinf√©rence.
Les dix sorties du r√©seau sont ensuite mises √† l‚Äô√©chelle en octets et envoy√©es √† l‚Äôh√¥te.

C√¥t√© PC, un **script Python** envoie les images CIFAR-10 normalis√©es, lit les r√©ponses de la carte et calcule l‚Äôexactitude sur un √©chantillon.
Ce test v√©rifie la coh√©rence du pr√©traitement et d√©tecte rapidement des erreurs courantes (ordre des canaux, √©chelle, etc.).

![R√©sultat de l'accuracy sur la carte STM32](Image/accuracy_sur_carte.jpg)

---

## √âvaluation

###  Analyse des performances sur cible

L‚Äô√©valuation a √©t√© r√©alis√©e sur une cible **STM32L4**, via **ST Edge AI Core v2.2.0** int√©gr√© √† STM32Cube.AI.
Les param√®tres mesur√©s : latence d‚Äôinf√©rence, consommation m√©moire (Flash et RAM), et complexit√© de calcul (**MACC**).

#### Mod√®le compress√© (mod√®le final)

* **Poids totaux** : 148 161 param√®tres (591 932 B ‚âà 578 KiB)
* **Activations dynamiques** : 97 048 B (‚âà 95 KiB)
* **Complexit√© de calcul** : 18,34 M MACC
* **M√©moire Flash totale** : 611 020 B (‚âà 597 KiB)
* **M√©moire RAM totale** : 104 636 B (‚âà 102 KiB)
* **Temps d‚Äôanalyse** : < 25 s sur STM32Cube.AI

Architecture : blocs **Conv2D ‚Äì BatchNorm ‚Äì ReLU ‚Äì Pooling**, suivis d‚Äôun **GlobalAveragePooling** et de deux **Dense**.
Cette organisation compacte permet une ex√©cution fluide sur STM32L4.

#### Mod√®le d‚Äôorigine (non compress√©)

* **Poids totaux** : 1 343 146 (5 372 584 B ‚âà 5,12 MiB)
* **Activations dynamiques** : 143 468 B (‚âà 140 KiB)
* **Complexit√© de calcul** : 32,99 M MACC
* **M√©moire Flash totale** : 5 393 034 B (‚âà 5,14 MiB)
* **M√©moire RAM totale** : 152 124 B (‚âà 148 KiB)

‚û°Ô∏è Taille exc√©dant les capacit√©s m√©moire de la STM32L4.

---

### 8.2 Comparaison avec le mod√®le d‚Äôorigine

| Param√®tre                   | Mod√®le d‚Äôorigine (float32) | Mod√®le final compress√©            | Gain / R√©duction |
| --------------------------- | -------------------------- | --------------------------------- | ---------------- |
| Poids (Flash)               | 5 372 584 B (5,12 MiB)     | 591 932 B (578 KiB)               | ‚Äì 89 %           |
| Activations (RAM)           | 143 468 B (140 KiB)        | 97 048 B (95 KiB)                 | ‚Äì 32 %           |
| Complexit√© (MACC)           | 32 997 984                 | 18 338 190                        | ‚Äì 44 %           |
| M√©moire Flash totale        | 5 393 034 B                | 611 020 B                         | ‚Äì 88,7 %         |
| M√©moire RAM totale          | 152 124 B                  | 104 636 B                         | ‚Äì 31 %           |
| Ex√©cution sur cible STM32L4 | Non compatible             | Compatible et analys√© avec succ√®s |                  |

---

###  Discussion

L‚Äôanalyse met en √©vidence une r√©duction majeure des ressources n√©cessaires gr√¢ce √† l‚Äôoptimisation du mod√®le.
Le passage d‚Äôun mod√®le de 5,1 MiB √† 0,6 MiB permet une int√©gration embarqu√©e sans perte significative de structure ni de pr√©cision.

La compression divise par deux le nombre d‚Äôop√©rations (33 M ‚Üí 18 M MACC), r√©duisant la latence et la consommation √©nerg√©tique.
Le compromis obtenu illustre l‚Äôefficacit√© des techniques d‚Äôoptimisation pour la vision embarqu√©e.

---

### Pr√©cision des mod√®les

* **Mod√®le d‚Äôorigine (non compress√©)** : 84 %
* **Mod√®le final embarqu√© (compress√©)** : 79 %

La perte d‚Äôenviron **5 points** (‚âà 5,95 %) reste mod√©r√©e et acceptable compte tenu des gains consid√©rables :

* Taille du mod√®le : ‚Äì 89 % (5,1 MiB ‚Üí 0,58 MiB)
* Param√®tres : ‚Äì 90 % (1,34 M ‚Üí 148 k)
* Op√©rations : ‚Äì 45 % (33 M ‚Üí 18 M MACC)

Le mod√®le compress√© reste pr√©cis (~ 80 %) et totalement ex√©cutable sur STM32L4, avec un excellent rapport pr√©cision / co√ªt computationnel.

---

## R√©silience aux corruptions binaires ‚Äî attaque Bit-Flip

Dans cette section, nous pr√©sentons une √©valuation exp√©rimentale de la r√©silience du mod√®le embarqu√© face √† des corruptions binaires appliqu√©es directement aux poids ‚Äî commun√©ment appel√©e Bit-Flip Attack (BFA). L‚Äôobjectif n‚Äôest pas d‚Äôexposer l‚Äôimpl√©mentation pas √† pas, mais de d√©crire de mani√®re synth√©tique la m√©thode exp√©rimentale, les indicateurs mesur√©s et les conclusions pratiques que l‚Äôon peut en tirer pour un d√©ploiement embarqu√©.

---

###  Principe g√©n√©ral de l‚Äôattaque

L‚Äôattaque par **inversion de bits (Bit-Flip Attack)** consiste √† modifier la repr√©sentation binaire des poids du r√©seau (dans leur format quantifi√©) en inversant un ou plusieurs bits cibl√©s.
Lorsque ces inversions portent sur des bits critiques, la performance peut chuter rapidement.

La BFA vise √† localiser et inverser les bits ayant le plus fort impact sur la loss, afin d‚Äôobtenir une attaque ¬´ maximale ¬ª en quelques flips seulement.

---

###  Protocole exp√©rimental synth√©tique

* Utilisation du mod√®le compress√© tel que d√©ploy√© sur la carte.
* Mesure de la pr√©cision de r√©f√©rence (avant alt√©ration).
* Application d‚Äôune attaque dirig√©e (BFA) s√©lectionnant les bits les plus impactants.
* Construction d‚Äôun **baseline al√©atoire** (flips al√©atoires pour comparaison).
* √âvaluation via courbes *Accuracy vs # flips* et indicateurs (accuracy apr√®s k flips, etc.).

---

### R√©sultats attendus et interpr√©tation

Deux observations majeures :

1. **Efficacit√© sup√©rieure de la BFA** : une attaque dirig√©e d√©grade beaucoup plus vite la pr√©cision qu‚Äôune corruption al√©atoire.
2. **Vuln√©rabilit√© accrue des mod√®les compact√©s** : la quantification concentre l‚Äôinformation, rendant certains bits critiques.

---

### R√©sultats

![Comparaison BFA vs flips al√©atoires](Image/bfa_attack_vs_random.png)

Apr√®s observation, deux comportements distincts apparaissent :

* **BFA cibl√©e** : pr√©cision chutant de 79 % √† ‚âà 22 % avec 20 flips.
* **Flips al√©atoires** : perte marginale, pr√©cision stable autour de 73‚Äì75 %.

Cette diff√©rence confirme que la **fragilit√© observ√©e provient du ciblage** : la BFA identifie et corrompt les poids les plus critiques, provoquant une d√©gradation rapide.

---

