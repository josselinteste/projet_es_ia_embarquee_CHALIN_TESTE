# D√©ploiement d‚Äôun mod√®le DNN pr√©entra√Æn√© sur le dataset CIFAR-10 pour microcontr√¥leur

Ce projet √©tudie le **d√©ploiement d‚Äôun mod√®le de classification** sur une cible embarqu√©e **STM32**.  

---

# üß© Sommaire 

## üß† Partie 1 ‚Äî Conception du mod√®le

Cette premi√®re partie concerne la **conception et l‚Äôoptimisation** du mod√®le via :
- l‚Äô√©laboration d‚Äôune **m√©thode de pruning**,  
- la **s√©lection d‚Äôune architecture personnalis√©e**,  
- et l‚Äô**√©valuation** de cette derni√®re sur le dataset **CIFAR-10**.

project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ vgg11_cifar10.py
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ analysis.ipynb
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ data_loader.py
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ requirements.txt


### Contenu :
- **`Pruning.pdf`** ‚Äî rapport d√©taillant la m√©thode de pruning et les choix d‚Äôarchitecture du nouveau mod√®le ;  (dossier *Pruning*) 
- **`pruning_modele.ipynb`** ‚Äî d√©monstration pratique de la m√©thode de pruning appliqu√©e au mod√®le. (dossier *Pruning*) 
- **`entrainement_evaluation.ipynb`** - code d'entrainement et d'√©valuation du mod√®le. 
- **`outils.ipynb`** - Ensemble de fonctions, pour la plupart absentes des autres notebooks, mais qui nous ont permis d‚Äôexplorer la m√©thode de **pruning** et son √©valuation.
- **`resultats_pruning.xlxs`** Tableau r√©capitulatif de l'ensemble des r√©sultats obtenus pour les diff√©rentes m√©thodes de pruning (dossier *Pruning*) 
- **`resultats_pruning_bruts.txt`** Document enregistrants l'ensemble des r√©sultats brutes pour les diff√©rentes m√©thodes de pruning (dossier *Pruning*) 
---

## ‚öôÔ∏è Partie 2 ‚Äî D√©ploiement sur microcontr√¥leur

La seconde partie porte sur le **d√©ploiement du mod√®le con√ßu** sur la cible **STM32**.

### Contenu :
- **Fichiers de d√©ploiement** pour le microcontr√¥leur ;  
- **Mod√®le converti** et pr√™t √† √™tre int√©gr√© sur la plateforme embarqu√©e.

---
## üí£ Partie 3 - Attaque du mod√®le 

Cette troisi√®me partie porte sur l'attaque du mod√®le d√©ploy√© sur le microcontr√¥leur. 
### Contenu : 
- xxxxx
- xxxxx

# üìñ Documentation

## Analyse du mod√®le existant


Cette analyse pr√©sente une architecture VGG-11 modifi√©e et optimis√©e pour la classification d'images CIFAR-10. Le mod√®le int√®gre des techniques modernes de r√©gularisation tout en conservant la philosophie architecturale VGG classique. L'architecture VGG, introduite par Simonyan et Zisserman en 2014, a d√©montr√© l'efficacit√© des r√©seaux profonds utilisant exclusivement des filtres de petite taille (3√ó3), principe qui est conserv√© dans cette adaptation.

### Caract√©ristiques principales

- **8 couches convolutionnelles** organis√©es en 6 blocs distincts qui extraient progressivement des features de plus en plus abstraites
- **Classificateur dense** √† 3 couches qui transforme les features extraites en pr√©dictions de classes
- **~1.34 millions de param√®tres** (optimis√© pour CIFAR-10, bien inf√©rieur aux 132M du VGG-11 original)
- **R√©gularisation moderne** : BatchNormalization pour la stabilit√© et SpatialDropout2D pour la robustesse



## üèóÔ∏è Architecture

### Philosophie de conception

L'architecture s'inspire du paradigme VGG classique avec des am√©liorations modernes adapt√©es aux d√©fis sp√©cifiques du dataset CIFAR-10 :

- **Filtres uniformes** : Noyaux 3√ó3 exclusivement, permettant un empilement profond avec un nombre de param√®tres r√©duit
- **Profondeur contr√¥l√©e** : 8 couches convolutionnelles, un compromis entre la capacit√© d'apprentissage et le risque de sur-apprentissage
- **R√©gularisation** : BatchNorm apr√®s chaque activation et SpatialDropout2D dans les blocs strat√©giques
- **Adaptation** : Optimis√©e pour images 32√ó32 pixels avec un nombre de filtres maximal de 128 (vs 512 dans VGG original)

### Structure hi√©rarchique

Le mod√®le suit une structure pyramidale √† 4 niveaux o√π les dimensions spatiales diminuent progressivement tandis que la profondeur des canaux augmente. Cette approche classique permet de capturer d'abord des d√©tails fins avec une haute r√©solution, puis des concepts de plus en plus abstraits :

1. **Bloc 1** : Extraction des caract√©ristiques de bas niveau (32 filtres) - d√©tection des contours, transitions de couleurs
2. **Bloc 2** : Consolidation des motifs √©l√©mentaires (32 filtres) avec premi√®re r√©duction spatiale
3. **Bloc 3** : Capture des motifs interm√©diaires (64 filtres) - textures, formes g√©om√©triques simples
4. **Bloc 4** : Approfondissement des features interm√©diaires (64 filtres) avec deuxi√®me r√©duction spatiale
5. **Bloc 5** : Extraction des caract√©ristiques de haut niveau (128 filtres) - parties d'objets, motifs complexes
6. **Bloc 6** : Raffinement final (128 filtres) avec r√©solution spatiale minimale



## üìä D√©tails de l'architecture

### Progression des caract√©ristiques

Le tableau ci-dessous montre l'√©volution des dimensions et de la complexit√© √† travers le r√©seau. On observe que le volume d'information cro√Æt initialement, puis d√©cro√Æt progressivement gr√¢ce aux op√©rations de max pooling :

| Bloc | Canaux entr√©e | Canaux sortie | Dimension spatiale | Volume total |
|------|---------------|---------------|--------------------|--------------| 
| 1 | 3 | 32 | 32√ó32 | 32,768 valeurs |
| 2 | 32 | 32 | 32√ó32 ‚Üí 16√ó16 | 8,192 valeurs |
| 3 | 32 | 64 | 16√ó16 | 16,384 valeurs |
| 4 | 64 | 64 | 16√ó16 ‚Üí 8√ó8 | 4,096 valeurs |
| 5 | 64 | 128 | 8√ó8 ‚Üí 4√ó4 | 2,048 valeurs |
| 6 | 128 | 128 | 4√ó4 ‚Üí 2√ó2 | 512 valeurs |

La progression montre une compensation intelligente : quand la r√©solution spatiale diminue de moiti√©, le nombre de canaux double, maintenant ainsi la capacit√© repr√©sentationnelle du r√©seau.

### Classificateur dense

Le classificateur adopte une architecture en pyramide invers√©e, contrastant avec la structure en entonnoir de la partie convolutionnelle. Cette expansion puis contraction permet de combiner richement les features extraites :

- **Flatten** : 512 dimensions (128 √ó 2 √ó 2), transformation du tenseur 3D en vecteur 1D
- **Dense 1** : 512 ‚Üí 1024 (ReLU + Dropout 0.3) - expansion pour cr√©er un espace de combinaisons riche
- **Dense 2** : 1024 ‚Üí 512 (ReLU + Dropout 0.3) - synth√®se et compression de l'information discriminante
- **Sortie** : 512 ‚Üí 10 (Softmax) - projection vers les 10 classes avec distribution de probabilit√©



## üîß Innovations architecturales

### BatchNormalization strat√©gique

Int√©gr√©e apr√®s chaque activation ReLU dans tous les blocs convolutionnels, la BatchNormalization normalise la distribution des activations en ajustant leur moyenne √† 0 et leur variance √† 1. Cette technique apporte plusieurs b√©n√©fices mesurables :

- **Stabiliser** la variance interne des activations, r√©duisant le ph√©nom√®ne d'Internal Covariate Shift
- **Acc√©l√©rer** la convergence durant l'entra√Ænement en permettant des learning rates plus √©lev√©s
- **R√©gulariser** implicitement le mod√®le gr√¢ce au bruit introduit par les statistiques de batch
- **Renforcer** la robustesse √† l'initialisation des poids, facilitant l'exp√©rimentation

La formule math√©matique appliqu√©e est : `xÃÇ = (x - Œº_batch) / ‚àö(œÉ¬≤_batch + Œµ)` suivie de `y = Œ≥ * xÃÇ + Œ≤`, o√π Œ≥ et Œ≤ sont des param√®tres apprenables qui permettent au r√©seau de retrouver la distribution originale si n√©cessaire.

### SpatialDropout2D

Am√©lioration significative par rapport au dropout classique, sp√©cifiquement con√ßue pour les architectures convolutionnelles. Le SpatialDropout2D d√©sactive al√©atoirement des feature maps enti√®res plut√¥t que des neurones individuels :

| Caract√©ristique | Dropout Classique | SpatialDropout2D |
|-----------------|-------------------|------------------|
| Unit√© de suppression | Neurones individuels | **Canaux complets** (25% avec taux 0.25) |
| Pr√©servation spatiale | ‚ùå Non | ‚úÖ Oui - maintient les corr√©lations spatiales |
| Corr√©lations locales | Perturb√©es par le bruit | Maintenues dans chaque feature map |
| Efficacit√© convolutionnelle | Limit√©e | Optimale pour les CNN |

Cette approche est plus efficace car les valeurs au sein d'une m√™me feature map sont fortement corr√©l√©es spatialement (elles proviennent du m√™me filtre). D√©sactiver des pixels al√©atoires ne forcerait pas le r√©seau √† d√©velopper des repr√©sentations robustes, alors que supprimer des canaux entiers oblige le r√©seau √† ne pas d√©pendre excessivement de certaines features sp√©cifiques.

### S√©quence des op√©rations

**S√©quence appliqu√©e** : Conv2D ‚Üí ReLU ‚Üí [SpatialDropout2D] ‚Üí BatchNorm ‚Üí [MaxPool2D]

Cette s√©quence pr√©sente l'avantage de normaliser les activations apr√®s application du dropout, stabilisant ainsi la distribution des donn√©es d'entr√©e de la couche suivante. L'activation ReLU est appliqu√©e avant la normalisation, ce qui permet de normaliser une distribution d√©j√† filtr√©e par la non-lin√©arit√©.



## üìà Distribution des param√®tres

### R√©partition par composant

Le tableau d√©taill√© ci-dessous r√©v√®le la distribution compl√®te des param√®tres √† travers l'architecture. On observe un d√©s√©quilibre notable vers les couches denses qui concentrent la majorit√© des param√®tres :

| Composant | Param√®tres | Pourcentage | Calcul d√©taill√© |
|-----------|------------|-------------|-----------------|
| **Couches Convolutionnelles** | **287,008** | **21.4%** | |
| Conv2D (3‚Üí32) | 896 | 0.07% | 3√ó3√ó3√ó32 + 32 biais |
| Conv2D (32‚Üí32) | 9,248 | 0.69% | 3√ó3√ó32√ó32 + 32 biais |
| Conv2D (32‚Üí64) | 18,496 | 1.38% | 3√ó3√ó32√ó64 + 64 biais |
| Conv2D (64‚Üí64) | 36,928 | 2.75% | 3√ó3√ó64√ó64 + 64 biais |
| Conv2D (64‚Üí128) | 73,856 | 5.50% | 3√ó3√ó64√ó128 + 128 biais |
| Conv2D (128‚Üí128) | 147,584 | 11.0% | 3√ó3√ó128√ó128 + 128 biais |
| **BatchNormalization** | **896** | **0.07%** | |
| BN (32 canaux) √ó 2 | 128 | 0.01% | (Œ≥ + Œ≤) √ó 32 √ó 2 blocs |
| BN (64 canaux) √ó 2 | 256 | 0.02% | (Œ≥ + Œ≤) √ó 64 √ó 2 blocs |
| BN (128 canaux) √ó 2 | 512 | 0.04% | (Œ≥ + Œ≤) √ó 128 √ó 2 blocs |
| **Couches Denses** | **1,055,242** | **78.6%** | |
| Dense (512‚Üí1024) | 525,312 | 39.1% | 512√ó1024 + 1024 biais |
| Dense (1024‚Üí512) | 524,800 | 39.1% | 1024√ó512 + 512 biais |
| Dense (512‚Üí10) | 5,130 | 0.38% | 512√ó10 + 10 biais |
| **TOTAL** | **~1,343,146** | **100%** | |

### Analyse de l'efficacit√©

**Observations critiques** r√©v√©lant les forces et faiblesses de l'architecture :

- **78.6%** des param√®tres concentr√©s dans seulement 3 couches denses du classificateur
- Les deux premi√®res couches denses contiennent √† elles seules plus de 1 million de param√®tres
- Cette concentration peut cr√©er un risque de sur-apprentissage dans le classificateur
- Les couches convolutionnelles ne repr√©sentent que **21.4%** des param√®tres mais effectuent l'essentiel du travail d'extraction de features
- La BatchNormalization ajoute un overhead param√©trique n√©gligeable (0.07%) pour un b√©n√©fice substantiel
- Meilleur √©quilibre que certaines architectures CNN basiques o√π les couches denses peuvent repr√©senter >90% des param√®tres



## ‚ö†Ô∏è Limitations et d√©fis

### Limitations architecturales

Malgr√© ses qualit√©s, l'architecture pr√©sente plusieurs limitations inh√©rentes √† sa conception s√©quentielle pure :

- **Absence de skip connections** : Contrairement aux architectures ResNet qui utilisent des connexions r√©siduelles, ce mod√®le peut souffrir de probl√®mes de gradient dans les couches profondes
- **Pooling agressif** : Quatre op√©rations de max pooling r√©duisent l'image de 32√ó32 √† 2√ó2, entra√Ænant une perte potentielle d'information spatiale fine qui pourrait √™tre discriminante
- **Architecture s√©quentielle** : Pas de parall√©lisation des branches comme dans Inception, limitant la diversit√© des features √† chaque niveau
- **Classificateur dense dominant** : 78.6% des param√®tres concentr√©s dans 3 couches denses peut cr√©er un goulot d'√©tranglement et un risque de sur-apprentissage localis√©

### D√©fis computationnels

Plusieurs aspects de l'architecture posent des d√©fis pratiques lors de l'entra√Ænement et du d√©ploiement :

- **M√©moire** : Les feature maps volumineuses des premi√®res couches (32√ó32√ó32) n√©cessitent une m√©moire GPU substantielle, surtout avec des batchs de grande taille
- **BatchNorm** : D√©pendance √† la taille du batch pour des statistiques fiables ; performance peut se d√©grader avec des batchs tr√®s petits (<16)
- **R√©gularisation** : √âquilibrage d√©licat entre dropout et BatchNorm n√©cessaire ; trop de r√©gularisation peut sous-fitter, pas assez peut sur-fitter
- **Temps d'inf√©rence** : Les couches denses massives ralentissent l'inf√©rence compar√© √† des architectures plus modernes avec Global Average Pooling


## üìö Conclusion

### Synth√®se des forces

Ce mod√®le repr√©sente une **adaptation moderne et r√©ussie** du paradigme VGG pour CIFAR-10, avec plusieurs points forts identifi√©s :

‚úÖ **Architecture √©prouv√©e et stable** - Bas√©e sur VGG, une architecture qui a fait ses preuves depuis 2014  
‚úÖ **R√©gularisation multi-niveaux efficace** - Combinaison de SpatialDropout2D, BatchNorm et Dropout classique  
‚úÖ **Complexit√© param√©trique raisonnable** - 1.34M param√®tres offre un bon compromis capacit√©/g√©n√©ralisation  
‚úÖ **Potentiel de performance √©lev√©** - Estimation de ~90% d'accuracy sur CIFAR-10  
‚úÖ **Excellent pour l'apprentissage** - Code simple et maintenable, concepts clairement illustr√©s  

---

## Etude du microcontr√¥leur cible 

Pour ce projet de d√©ploiement d‚Äôun mod√®le de r√©seau de neurones pr√©entra√Æn√© sur le jeu de donn√©es CIFAR-10, le choix du microcontr√¥leur joue un r√¥le essentiel. L‚Äôobjectif est d‚Äôobtenir une plateforme capable d‚Äôex√©cuter un mod√®le de classification d‚Äôimages tout en respectant les contraintes propres aux syst√®mes embarqu√©s, notamment en termes de m√©moire, de puissance de calcul et de consommation √©nerg√©tique.
Le microcontr√¥leur STM32L4R9AII6, bas√© sur un c≈ìur ARM¬Æ Cortex¬Æ-M4, a √©t√© retenu pour sa polyvalence et ses performances adapt√©es aux applications d‚Äôintelligence artificielle l√©g√®re. Il dispose de 2 MiB de m√©moire Flash et 192 KiB  de RAM, ce qui permet de stocker et d‚Äôex√©cuter des mod√®les de taille mod√©r√©e, surtout apr√®s quantification. La carte int√®gre √©galement plusieurs p√©riph√©riques utiles au projet, tels qu‚Äôun √©cran AMOLED tactile, un port microSD‚Ñ¢, un connecteur USB OTG, ainsi qu‚Äôun module de d√©bogage ST-LINK/V2-1 facilitant la programmation et l‚Äôanalyse des performances.
Cette plateforme offre une bonne base pour exp√©rimenter le d√©ploiement de mod√®les de vision embarqu√©e, gr√¢ce √† la compatibilit√© avec les outils logiciels de la suite STM32Cube.AI. Cet environnement permet de convertir et d‚Äôoptimiser le mod√®le afin de l‚Äôadapter aux ressources limit√©es du microcontr√¥leur, tout en conservant des performances acceptables. 


---

## Evaluation de l'embarquabilit√© du mod√®le intiial 

L‚Äô√©tape suivante du projet consiste √† √©valuer la possibilit√© d‚Äôex√©cuter le mod√®le de r√©seau de neurones initial sur le microcontr√¥leur choisi, en tenant compte des contraintes mat√©rielles de la carte STM32L4R9AII6. Cette analyse vise √† d√©terminer si le mod√®le peut √™tre d√©ploy√© tel quel, ou s‚Äôil n√©cessite une adaptation pour respecter les limites de m√©moire, de puissance de calcul et de temps d‚Äôinf√©rence du syst√®me embarqu√©.
Pour cela, l‚Äôoutil STM32Cube.AI a √©t√© utilis√© afin de convertir le mod√®le pr√©entra√Æn√© (au format TensorFlow) en un format compatible avec la famille STM32. Cet outil permet √©galement d‚Äôobtenir des estimations pr√©cises concernant la taille du mod√®le, la m√©moire RAM requise pour l‚Äôinf√©rence, le type d‚Äôop√©rations arithm√©tiques utilis√©es, ainsi que le nombre total d‚Äôop√©rations n√©cessaires √† l‚Äôex√©cution (en millions de multiplications-accumulations, ou MACC).
Dans un premier temps, le mod√®le a √©t√© analys√© sans compression, puis avec les trois niveaux de compression propos√©s par STM32Cube.AI : Low, Medium et High. Ces niveaux reposent sur des techniques de quantification et de r√©duction de poids, permettant de r√©duire la taille m√©moire et le co√ªt de calcul, au prix d‚Äôune √©ventuelle perte de pr√©cision.
Les r√©sultats des quatre analyses sont synth√©tis√©s dans le tableau suivant :
Niveau de compression	Taille totale (Flash)	Poids (Weights)	M√©moire RAM totale	Nombre d‚Äôop√©rations (MACC)	Type d‚Äôop√©rations principales	Observation
Aucune (None)	5,37 Mo	5,12 Mo	143,8 Ko	32,998 M	96,5 % smul_f32_f32 (float 32)	Mod√®le trop volumineux pour la carte
Faible (Low)	3,45 Mo	3,33 Mo	146,2 Ko	32,998 M	Majorit√© d‚Äôop√©rations en float32	Encore trop lourd pour la m√©moire Flash
Moyenne (Medium)	1,72 Mo	1,62 Mo	152,1 Ko	32,998 M	96,5 % smul_f32_f32, 3,2 % smul_f32_f4	Compatible avec les ressources de la carte
Forte (High)	1,27 Mo	1,20 Mo	147,4 Ko	32,998 M	Op√©rations fortement quantifi√©es (poids en int8)	D√©ployable mais risque de perte de pr√©cision
L‚Äôanalyse montre que le mod√®le non compress√© d√©passe largement les capacit√©s m√©moire de la carte STM32L4R9AII6, emp√™chant son ex√©cution directe. M√™me avec une compression faible, la taille du mod√®le reste sup√©rieure √† la limite de m√©moire Flash embarqu√©e. Ce n‚Äôest qu‚Äô√† partir du niveau de compression moyen que le mod√®le devient compatible avec les 640 Ko de RAM et la m√©moire Flash disponible (2 Mo) sur la carte.
Concernant le temps d‚Äôinf√©rence, l‚Äôanalyse de la complexit√© du mod√®le indique un total d‚Äôenviron 33 millions d‚Äôop√©rations (MACC), essentiellement des multiplications flottantes (smul_f32_f32). Ce volume de calcul reste cons√©quent pour un microcontr√¥leur Cortex-M4 cadenc√© √† 120 MHz, mais il demeure g√©rable apr√®s quantification et optimisation logicielle via les biblioth√®ques CMSIS-NN int√©gr√©es √† STM32Cube.AI. Le temps d‚Äôinf√©rence estim√© reste compatible avec une ex√©cution locale sur microcontr√¥leur, mais il demeure trop √©lev√© pour une utilisation en temps r√©el sans compression ni optimisation suppl√©mentaire.
Ainsi, le d√©ploiement sur STM32L4R9AII6 n‚Äôest pas possible tel quel : le mod√®le initial est trop volumineux pour √™tre charg√© dans la m√©moire interne. Une compression interm√©diaire (niveau Medium) est n√©cessaire pour rendre l‚Äôapplication r√©alisable.

---

## Conception du nouveau mod√®le 

Voir partie *Conception du mod√®le* et l'√©tude associ√©. 

---

## Embarquabilit√© du mod√®le finale et √©valuation

7. Int√©gration dans un projet embarqu√© 
‚Ä¢ Mise en ≈ìuvre dans un environnement adapt√© (STM32CubeIDE, Arduino IDE, etc.) 
L‚Äôenvironnement choisi pour l‚Äôint√©gration est STM32CubeIDE associ√© √† l‚Äôextension X‚ÄëCUBE‚ÄëAI. Apr√®s avoir export√© le mod√®le entra√Æn√© (au format onxx), X‚ÄëCUBE‚ÄëAI a g√©n√©r√© le code C n√©cessaire pour ex√©cuter le r√©seau sur la MCU.
X-CUBE-AI nous a aussi permis de valider l‚Äôembarquabilit√© de notre mod√®le, gra√†ce √† l‚Äôinterface propos√©e dans le logiciel : 
 
Figure : R√©sultats analyse mod√®le
En effet, on voit bien ici que notre mod√®le respecte bien les limites mat√©rielles de notre carte, avec une marge de travail suffisante si l‚Äôon veut effectuer d‚Äôautres t√¢ches sur le microcontr√¥leur.
 Le projet CubeMX/STM32CubeIDE a ensuite √©t√© utilis√© pour activer et configurer les p√©riph√©riques indispensables, en particulier l‚ÄôUART pour la communication, l‚Äôhorloge et la gestion m√©moire. L‚Äôinitialisation du mod√®le est r√©alis√©e au d√©marrage par la fonction fournie par X‚ÄëCUBE‚ÄëAI, ce qui permet d‚Äôallouer les activations et de lier proprement les buffers d‚Äôentr√©e et de sortie au reste de l‚Äôapplication embarqu√©e.
‚Ä¢ Impl√©mentation de l‚Äôinf√©rence et tests avec des images CIFAR-10 (ou extraites en local)

L‚Äôimpl√©mentation embarqu√©e se compose de trois √©tapes simples : recevoir les donn√©es, lancer l‚Äôinf√©rence et renvoyer les r√©sultats. Pour la communication, un protocole UART √©l√©mentaire garantit la synchronisation avant chaque transfert : l‚Äôh√¥te envoie un octet de synchronisation et la cible r√©pond par un accus√©. Les images pr√©‚Äëpr√©trait√©es sont transmises en float32 little‚Äëendian et r√©ordonn√©es selon le format attendu par le mod√®le (CHW). Sur la STM32, ces floats sont copi√©s dans le buffer d‚Äôentr√©e puis la fonction ai_cifar10_run ex√©cute l‚Äôinf√©rence. Les dix sorties du r√©seau sont ensuite mises √† l‚Äô√©chelle en octets et envoy√©es √† l‚Äôh√¥te.
C√¥t√© PC, un script Python automatis√© envoie les images CIFAR‚Äë10 normalis√©es, lit les r√©ponses de la carte et calcule l‚Äôexactitude sur un √©chantillon. Ce test permet de v√©rifier que le pr√©traitement appliqu√© sur l‚Äôh√¥te correspond bien √† ce que la cible attend, et de d√©tecter rapidement des erreurs courantes (mauvais ordre des canaux, √©chelle diff√©rente, etc.). 
Cela nous permet alors d‚Äôeffectuer des tests en s√©rie sur diff√©rentes images du jeu de donn√©es, afin d‚Äôobtenir au final l‚Äôaccuracy de notre mod√®le sur la carte : 
 
Figure : R√©sultat accuracy en communication avec la carte


8. √âvaluation
8.1 Analyse des performances sur cible

L‚Äô√©valuation des performances des mod√®les a √©t√© r√©alis√©e sur une cible STM32L4, √† l‚Äôaide de l‚Äôoutil ST Edge AI Core v2.2.0, int√©gr√© dans STM32Cube.AI. Les param√®tres cl√©s mesur√©s concernent la latence d‚Äôinf√©rence, la consommation m√©moire (Flash et RAM) et la complexit√© de calcul (nombre de MACC ‚Äì Multiply‚ÄìAccumulate Operations).

a) Mod√®le compress√© (mod√®le final)

Le mod√®le compress√©, g√©n√©r√© au format ONNX sous le nom model.onnx, pr√©sente les caract√©ristiques suivantes :
Poids totaux : 148 161 param√®tres, soit 591 932 B (578 KiB).
Activations dynamiques : 97 048 B (94,77 KiB).
Complexit√© de calcul : 18,34 M de MACC.
M√©moire Flash totale : 611 020 B (‚âà 597 KiB).
M√©moire RAM totale : 104 636 B (‚âà 102 KiB).
Temps d‚Äôanalyse : inf√©rieur √† 25 s sur STM32Cube.AI.
La structure du r√©seau montre une architecture convolutionnelle compacte, comprenant plusieurs blocs Conv2D ‚Äì BatchNorm ‚Äì ReLU ‚Äì Pooling, suivis d‚Äôune √©tape de GlobalAveragePooling et de deux couches enti√®rement connect√©es (Dense) de petite taille.
Cette organisation, associ√©e √† la r√©duction du nombre de filtres, permet une forte diminution du volume de calcul et des besoins m√©moire, tout en conservant la compatibilit√© avec la cible STM32L4.

b) Mod√®le d‚Äôorigine (non compress√©)

Le mod√®le de r√©f√©rence, nomm√© CIFAR10_CNN.h5, est un mod√®le Keras sans compression. Il pr√©sente les caract√©ristiques suivantes :
Poids totaux : 1 343 146 param√®tres, soit 5 372 584 B (5,12 MiB).
Activations dynamiques : 143 468 B (140,11 KiB).
Complexit√© de calcul : 32,99 M de MACC.
M√©moire Flash totale : 5 393 034 B (5,14 MiB).
M√©moire RAM totale : 152 124 B (148,56 KiB).
L‚Äôoutil indique que la taille requise exc√®de les capacit√©s m√©moire de la cible STM32L4.
Ce mod√®le initial, bien que performant en pr√©cision, s‚Äôav√®re inadapt√© √† une ex√©cution embarqu√©e sur STM32L4 sans compression ou optimisation pr√©alable, en raison de sa taille et de sa charge de calcul.

8.2 Comparaison avec le mod√®le d‚Äôorigine
Param√®tre	Mod√®le d‚Äôorigine (float32)	Mod√®le final compress√©	Gain / R√©duction
Poids (Flash)	5 372 584 B (5.12 MiB)	591 932 B (578 KiB)	‚Äì 89 %
Activations (RAM)	143 468 B (140 KiB)	97 048 B (95 KiB)	‚Äì 32 %
Complexit√© (MACC)	32 997 984	18 338 190	‚Äì 44 %
M√©moire Flash totale	5 393 034 B	611 020 B	‚Äì 88,7 %
M√©moire RAM totale	152 124 B	104 636 B	‚Äì 31 %
Ex√©cution sur cible STM32L4	Non compatible (m√©moire insuffisante)	Compatible et analys√© avec succ√®s	

8.3 Discussion

L‚Äôanalyse met en √©vidence une r√©duction majeure des ressources n√©cessaires gr√¢ce √† l‚Äôoptimisation du mod√®le.
Le passage d‚Äôun mod√®le de 5,1 MiB √† environ 0,6 MiB permet une int√©gration embarqu√©e sur microcontr√¥leur STM32L4 sans perte significative de structure ni de pr√©cision fonctionnelle (les couches principales et la topologie sont conserv√©es).

Cette compression a divis√© par pr√®s de 2 le nombre d‚Äôop√©rations (de 33 M √† 18 M MACC), ce qui se traduit par une latence d‚Äôinf√©rence potentiellement r√©duite de moiti√©, ainsi qu‚Äôune baisse de la consommation √©nerg√©tique sur cible.
Le compromis obtenu illustre l‚Äôefficacit√© des techniques d‚Äôoptimisation et de compression pour les mod√®les de vision embarqu√©s (CIFAR-10 dans ce cas), rendant possible leur ex√©cution sur des plateformes √† ressources limit√©es.

8.4 Pr√©cision des mod√®les

Les performances en termes de pr√©cision ont √©t√© √©valu√©es sur le jeu de test CIFAR-10 afin de mesurer l‚Äôimpact de la compression sur la qualit√© des pr√©dictions.
-Mod√®le d‚Äôorigine (non compress√©) : 84 % de pr√©cision
-Mod√®le final embarqu√© (compress√©) : 79 % de pr√©cision
La perte de pr√©cision introduite par la compression est donc d‚Äôenviron 5 points de pourcentage, soit une baisse relative de 5,95 %. Cette diminution reste mod√©r√©e et acceptable compte tenu des gains consid√©rables en ressources m√©moire et en complexit√© de calcul observ√©s pr√©c√©demment.
En effet, la taille du mod√®le a √©t√© r√©duite de plus de 89 % (de 5,1 MiB √† 0,58 MiB), et le nombre total de param√®tres est pass√© de 1,34 million √† 148 000, soit une r√©duction d‚Äôenviron 90 %.
De plus, le nombre d‚Äôop√©rations n√©cessaires √† une inf√©rence compl√®te a √©t√© divis√© par presque deux (de 33 M MACC √† 18 M MACC), rendant l‚Äôex√©cution sur la cible STM32L4 possible, fluide et √©conome en √©nergie.
Cette l√©g√®re d√©gradation de la pr√©cision s‚Äôexplique par la simplification du r√©seau : la compression a r√©duit la profondeur et le nombre de filtres convolutionnels, ce qui limite l√©g√®rement la capacit√© de g√©n√©ralisation du mod√®le.
Cependant, le compromis obtenu reste tr√®s favorable pour une application embarqu√©e. Le mod√®le final offre un excellent rapport pr√©cision / co√ªt computationnel, tout en respectant les contraintes strictes de m√©moire et de puissance du microcontr√¥leur.
Ainsi, le mod√®le compress√© parvient √† maintenir une pr√©cision proche de 80 %, niveau tout √† fait satisfaisant pour des t√¢ches de classification d‚Äôimages l√©g√®res (comme CIFAR-10), tout en √©tant pleinement ex√©cutable sur une plateforme STM32 √† ressources limit√©es ‚Äî ce qui n‚Äô√©tait pas possible pour le mod√®le initial.

9. R√©silience aux corruptions binaires ‚Äî attaque Bit-Flip
Dans cette section, nous pr√©sentons une √©valuation exp√©rimentale de la r√©silience du mod√®le embarqu√© face √† des corruptions binaires appliqu√©es directement aux poids ‚Äî commun√©ment appel√©e Bit-Flip Attack (BFA). L‚Äôobjectif n‚Äôest pas d‚Äôexposer l‚Äôimpl√©mentation pas √† pas, mais de d√©crire de mani√®re synth√©tique la m√©thode exp√©rimentale, les indicateurs mesur√©s et les conclusions pratiques que l‚Äôon peut en tirer pour un d√©ploiement embarqu√©.

9.1 Principe g√©n√©ral de l‚Äôattaque
L‚Äôattaque par inversion de bits consiste √† modifier la repr√©sentation binaire des poids du r√©seau (dans leur format quantifi√©) en inversant un ou plusieurs bits cibl√©s. Lorsque ces inversions portent sur des bits critiques ‚Äî typiquement des bits de poids fortement influents sur la fonction de perte ‚Äî la performance du mod√®le (accuracy sur l‚Äôensemble de test) peut chuter rapidement. La BFA vise √† localiser et inverser les bits qui entra√Ænent la plus forte d√©gradation de la loss, afin d‚Äôobtenir une attaque ¬´ maximale ¬ª en quelques flips seulement.

9.2 Protocole exp√©rimental synth√©tique
Pour √©valuer l‚Äôimpact de ce type de corruption sur le mod√®le final d√©ploy√© sur STM32L4, nous avons proc√©d√© selon le protocole suivant (r√©sum√©) :
-Utilisation du mod√®le compress√© tel que d√©ploy√© sur la carte (m√™mes poids/quantification).
-Mesure de la pr√©cision de r√©f√©rence (accuracy) sur le jeu de test CIFAR-10 avant toute alt√©ration.
-Application d‚Äôune attaque dirig√©e (BFA) qui, it√©rativement, s√©lectionne et inverse le bit dont l‚Äôimpact empirique sur la loss est maximal, en mesurant la pr√©cision globale apr√®s chaque flip.
-Construction d‚Äôun baseline al√©atoire : application du m√™me nombre de flips, mais choisis al√©atoirement parmi les bits des poids, afin d‚Äô√©valuer la sup√©riorit√© d‚Äôune strat√©gie dirig√©e par rapport √† des corruptions non cibl√©es.
Le protocole privil√©gie des √©valuations r√©p√©t√©es et la pr√©sentation des courbes Accuracy vs # flips ainsi que des indicateurs synth√©tiques (p. ex. accuracy apr√®s k flips, nombre de flips pour atteindre un seuil donn√©).

9.3 R√©sultats attendus et interpr√©tation

L‚Äôexp√©rience vise √† mettre en √©vidence deux observations importantes :
-Efficacit√© sup√©rieure de la BFA : une attaque dirig√©e permet typiquement d‚Äôobtenir une d√©gradation beaucoup plus rapide de l‚Äôaccuracy qu‚Äôune suite de flips al√©atoires. En pratique, quelques flips opportun√©ment choisis peuvent provoquer une chute significative de la performance, tandis que les flips al√©atoires n√©cessitent un nombre bien plus √©lev√© d‚Äôalt√©rations pour atteindre un effet comparable.
-Vuln√©rabilit√© accrue des mod√®les compact√©s : la compression et la quantification concentrent l‚Äôinformation utile sur un ensemble de poids plus restreint. Cette concentration peut rendre certains bits particuli√®rement sensibles : leur corruption a un impact disproportionn√© sur la loss. Par cons√©quent, la r√©duction du nombre de param√®tres et la taille m√©moire avantageuse du mod√®le embarqu√© s‚Äôaccompagnent d‚Äôun risque accru vis-√†-vis d‚Äôalt√©rations binaires cibl√©es.

9.4 R√©sultats

 Figure : comparaison r√©sultats bit-flip
 
Apr√®s la capture (figure ci-dessus), on constate clairement deux comportements distincts : l‚Äôattaque BFA cibl√©e provoque une d√©gradation rapide et soutenue des performances ‚Äî la pr√©cision chute d‚Äôenviron 79 % √† ~22 % lorsque le nombre de bit flips passe de 0 √† 20 ‚Äî alors que les inversions de bits al√©atoires n‚Äôentra√Ænent qu‚Äôune perte marginale, la pr√©cision restant stable autour de 73‚Äì75 %. Cette comparaison illustre que la fragilit√© observ√©e ne provient pas d‚Äôune simple sensibilit√© aux perturbations binaires, mais bien d‚Äôun effet de ciblage : la BFA identifie et corrompt des poids/bits √† fort impact, ce qui m√®ne √† une d√©t√©rioration bien plus marqu√©e du mod√®le.
