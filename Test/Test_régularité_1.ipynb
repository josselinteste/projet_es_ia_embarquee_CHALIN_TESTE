{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP697LuRwBgo",
        "outputId": "0f7b241e-724a-4934-93d3-2884ae776b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "import torch\n",
        "data_folder = '/content/' # This can be any directory you want to download FMNIST to\n",
        "fmnist = datasets.CIFAR10(data_folder, download=True, train=True)\n",
        "\n",
        "tr_images = fmnist.data\n",
        "tr_targets = fmnist.targets\n",
        "\n",
        "val_fmnist = datasets.CIFAR10(data_folder, download=True, train=False)\n",
        "val_images = val_fmnist.data\n",
        "val_targets = val_fmnist.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cuyLuLPwCeA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, images, targets, device='cpu'):\n",
        "        # Convertir les tableaux NumPy en tenseurs PyTorch\n",
        "        images = torch.from_numpy(images).float() / 255.0\n",
        "        targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "        # CIFAR10 : images en 3x32x32, format (N, H, W, C) -> (N, C, H, W)\n",
        "        images = images.permute(0, 3, 1, 2)\n",
        "\n",
        "        self.x = images\n",
        "        self.y = targets\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        x = self.x[ix].to(self.device)\n",
        "        y = self.y[ix].to(self.device)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHGn69pmwFCk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_model(device='cpu'):\n",
        "    model = nn.Sequential(\n",
        "        # Bloc 1\n",
        "        nn.Conv2d(3, 16, kernel_size=5, padding=2, bias=True),  # 64 → 16\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16, 16, kernel_size=5, padding=2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.MaxPool2d(2),  # 32x32 → 16x16\n",
        "\n",
        "        # Bloc 2\n",
        "        nn.Conv2d(16, 32, kernel_size=5, padding=2, bias=True),  # 128 → 32\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),  # 16x16 → 8x8\n",
        "\n",
        "        # Bloc 3\n",
        "        nn.Conv2d(32, 32, kernel_size=5, padding=2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),  # 8x8 → 4x4\n",
        "\n",
        "        # Classificateur\n",
        "        nn.Flatten(),              # 32 * 4 * 4 = 512\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(64, 10)\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    return model, loss_fn, optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F8B-MtQwIrx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oABLdS0NwJQx"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    train = CIFAR10Dataset(tr_images, tr_targets)\n",
        "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    val = CIFAR10Dataset(val_images, val_targets)\n",
        "    val_dl = DataLoader(val, batch_size=len(val_images), shuffle=True)\n",
        "    return trn_dl, val_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGA7dXVLwLO5",
        "outputId": "116d72e6-7cd6-470c-f982-28f03b31c3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]           1,216\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "            Conv2d-4           [-1, 16, 32, 32]           6,416\n",
            "              ReLU-5           [-1, 16, 32, 32]               0\n",
            "         Dropout2d-6           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
            "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]          12,832\n",
            "             ReLU-10           [-1, 32, 16, 16]               0\n",
            "        Dropout2d-11           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
            "        MaxPool2d-13             [-1, 32, 8, 8]               0\n",
            "           Conv2d-14             [-1, 32, 8, 8]          25,632\n",
            "             ReLU-15             [-1, 32, 8, 8]               0\n",
            "        Dropout2d-16             [-1, 32, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 32, 8, 8]              64\n",
            "        MaxPool2d-18             [-1, 32, 4, 4]               0\n",
            "          Flatten-19                  [-1, 512]               0\n",
            "           Linear-20                  [-1, 128]          65,664\n",
            "             ReLU-21                  [-1, 128]               0\n",
            "          Dropout-22                  [-1, 128]               0\n",
            "           Linear-23                   [-1, 64]           8,256\n",
            "             ReLU-24                   [-1, 64]               0\n",
            "          Dropout-25                   [-1, 64]               0\n",
            "           Linear-26                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 120,858\n",
            "Trainable params: 120,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.25\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 1.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Définir le device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Charger les données\n",
        "trn_dl, val_dl = get_data()\n",
        "\n",
        "# Initialiser le modèle\n",
        "model, loss_fn, optimizer = get_model(device=device)\n",
        "\n",
        "# Afficher un résumé du modèle\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))  # CIFAR10 : 3 canaux, 32x32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c43c5VK8wOVy"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    prediction = model(x)\n",
        "    batch_loss = loss_fn(prediction, y)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return batch_loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    max_values, argmaxes = prediction.max(-1)\n",
        "    is_correct = argmaxes == y\n",
        "    return is_correct.cpu().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8s7IsyUwR-Q"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def val_loss(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    val_loss = loss_fn(prediction, y)\n",
        "    return val_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-blw4yXLwTnb",
        "outputId": "5380d741-a9f7-4024-bb1d-c2ac6a09e566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "for epoch in range(6):\n",
        "    print(epoch)\n",
        "    train_epoch_losses, train_epoch_accuracies = [], []\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
        "        train_epoch_losses.append(batch_loss)\n",
        "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
        "\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        is_correct = accuracy(x, y, model)\n",
        "        train_epoch_accuracies.extend(is_correct)\n",
        "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
        "\n",
        "    for ix, batch in enumerate(iter(val_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        val_is_correct = accuracy(x, y, model)\n",
        "        validation_loss = val_loss(x, y, model)\n",
        "    val_epoch_accuracy = np.mean(val_is_correct)\n",
        "\n",
        "    train_losses.append(train_epoch_loss)\n",
        "    train_accuracies.append(train_epoch_accuracy)\n",
        "    val_losses.append(validation_loss)\n",
        "    val_accuracies.append(val_epoch_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvxloP_xpeU"
      },
      "source": [
        "**INTERPOLATION DU FILTRE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGYfASukxtuA"
      },
      "outputs": [],
      "source": [
        "def interpolate_filter(filter_weights, smooth_factor=50):\n",
        "    \"\"\"Interpolation cubique bilinéaire pour passer du filtre discret à une fonction continue\"\"\"\n",
        "    h, w = filter_weights.shape\n",
        "    y = np.arange(h)\n",
        "    x = np.arange(w)\n",
        "    interp_func = RegularGridInterpolator((y, x), filter_weights, method='cubic')\n",
        "    ynew = np.linspace(0, h-1, smooth_factor)\n",
        "    xnew = np.linspace(0, w-1, smooth_factor)\n",
        "    X, Y = np.meshgrid(xnew, ynew)\n",
        "    points = np.array([Y.ravel(), X.ravel()]).T\n",
        "    Zsmooth = interp_func(points).reshape(smooth_factor, smooth_factor)\n",
        "    return Zsmooth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI3eqSuFxubf"
      },
      "source": [
        "**Projection dans schwartz**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA0CEZ2Vx3AF"
      },
      "outputs": [],
      "source": [
        "def project_to_schwartz(Zsmooth, sigma=None):\n",
        "    \"\"\"Projette un filtre interpolé dans un espace proche de S(R^2) via une fenêtre gaussienne\"\"\"\n",
        "    H, W = Zsmooth.shape\n",
        "    if sigma is None:\n",
        "        sigma = min(H, W) / 2\n",
        "    y = np.arange(H) - H/2\n",
        "    x = np.arange(W) - W/2\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    gauss_window = np.exp(-(X**2 + Y**2) / (2*sigma**2))\n",
        "    Z_schwartz = Zsmooth * gauss_window\n",
        "    return Z_schwartz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8bfJzHt1uFQ"
      },
      "source": [
        "**Mesure de régularité**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFS613_Wx7NN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def gaussian_window(shape, sigma=1.0, center=None):\n",
        "    \"\"\"Fenêtre gaussienne normalisée 2D\"\"\"\n",
        "    n, m = shape\n",
        "    if center is None:\n",
        "        center = (n//2, m//2)\n",
        "    y = np.arange(n) - center[0]\n",
        "    x = np.arange(m) - center[1]\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    g = np.exp(-(X**2 + Y**2)/(2*sigma**2))\n",
        "    g /= np.sqrt(np.sum(g**2))\n",
        "    return g\n",
        "\n",
        "def local_sobolev_gauss_3D(h, block_size=(5,5), alpha=2, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Calcule la régularité locale de sous-blocs d'un filtre 2D\n",
        "    avec fenêtre gaussienne et pondération Sobolev.\n",
        "\n",
        "    Retour :\n",
        "    - reg_map : matrice de régularité locale\n",
        "    \"\"\"\n",
        "    n, m = h.shape\n",
        "    bh, bw = block_size\n",
        "    reg_map = np.zeros((n - bh + 1, m - bw + 1))\n",
        "\n",
        "    for i in range(n - bh + 1):\n",
        "        for j in range(m - bw + 1):\n",
        "            block = h[i:i+bh, j:j+bw]\n",
        "            g = gaussian_window(block.shape, sigma=sigma)\n",
        "            block_win = block * g\n",
        "\n",
        "            H = np.fft.fft2(block_win)\n",
        "            H = np.fft.fftshift(H)\n",
        "\n",
        "            u = np.fft.fftshift(np.fft.fftfreq(bh))\n",
        "            v = np.fft.fftshift(np.fft.fftfreq(bw))\n",
        "            U, V = np.meshgrid(u, v, indexing='ij')\n",
        "\n",
        "            freq_weight = (1 + U**2 + V**2)**alpha\n",
        "            reg_map[i,j] = np.sum(freq_weight * np.abs(H)**2)\n",
        "\n",
        "    return reg_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_7Fds61Q10"
      },
      "source": [
        "**Récupération des poids réguliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90sq5XIUxeBg"
      },
      "outputs": [],
      "source": [
        "def graphcut_filter_surface(Zsmooth, percentile=20):\n",
        "    \"\"\"\n",
        "    Conserve uniquement les valeurs les plus petites (en valeur absolue)\n",
        "    selon un seuil basé sur le percentile.\n",
        "    #\n",
        "    Zsmooth : surface lissée (2D numpy array)\n",
        "    percentile : pourcentage de valeurs à conserver (les plus petites)\n",
        "    \"\"\"\n",
        "    threshold = np.percentile(np.abs(Zsmooth), percentile)\n",
        "    mask = np.abs(Zsmooth) <= threshold  # True là où on garde\n",
        "    Zcut = np.where(mask, Zsmooth, np.nan)  # NaN pour visualiser les trous\n",
        "    return Zcut, mask\n",
        "\n",
        "# Application sur reg_map\n",
        "#Zcut, mask = graphcut_filter_surface(reg_map, percentile=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjFLTC0414E0"
      },
      "source": [
        "Mesure de valeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ky5RZdD13Sm"
      },
      "outputs": [],
      "source": [
        "def magnitude_mesure(Zcut):\n",
        "    \"\"\"\n",
        "    Calcule la somme des valeurs absolues de Zcut.\n",
        "    Les NaN sont traités comme des zéros.\n",
        "    \"\"\"\n",
        "    return np.nansum(np.abs(Zcut))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPbX5jqYDHnS"
      },
      "outputs": [],
      "source": [
        "def ultimate_graphcut_filter_analysis_reg(filter_weights):\n",
        "  Zsmooth = interpolate_filter(filter_weights)\n",
        "  Z_schwartz = project_to_schwartz(Zsmooth)\n",
        "  reg_map = local_sobolev_gauss_3D(Zsmooth, block_size=(5,5), alpha=2, sigma=1.0)\n",
        "  Zcut, mask = graphcut_filter_surface(reg_map, percentile=20)\n",
        "  return magnitude_mesure(Zcut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp20qDf12KYW"
      },
      "source": [
        "**Classement des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcI5tkbgCpjr",
        "outputId": "780f27fa-1ad8-4fc3-bd04-8e5476b58a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]           1,216\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "            Conv2d-4           [-1, 16, 32, 32]           6,416\n",
            "              ReLU-5           [-1, 16, 32, 32]               0\n",
            "         Dropout2d-6           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
            "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]          12,832\n",
            "             ReLU-10           [-1, 32, 16, 16]               0\n",
            "        Dropout2d-11           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
            "        MaxPool2d-13             [-1, 32, 8, 8]               0\n",
            "           Conv2d-14             [-1, 32, 8, 8]          25,632\n",
            "             ReLU-15             [-1, 32, 8, 8]               0\n",
            "        Dropout2d-16             [-1, 32, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 32, 8, 8]              64\n",
            "        MaxPool2d-18             [-1, 32, 4, 4]               0\n",
            "          Flatten-19                  [-1, 512]               0\n",
            "           Linear-20                  [-1, 128]          65,664\n",
            "             ReLU-21                  [-1, 128]               0\n",
            "          Dropout-22                  [-1, 128]               0\n",
            "           Linear-23                   [-1, 64]           8,256\n",
            "             ReLU-24                   [-1, 64]               0\n",
            "          Dropout-25                   [-1, 64]               0\n",
            "           Linear-26                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 120,858\n",
            "Trainable params: 120,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.25\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 1.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgwbKDtt6rmd",
        "outputId": "880859e1-1277-47a5-f718-8a9d68be0edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Couche 1/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "   Couche 2/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "   Couche 3/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "   Couche 4/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n"
          ]
        }
      ],
      "source": [
        "from scipy.interpolate import RegularGridInterpolator\n",
        "conv_layers = [module for module in model.modules() if isinstance(module, nn.Conv2d)]\n",
        "\n",
        "filter_ranking = {}\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "\n",
        "for m_idx, conv_layer in enumerate(conv_layers):\n",
        "    print(f\"   Couche {m_idx+1}/{len(conv_layers)}...\")\n",
        "    filter_ranking[m_idx] = {}\n",
        "\n",
        "    out_channels, in_channels, h, w = conv_layer.weight.shape\n",
        "\n",
        "    for oc in range(out_channels):\n",
        "        print(oc)\n",
        "        filter_ranking[m_idx][oc] = {}\n",
        "        for ic in range(in_channels):\n",
        "            print(ic)\n",
        "                # 1. Importance GraphCut multi-échelle + structurelle\n",
        "            filter_weights = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
        "            base_importance = ultimate_graphcut_filter_analysis_reg(filter_weights)\n",
        "\n",
        "                # 2. Correction contextuelle (redondance)\n",
        "            #redundancy_factor = contextual_redundancy_check(conv_layer, oc, ic)\n",
        "\n",
        "                # 3. Score final\n",
        "            #final_importance = base_importance * redundancy_factor\n",
        "            filter_ranking[m_idx][oc][ic] = float(base_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjCKJdwqyTtc",
        "outputId": "e8f5b3b7-acb8-4b0f-9486-41a82713d55f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {0: {0: 6.965900770224636, 1: 2.980007526118758, 2: 3.03821874193555},\n",
              "  1: {0: 4.564288365269535, 1: 5.999807607866493, 2: 4.873704623472269},\n",
              "  2: {0: 5.111575870499241, 1: 3.468271886690179, 2: 1.5772259409310694},\n",
              "  3: {0: 5.3195794474925835, 1: 2.233252689302897, 2: 5.197712128145371},\n",
              "  4: {0: 2.4791868347104904, 1: 4.808416007300519, 2: 1.2213777175659053},\n",
              "  5: {0: 3.1571076287245523, 1: 2.3674376700021416, 2: 5.4100857663632},\n",
              "  6: {0: 6.457230244233056, 1: 2.0384423483721026, 2: 6.228639587683963},\n",
              "  7: {0: 8.918024367508949, 1: 6.674194859354812, 2: 6.061433544959715},\n",
              "  8: {0: 3.9077113052123513, 1: 6.052075598360608, 2: 4.496383209929037},\n",
              "  9: {0: 5.907845380502608, 1: 2.472079646150395, 2: 5.108989197569615},\n",
              "  10: {0: 3.944795547887996, 1: 1.198616052739446, 2: 32.44656641904763},\n",
              "  11: {0: 7.4656743092379205, 1: 11.145567906002922, 2: 13.365457400086875},\n",
              "  12: {0: 6.840396798958277, 1: 3.7735719777756707, 2: 5.332115589008468},\n",
              "  13: {0: 8.782523924568771, 1: 2.9238100968032716, 2: 4.415321577252831},\n",
              "  14: {0: 11.793384130860307, 1: 12.043911707370269, 2: 5.567537103553974},\n",
              "  15: {0: 10.684941493435302, 1: 13.053013518847374, 2: 4.402093180835276}},\n",
              " 1: {0: {0: 0.6541130452462318,\n",
              "   1: 1.8591765038820687,\n",
              "   2: 0.47828218871622497,\n",
              "   3: 2.5777219440046553,\n",
              "   4: 51.44513036310912,\n",
              "   5: 0.7391829181136222,\n",
              "   6: 3.219128341247771,\n",
              "   7: 2.7619259484591265,\n",
              "   8: 119.23102908304583,\n",
              "   9: 0.6013881722851572,\n",
              "   10: 2.757502054584665,\n",
              "   11: 3.5407617426085594,\n",
              "   12: 1.5410845797146957,\n",
              "   13: 0.9298950612904833,\n",
              "   14: 2.496749534192402,\n",
              "   15: 1.1474201788051535},\n",
              "  1: {0: 1.203012159120139,\n",
              "   1: 3.154135886955343,\n",
              "   2: 0.12370579031233712,\n",
              "   3: 2.964561964819701,\n",
              "   4: 14.074687825215008,\n",
              "   5: 0.5910278173900233,\n",
              "   6: 20.329547882922057,\n",
              "   7: 3.8198866784204633,\n",
              "   8: 23.310747354489465,\n",
              "   9: 1.2770630699238623,\n",
              "   10: 2.162439517086354,\n",
              "   11: 14.592538094468587,\n",
              "   12: 9.58387818092422,\n",
              "   13: 5.7006307888653875,\n",
              "   14: 4.012929742839628,\n",
              "   15: 6.637742167475276},\n",
              "  2: {0: 1.460109722959433,\n",
              "   1: 1.9430983023440387,\n",
              "   2: 0.33132373776210294,\n",
              "   3: 0.7125824435946617,\n",
              "   4: 39.52349372941772,\n",
              "   5: 0.46074897450458324,\n",
              "   6: 8.51170089026352,\n",
              "   7: 2.223199362452098,\n",
              "   8: 47.37111152456125,\n",
              "   9: 1.6151425375705784,\n",
              "   10: 1.8034463813016834,\n",
              "   11: 14.084229728716963,\n",
              "   12: 7.574108488499137,\n",
              "   13: 1.838078719215662,\n",
              "   14: 10.782866075094134,\n",
              "   15: 1.0331795352364104},\n",
              "  3: {0: 10.17899724572247,\n",
              "   1: 3.754022338240274,\n",
              "   2: 0.5955505665592187,\n",
              "   3: 1.4441519985731486,\n",
              "   4: 36.39951472643399,\n",
              "   5: 0.43672653299250985,\n",
              "   6: 6.080698094158941,\n",
              "   7: 0.4117857475291179,\n",
              "   8: 12.101860058198078,\n",
              "   9: 2.723324651147428,\n",
              "   10: 0.4808098749394011,\n",
              "   11: 19.39215369160821,\n",
              "   12: 1.10081091783935,\n",
              "   13: 3.1930584956720427,\n",
              "   14: 6.060671034096053,\n",
              "   15: 2.2824565151056873},\n",
              "  4: {0: 1.0730232298209104,\n",
              "   1: 2.6505890791054165,\n",
              "   2: 0.3352897165200027,\n",
              "   3: 1.669263662599967,\n",
              "   4: 79.7621161061571,\n",
              "   5: 1.510709667266895,\n",
              "   6: 4.1829868353068305,\n",
              "   7: 1.7262201799747754,\n",
              "   8: 110.45354747891618,\n",
              "   9: 1.5159239446558277,\n",
              "   10: 0.5729999969764841,\n",
              "   11: 7.454792484302185,\n",
              "   12: 2.882991481960423,\n",
              "   13: 2.5195228254458875,\n",
              "   14: 13.217349340967012,\n",
              "   15: 2.1524091301517694},\n",
              "  5: {0: 1.168180731692347,\n",
              "   1: 7.104290706939745,\n",
              "   2: 0.44087071083835844,\n",
              "   3: 7.3805697045202745,\n",
              "   4: 9.076147473231098,\n",
              "   5: 2.8528919088457925,\n",
              "   6: 2.799884221584093,\n",
              "   7: 4.027498812353731,\n",
              "   8: 128.29351305657843,\n",
              "   9: 2.5668677551375296,\n",
              "   10: 3.1493086680676026,\n",
              "   11: 1.909327807694456,\n",
              "   12: 5.509448242144306,\n",
              "   13: 1.3065087373693711,\n",
              "   14: 3.1273769556654334,\n",
              "   15: 9.014600178082226},\n",
              "  6: {0: 2.2036519703220248,\n",
              "   1: 1.405949673757831,\n",
              "   2: 0.18915497500532452,\n",
              "   3: 1.9755600323002995,\n",
              "   4: 1.1742461312413897,\n",
              "   5: 0.5222703011911237,\n",
              "   6: 1.3583880196133646,\n",
              "   7: 11.937338573732285,\n",
              "   8: 0.7659869355286378,\n",
              "   9: 1.2223114971358653,\n",
              "   10: 1.9110688818631172,\n",
              "   11: 11.214829570382193,\n",
              "   12: 1.1350041720145978,\n",
              "   13: 1.1803939335726352,\n",
              "   14: 4.868444806742742,\n",
              "   15: 0.32325535603730476},\n",
              "  7: {0: 1.1873534501559564,\n",
              "   1: 11.533992618697155,\n",
              "   2: 0.2827821757760391,\n",
              "   3: 2.8252092814834953,\n",
              "   4: 1.2377460775619842,\n",
              "   5: 0.3848196371198829,\n",
              "   6: 0.6819516157899175,\n",
              "   7: 1.8063155094417636,\n",
              "   8: 30.45013020745183,\n",
              "   9: 3.559839629702708,\n",
              "   10: 5.308595403897819,\n",
              "   11: 6.403626499260751,\n",
              "   12: 4.213354231054244,\n",
              "   13: 2.6763170480191967,\n",
              "   14: 4.84249960473036,\n",
              "   15: 6.185271531081436},\n",
              "  8: {0: 2.3812407554378154,\n",
              "   1: 15.741808247753362,\n",
              "   2: 0.5104801972587081,\n",
              "   3: 1.407164460601021,\n",
              "   4: 0.6780685100283828,\n",
              "   5: 0.9421661898858388,\n",
              "   6: 4.457914331256313,\n",
              "   7: 1.571637180467755,\n",
              "   8: 16.41954386478124,\n",
              "   9: 3.9314010909797714,\n",
              "   10: 2.477523760132674,\n",
              "   11: 2.449830181754084,\n",
              "   12: 14.606910188384543,\n",
              "   13: 3.9757912049899,\n",
              "   14: 20.022382156391085,\n",
              "   15: 2.610801264509607},\n",
              "  9: {0: 2.9397767241758097,\n",
              "   1: 1.053373584580823,\n",
              "   2: 0.6849800493033367,\n",
              "   3: 1.6653778634387741,\n",
              "   4: 68.09344571963418,\n",
              "   5: 0.7657262797484963,\n",
              "   6: 1.4521076738518546,\n",
              "   7: 4.182425736041944,\n",
              "   8: 99.85854774384589,\n",
              "   9: 1.3948335087183628,\n",
              "   10: 0.5720382420616482,\n",
              "   11: 1.670211680993021,\n",
              "   12: 1.9988575938537596,\n",
              "   13: 5.539703505648033,\n",
              "   14: 5.935292898634484,\n",
              "   15: 5.573106278328256},\n",
              "  10: {0: 6.959340692121755,\n",
              "   1: 1.7162949380724695,\n",
              "   2: 0.2798710173631418,\n",
              "   3: 1.6659582992907815,\n",
              "   4: 205.8383850563871,\n",
              "   5: 1.056286371066221,\n",
              "   6: 3.3717739855246696,\n",
              "   7: 4.7895988856902205,\n",
              "   8: 259.97937027640216,\n",
              "   9: 1.6429227772799346,\n",
              "   10: 0.6660615787894204,\n",
              "   11: 7.718847083733311,\n",
              "   12: 4.582933928768986,\n",
              "   13: 1.0896256703571041,\n",
              "   14: 1.608330630779951,\n",
              "   15: 1.2134663274169755},\n",
              "  11: {0: 1.3621299546113124,\n",
              "   1: 2.145027800298214,\n",
              "   2: 0.10635075056210763,\n",
              "   3: 3.051712410777145,\n",
              "   4: 1.674427836981593,\n",
              "   5: 0.46285141315910944,\n",
              "   6: 1.736449395919036,\n",
              "   7: 1.5183787599803569,\n",
              "   8: 5.427522868933428,\n",
              "   9: 1.8413108738530475,\n",
              "   10: 3.330728836118871,\n",
              "   11: 3.4523073644563844,\n",
              "   12: 1.497667622968613,\n",
              "   13: 6.397740274387546,\n",
              "   14: 9.669892843361335,\n",
              "   15: 0.6954781617286294},\n",
              "  12: {0: 9.570527324625028,\n",
              "   1: 4.233027128657767,\n",
              "   2: 0.48222672456381255,\n",
              "   3: 3.20894718638878,\n",
              "   4: 21.48198601516606,\n",
              "   5: 0.24881776956771046,\n",
              "   6: 2.9856567964464253,\n",
              "   7: 5.07599850547098,\n",
              "   8: 44.60820974811401,\n",
              "   9: 2.8199197151942847,\n",
              "   10: 1.4364249398764104,\n",
              "   11: 4.131506850784726,\n",
              "   12: 5.163851500391316,\n",
              "   13: 2.3825197300402654,\n",
              "   14: 7.717264000723125,\n",
              "   15: 1.62832298704881},\n",
              "  13: {0: 1.3105687815042644,\n",
              "   1: 1.5820369924091882,\n",
              "   2: 0.40782621025204147,\n",
              "   3: 9.496681997775658,\n",
              "   4: 42.79536141083418,\n",
              "   5: 1.3546176391689855,\n",
              "   6: 3.2707104937471554,\n",
              "   7: 2.4213518398195712,\n",
              "   8: 11.9209737071855,\n",
              "   9: 1.293382633286701,\n",
              "   10: 0.909516141156163,\n",
              "   11: 14.763718281219393,\n",
              "   12: 4.733184815300154,\n",
              "   13: 2.4139984586426504,\n",
              "   14: 7.857113371670682,\n",
              "   15: 4.179573725102492},\n",
              "  14: {0: 0.898900564827622,\n",
              "   1: 2.1120644069732863,\n",
              "   2: 1.3480573698968032,\n",
              "   3: 1.1757489500009963,\n",
              "   4: 40.77675989730683,\n",
              "   5: 0.5090346737483338,\n",
              "   6: 0.6763727168103257,\n",
              "   7: 1.4171210705967245,\n",
              "   8: 34.39525646775793,\n",
              "   9: 0.529694103886321,\n",
              "   10: 3.466723763918019,\n",
              "   11: 0.2500161277897095,\n",
              "   12: 0.7924454178612222,\n",
              "   13: 2.82850589787267,\n",
              "   14: 7.796774846668799,\n",
              "   15: 1.3541517291869711},\n",
              "  15: {0: 0.8212506523126764,\n",
              "   1: 5.331609854880288,\n",
              "   2: 0.2528950093769027,\n",
              "   3: 2.601998851958287,\n",
              "   4: 46.92542865905865,\n",
              "   5: 0.20309641015038268,\n",
              "   6: 1.3477606122319363,\n",
              "   7: 5.823807116193377,\n",
              "   8: 48.16820445343513,\n",
              "   9: 5.91068936686859,\n",
              "   10: 5.7267092558780375,\n",
              "   11: 4.307167473666297,\n",
              "   12: 6.165420257415073,\n",
              "   13: 0.2208506803564822,\n",
              "   14: 1.2801700262951468,\n",
              "   15: 0.4759377277582698}},\n",
              " 2: {0: {0: 4.254009420007548,\n",
              "   1: 1.9259132915135027,\n",
              "   2: 15.101753424189106,\n",
              "   3: 12.516524108013543,\n",
              "   4: 1.4080613262884016,\n",
              "   5: 3.8971534680846354,\n",
              "   6: 4.139502625888767,\n",
              "   7: 0.9380950274994961,\n",
              "   8: 3.1267836430732423,\n",
              "   9: 7.025488790107722,\n",
              "   10: 2.584474340113891,\n",
              "   11: 2.9319437254412177,\n",
              "   12: 5.545225764524654,\n",
              "   13: 6.783412958880763,\n",
              "   14: 1.3089820466927469,\n",
              "   15: 2.4290758522302216},\n",
              "  1: {0: 1.9159584596773511,\n",
              "   1: 7.742794755324513,\n",
              "   2: 2.0361388312909785,\n",
              "   3: 3.898397653075146,\n",
              "   4: 4.48804228602509,\n",
              "   5: 2.09300471718471,\n",
              "   6: 0.8647309456042622,\n",
              "   7: 1.1126308887679484,\n",
              "   8: 1.2069530966553361,\n",
              "   9: 3.477154928032902,\n",
              "   10: 2.7035336611096508,\n",
              "   11: 2.9217825646862923,\n",
              "   12: 3.056893364502561,\n",
              "   13: 4.921504515694564,\n",
              "   14: 1.3058737944276295,\n",
              "   15: 10.700638702979182},\n",
              "  2: {0: 1.5923200342970683,\n",
              "   1: 3.1789905468922712,\n",
              "   2: 4.852973258303706,\n",
              "   3: 2.728307215757668,\n",
              "   4: 1.4390748963007498,\n",
              "   5: 12.203330229111081,\n",
              "   6: 6.785057680105748,\n",
              "   7: 6.542580794039755,\n",
              "   8: 1.3328080207792765,\n",
              "   9: 5.708479282910089,\n",
              "   10: 6.55629903574263,\n",
              "   11: 3.268592500454126,\n",
              "   12: 2.7122602440404755,\n",
              "   13: 2.0223969691493977,\n",
              "   14: 1.987242768642762,\n",
              "   15: 4.757767489009821},\n",
              "  3: {0: 1.0835495452332735,\n",
              "   1: 5.473872136430179,\n",
              "   2: 5.375959118611254,\n",
              "   3: 4.880890658082244,\n",
              "   4: 4.03146866998979,\n",
              "   5: 2.4036789049422667,\n",
              "   6: 12.96660553962273,\n",
              "   7: 0.624560955225024,\n",
              "   8: 2.0281229650695902,\n",
              "   9: 3.2589054473624444,\n",
              "   10: 1.2150532260046698,\n",
              "   11: 9.944237703750833,\n",
              "   12: 8.639142936817708,\n",
              "   13: 2.908702194832577,\n",
              "   14: 1.896607280928563,\n",
              "   15: 0.8881055227988095},\n",
              "  4: {0: 2.805488401220726,\n",
              "   1: 5.231121754375845,\n",
              "   2: 4.27885812094738,\n",
              "   3: 6.415316042006943,\n",
              "   4: 2.2591756016376996,\n",
              "   5: 6.35838442401443,\n",
              "   6: 5.98259738174559,\n",
              "   7: 14.942439154434034,\n",
              "   8: 6.608847271569601,\n",
              "   9: 7.368542155686179,\n",
              "   10: 7.8205181610501135,\n",
              "   11: 3.1588739611812318,\n",
              "   12: 1.5381388488102599,\n",
              "   13: 1.5967930750663164,\n",
              "   14: 3.7486960057297587,\n",
              "   15: 1.8422577615146474},\n",
              "  5: {0: 2.885760918121621,\n",
              "   1: 9.976579835721655,\n",
              "   2: 4.494208311641622,\n",
              "   3: 20.070717762932194,\n",
              "   4: 5.9474903842134506,\n",
              "   5: 0.9632197174326846,\n",
              "   6: 1.1969790178257422,\n",
              "   7: 1.6568632182112983,\n",
              "   8: 23.3303897605269,\n",
              "   9: 2.9108025048589576,\n",
              "   10: 7.413107573605424,\n",
              "   11: 3.0743007207332624,\n",
              "   12: 9.530323784335913,\n",
              "   13: 3.2588126774080304,\n",
              "   14: 1.0978526180963166,\n",
              "   15: 1.6954244164940226},\n",
              "  6: {0: 2.7714937240478634,\n",
              "   1: 4.258385403858604,\n",
              "   2: 2.8256157937218207,\n",
              "   3: 2.101501985025233,\n",
              "   4: 6.989334508411486,\n",
              "   5: 6.778812438979639,\n",
              "   6: 3.0731884332921755,\n",
              "   7: 1.5843666310592306,\n",
              "   8: 3.9664717920109323,\n",
              "   9: 8.353185832246528,\n",
              "   10: 3.5959869124836157,\n",
              "   11: 6.377427882557222,\n",
              "   12: 4.010194416629997,\n",
              "   13: 3.162290895842972,\n",
              "   14: 1.7459975899334927,\n",
              "   15: 7.840943400888041},\n",
              "  7: {0: 6.085517173098603,\n",
              "   1: 10.139585132526374,\n",
              "   2: 20.793947506566607,\n",
              "   3: 2.81541972330605,\n",
              "   4: 1.5197152294838125,\n",
              "   5: 6.762690366340829,\n",
              "   6: 9.48147212605006,\n",
              "   7: 3.2973108341894863,\n",
              "   8: 15.472086365752094,\n",
              "   9: 2.7510081198040552,\n",
              "   10: 2.625210631669514,\n",
              "   11: 5.279130645339044,\n",
              "   12: 11.559745343575319,\n",
              "   13: 3.5467521542071494,\n",
              "   14: 3.3498986613157395,\n",
              "   15: 2.6172220734722504},\n",
              "  8: {0: 2.5206949076234206,\n",
              "   1: 2.130024236072578,\n",
              "   2: 3.4366085559668846,\n",
              "   3: 3.344323951170229,\n",
              "   4: 3.90810540842543,\n",
              "   5: 5.106923025646768,\n",
              "   6: 5.160476325145908,\n",
              "   7: 9.748382922074764,\n",
              "   8: 12.213831929948304,\n",
              "   9: 3.2491924661198475,\n",
              "   10: 2.8695724252841512,\n",
              "   11: 9.19784510401691,\n",
              "   12: 3.78336317750812,\n",
              "   13: 1.1264396343958252,\n",
              "   14: 0.526591266748258,\n",
              "   15: 5.2306273751261685},\n",
              "  9: {0: 2.5316989751590695,\n",
              "   1: 2.0098355078276855,\n",
              "   2: 11.369850994026436,\n",
              "   3: 2.9411061441860387,\n",
              "   4: 1.499987985643935,\n",
              "   5: 2.8691871298124747,\n",
              "   6: 8.90518297319326,\n",
              "   7: 2.4786403836204953,\n",
              "   8: 0.5986959701055,\n",
              "   9: 3.4398749447889236,\n",
              "   10: 2.980664259458281,\n",
              "   11: 2.5499495105460444,\n",
              "   12: 3.813697179971437,\n",
              "   13: 10.12087560902189,\n",
              "   14: 1.8068980141231208,\n",
              "   15: 2.7540430892961254},\n",
              "  10: {0: 3.361678750070527,\n",
              "   1: 6.922849233627419,\n",
              "   2: 1.8253964438566885,\n",
              "   3: 9.05092586581602,\n",
              "   4: 8.059255871953203,\n",
              "   5: 1.6368547548246206,\n",
              "   6: 4.290697022076681,\n",
              "   7: 13.543527710965918,\n",
              "   8: 7.647398284226318,\n",
              "   9: 1.5049392531586854,\n",
              "   10: 5.275051431955218,\n",
              "   11: 3.651789740599492,\n",
              "   12: 4.723246063564922,\n",
              "   13: 1.8741990825124115,\n",
              "   14: 5.5840753549250195,\n",
              "   15: 2.094802366166667},\n",
              "  11: {0: 2.092465035267919,\n",
              "   1: 2.3705553322186694,\n",
              "   2: 1.5557215355027192,\n",
              "   3: 1.8480749925948206,\n",
              "   4: 3.7564386409867887,\n",
              "   5: 4.675705873905997,\n",
              "   6: 2.989101574291064,\n",
              "   7: 2.5310575150191292,\n",
              "   8: 4.984203620298697,\n",
              "   9: 6.61014914123694,\n",
              "   10: 2.838243121024836,\n",
              "   11: 6.346400210885735,\n",
              "   12: 8.290607013513716,\n",
              "   13: 9.768748925401674,\n",
              "   14: 11.532885335476713,\n",
              "   15: 3.7820904716335817},\n",
              "  12: {0: 17.881649625152566,\n",
              "   1: 2.5585716661271567,\n",
              "   2: 5.990687223670442,\n",
              "   3: 8.542052344251955,\n",
              "   4: 1.8017897845189936,\n",
              "   5: 7.810305087415624,\n",
              "   6: 3.876871896238919,\n",
              "   7: 4.927801192699633,\n",
              "   8: 21.063534681365084,\n",
              "   9: 1.8111642419755305,\n",
              "   10: 0.6552540126663617,\n",
              "   11: 2.459992376751452,\n",
              "   12: 1.6658288194016289,\n",
              "   13: 0.581160464688614,\n",
              "   14: 2.3499997140681437,\n",
              "   15: 4.315720341373124},\n",
              "  13: {0: 2.0209005555627377,\n",
              "   1: 1.6277677778685016,\n",
              "   2: 1.1669622002746693,\n",
              "   3: 43.17992851143903,\n",
              "   4: 4.05314446778036,\n",
              "   5: 1.5098172001692334,\n",
              "   6: 0.9879729947319663,\n",
              "   7: 4.078849464558667,\n",
              "   8: 3.973301200654504,\n",
              "   9: 1.4332485967673805,\n",
              "   10: 1.9215672243066366,\n",
              "   11: 4.516354387646985,\n",
              "   12: 3.7287513890060606,\n",
              "   13: 5.106607712164131,\n",
              "   14: 2.849419001705175,\n",
              "   15: 1.9060414457897166},\n",
              "  14: {0: 4.28209352043619,\n",
              "   1: 1.393444605000923,\n",
              "   2: 7.1814656023015955,\n",
              "   3: 18.309714228053224,\n",
              "   4: 6.7870110410219375,\n",
              "   5: 6.403112813231033,\n",
              "   6: 1.6857996056252817,\n",
              "   7: 2.021470820213647,\n",
              "   8: 4.476754355685603,\n",
              "   9: 0.5622363495427682,\n",
              "   10: 2.1082345583083137,\n",
              "   11: 2.9096980796508642,\n",
              "   12: 7.5157042683452655,\n",
              "   13: 10.001204400977908,\n",
              "   14: 2.6531626132657324,\n",
              "   15: 2.564250048773058},\n",
              "  15: {0: 3.8588093794855043,\n",
              "   1: 1.2382243011073613,\n",
              "   2: 2.7703985249376943,\n",
              "   3: 1.2586729409634727,\n",
              "   4: 2.98901013927118,\n",
              "   5: 1.0711987764771906,\n",
              "   6: 1.5831066755794527,\n",
              "   7: 1.014645461833016,\n",
              "   8: 11.120059061873471,\n",
              "   9: 3.2245409269464607,\n",
              "   10: 3.4163669381644235,\n",
              "   11: 1.2798633045647323,\n",
              "   12: 4.019497374614925,\n",
              "   13: 6.939398258923232,\n",
              "   14: 1.5749002888365484,\n",
              "   15: 4.683671315702911},\n",
              "  16: {0: 5.43494042343182,\n",
              "   1: 2.7683882572079352,\n",
              "   2: 6.601955098995983,\n",
              "   3: 1.9758568177266398,\n",
              "   4: 3.038145744415502,\n",
              "   5: 3.839807708926299,\n",
              "   6: 9.45958188057153,\n",
              "   7: 3.422443712065444,\n",
              "   8: 1.2550232006757716,\n",
              "   9: 3.4159252797750645,\n",
              "   10: 2.2288340679383034,\n",
              "   11: 2.715642795423254,\n",
              "   12: 1.366547293330542,\n",
              "   13: 4.479128087295861,\n",
              "   14: 7.3104219229309635,\n",
              "   15: 1.5380155643259357},\n",
              "  17: {0: 2.4508071327218905,\n",
              "   1: 2.2789056978837308,\n",
              "   2: 5.916906511520697,\n",
              "   3: 2.1381393748407493,\n",
              "   4: 2.088227285313578,\n",
              "   5: 1.2635933388541143,\n",
              "   6: 3.295414425163756,\n",
              "   7: 9.761749712214254,\n",
              "   8: 1.1764246903578424,\n",
              "   9: 8.208267335092692,\n",
              "   10: 4.612412514717249,\n",
              "   11: 4.545241724237026,\n",
              "   12: 4.416178433162123,\n",
              "   13: 4.865745976752177,\n",
              "   14: 8.687152298629703,\n",
              "   15: 4.148443998974441},\n",
              "  18: {0: 3.280880055118329,\n",
              "   1: 5.205424495901383,\n",
              "   2: 4.9518716402200695,\n",
              "   3: 0.989767712423052,\n",
              "   4: 1.1771842384258324,\n",
              "   5: 1.4110836010236527,\n",
              "   6: 3.6594660200661866,\n",
              "   7: 2.6624034365760547,\n",
              "   8: 5.760709588288302,\n",
              "   9: 4.222942726926323,\n",
              "   10: 8.939186173463678,\n",
              "   11: 1.5753220496384652,\n",
              "   12: 7.3482346644715655,\n",
              "   13: 3.8120639613538616,\n",
              "   14: 2.088656423481873,\n",
              "   15: 1.2876870094621409},\n",
              "  19: {0: 5.286878562515277,\n",
              "   1: 2.856949294811299,\n",
              "   2: 1.268500698911808,\n",
              "   3: 24.52182446246397,\n",
              "   4: 5.680279915601801,\n",
              "   5: 10.008432125416602,\n",
              "   6: 5.368667939805826,\n",
              "   7: 2.8397708110199225,\n",
              "   8: 1.2519941548139417,\n",
              "   9: 2.006534701858708,\n",
              "   10: 2.46206817156741,\n",
              "   11: 0.8520142743783872,\n",
              "   12: 0.9517220240538518,\n",
              "   13: 3.1952074108470265,\n",
              "   14: 7.725413396602638,\n",
              "   15: 3.470089340500674},\n",
              "  20: {0: 4.4951339510918675,\n",
              "   1: 7.665527410068192,\n",
              "   2: 0.49611777394111534,\n",
              "   3: 0.7296331840728378,\n",
              "   4: 3.6331479481663203,\n",
              "   5: 5.597779251215248,\n",
              "   6: 5.1404184428823765,\n",
              "   7: 8.058057445311615,\n",
              "   8: 3.5531652464742725,\n",
              "   9: 3.0880043287370307,\n",
              "   10: 9.582985452158226,\n",
              "   11: 3.6080286131269355,\n",
              "   12: 2.5657120006124,\n",
              "   13: 5.68695526812971,\n",
              "   14: 12.439267517492064,\n",
              "   15: 13.06626838803369},\n",
              "  21: {0: 2.5552362856085677,\n",
              "   1: 1.4828944450108634,\n",
              "   2: 13.797348017217587,\n",
              "   3: 11.443077403478247,\n",
              "   4: 48.24381574503318,\n",
              "   5: 2.8513786103293266,\n",
              "   6: 1.7913804287012,\n",
              "   7: 0.221183388206199,\n",
              "   8: 2.7846576461525387,\n",
              "   9: 0.7710193455495791,\n",
              "   10: 2.036950388496703,\n",
              "   11: 2.469151172100369,\n",
              "   12: 3.3949464063742285,\n",
              "   13: 6.87590982466076,\n",
              "   14: 0.6259296301397259,\n",
              "   15: 1.8759465968127649},\n",
              "  22: {0: 1.2475844197692512,\n",
              "   1: 11.013409031172428,\n",
              "   2: 2.8344774533980566,\n",
              "   3: 5.420475791281453,\n",
              "   4: 2.891565668572838,\n",
              "   5: 4.131989164269234,\n",
              "   6: 4.553419018215249,\n",
              "   7: 1.031137761065304,\n",
              "   8: 3.2303178511955304,\n",
              "   9: 2.229882064612104,\n",
              "   10: 4.9446082602886525,\n",
              "   11: 6.248860843022612,\n",
              "   12: 8.357468337344095,\n",
              "   13: 3.2976608457033403,\n",
              "   14: 2.979777070324606,\n",
              "   15: 1.6875808057101767},\n",
              "  23: {0: 1.247776023150433,\n",
              "   1: 1.8304368980494177,\n",
              "   2: 2.7814100151647034,\n",
              "   3: 1.3627758353375015,\n",
              "   4: 1.657536733426912,\n",
              "   5: 5.979773288452089,\n",
              "   6: 3.63148706106477,\n",
              "   7: 3.2232825015859055,\n",
              "   8: 3.501489326525211,\n",
              "   9: 1.0788826828745894,\n",
              "   10: 1.0285936022826596,\n",
              "   11: 6.735918913105718,\n",
              "   12: 1.9646451109138257,\n",
              "   13: 1.2844593819653596,\n",
              "   14: 3.828311497423054,\n",
              "   15: 2.5782606833955777},\n",
              "  24: {0: 2.4493071859583053,\n",
              "   1: 5.385552611955939,\n",
              "   2: 2.495268990491846,\n",
              "   3: 6.522117928263421,\n",
              "   4: 1.294259578684233,\n",
              "   5: 4.369535107971382,\n",
              "   6: 1.003499666962954,\n",
              "   7: 3.637939462598524,\n",
              "   8: 32.019685077797966,\n",
              "   9: 4.149378538765624,\n",
              "   10: 2.730948349906555,\n",
              "   11: 13.379767679779057,\n",
              "   12: 2.1199227271211267,\n",
              "   13: 4.309802822835037,\n",
              "   14: 1.371348873724102,\n",
              "   15: 4.568029095281261},\n",
              "  25: {0: 2.382039127528745,\n",
              "   1: 5.965863231569246,\n",
              "   2: 1.232735675844482,\n",
              "   3: 4.360568403463324,\n",
              "   4: 2.9514112479517935,\n",
              "   5: 8.418329643657145,\n",
              "   6: 4.379959823482503,\n",
              "   7: 2.587012299625621,\n",
              "   8: 1.6625592782622,\n",
              "   9: 1.0332907145803842,\n",
              "   10: 1.7992515745912803,\n",
              "   11: 2.296484725444822,\n",
              "   12: 4.539720030317321,\n",
              "   13: 3.3039189399624527,\n",
              "   14: 0.38364821101286084,\n",
              "   15: 6.3419329706329695},\n",
              "  26: {0: 2.900979767168748,\n",
              "   1: 1.253371639587122,\n",
              "   2: 1.989005969514085,\n",
              "   3: 2.5258904912294,\n",
              "   4: 2.609227435078597,\n",
              "   5: 4.6977619633959256,\n",
              "   6: 0.585067463194195,\n",
              "   7: 3.0117265304026315,\n",
              "   8: 1.8555327042758596,\n",
              "   9: 109.40424662058402,\n",
              "   10: 1.7088063474391082,\n",
              "   11: 0.4174810015964553,\n",
              "   12: 3.196081313904782,\n",
              "   13: 1.412474225455485,\n",
              "   14: 108.5174520275974,\n",
              "   15: 14.95796241125993},\n",
              "  27: {0: 7.4150295278249505,\n",
              "   1: 0.6228343602249146,\n",
              "   2: 6.450531900738133,\n",
              "   3: 11.555355618315517,\n",
              "   4: 21.636055054881705,\n",
              "   5: 2.1495437839631975,\n",
              "   6: 5.272681335361953,\n",
              "   7: 3.5000784544832477,\n",
              "   8: 0.8834713265352238,\n",
              "   9: 2.3466662161847434,\n",
              "   10: 1.8931451710580491,\n",
              "   11: 4.260204473619847,\n",
              "   12: 2.5167390439056723,\n",
              "   13: 5.290393030632355,\n",
              "   14: 0.8541826942417463,\n",
              "   15: 2.2517771973667506},\n",
              "  28: {0: 3.3361683164851015,\n",
              "   1: 2.9756696356436225,\n",
              "   2: 6.1708464543482755,\n",
              "   3: 10.603511486136966,\n",
              "   4: 7.884905395513461,\n",
              "   5: 1.058569144234497,\n",
              "   6: 1.1339907650215206,\n",
              "   7: 2.6642584582691837,\n",
              "   8: 9.470711014024724,\n",
              "   9: 10.13266866642552,\n",
              "   10: 5.848916201063819,\n",
              "   11: 3.0746568998594483,\n",
              "   12: 1.8806936707933664,\n",
              "   13: 3.1904812520238504,\n",
              "   14: 5.510761854311513,\n",
              "   15: 1.9930980704819121},\n",
              "  29: {0: 1.6237999737442559,\n",
              "   1: 3.035211781394425,\n",
              "   2: 1.9478012783138552,\n",
              "   3: 1.7241946220155955,\n",
              "   4: 5.832909878619598,\n",
              "   5: 9.847034585445673,\n",
              "   6: 1.4913021399846396,\n",
              "   7: 0.5055710511465641,\n",
              "   8: 126.66914556868116,\n",
              "   9: 1.9155548134015543,\n",
              "   10: 1.4744491400407647,\n",
              "   11: 5.607928247765858,\n",
              "   12: 157.82287994296854,\n",
              "   13: 1.8100836529099271,\n",
              "   14: 1.5171785808711926,\n",
              "   15: 0.5829608307908025},\n",
              "  30: {0: 5.395964336177666,\n",
              "   1: 5.806436934511061,\n",
              "   2: 3.755726523795434,\n",
              "   3: 1.952457174502884,\n",
              "   4: 1.7451948087634357,\n",
              "   5: 1.6704475772839673,\n",
              "   6: 2.9272283030630746,\n",
              "   7: 4.0666960423133975,\n",
              "   8: 4.345572488289268,\n",
              "   9: 3.64032774711941,\n",
              "   10: 1.4474059775236499,\n",
              "   11: 1.7657363748177057,\n",
              "   12: 8.586144547193527,\n",
              "   13: 2.31347889854889,\n",
              "   14: 5.944411777972542,\n",
              "   15: 9.509777575533755},\n",
              "  31: {0: 3.492188594899597,\n",
              "   1: 4.689682359370832,\n",
              "   2: 3.340848131997224,\n",
              "   3: 8.86239831095643,\n",
              "   4: 4.92388035469256,\n",
              "   5: 1.7752521603117537,\n",
              "   6: 2.137287943187639,\n",
              "   7: 6.332552101756496,\n",
              "   8: 1.78176170931193,\n",
              "   9: 0.8595171590993254,\n",
              "   10: 2.9733088252710935,\n",
              "   11: 16.13330954697824,\n",
              "   12: 2.236439462656723,\n",
              "   13: 41.255554346282,\n",
              "   14: 5.046455628780507,\n",
              "   15: 2.4078775677948814}},\n",
              " 3: {0: {0: 1.5171286543032088,\n",
              "   1: 7.316441072770931,\n",
              "   2: 2.841943594903837,\n",
              "   3: 2.1421380784316515,\n",
              "   4: 1.5292736304143506,\n",
              "   5: 1.9896659840927513,\n",
              "   6: 2.3645788003836596,\n",
              "   7: 12.01963544722167,\n",
              "   8: 1.225296107381426,\n",
              "   9: 1.9648043011733347,\n",
              "   10: 3.894542310116695,\n",
              "   11: 3.943274873965043,\n",
              "   12: 4.432689826172796,\n",
              "   13: 5.3691201979483525,\n",
              "   14: 4.032672948479951,\n",
              "   15: 1.00967015766047,\n",
              "   16: 3.5590663774884885,\n",
              "   17: 5.055606160213461,\n",
              "   18: 1.8826802546981876,\n",
              "   19: 2.5159416862104,\n",
              "   20: 1.8288397209945746,\n",
              "   21: 5.231355039258691,\n",
              "   22: 4.513393309832716,\n",
              "   23: 2.205740765353483,\n",
              "   24: 4.860142372216013,\n",
              "   25: 6.3013698898294175,\n",
              "   26: 5.4700684315609855,\n",
              "   27: 5.983477212775856,\n",
              "   28: 3.4093609766694777,\n",
              "   29: 5.124462710974598,\n",
              "   30: 6.499465199599667,\n",
              "   31: 1.6423710528080462},\n",
              "  1: {0: 6.506976983254467,\n",
              "   1: 1.9071660641938175,\n",
              "   2: 6.9243249805924725,\n",
              "   3: 3.5829423466282666,\n",
              "   4: 5.852024952101097,\n",
              "   5: 3.2476121394128006,\n",
              "   6: 1.3617571959867951,\n",
              "   7: 4.668036433125453,\n",
              "   8: 2.5380136255051284,\n",
              "   9: 2.3727818709502686,\n",
              "   10: 2.4826374754087253,\n",
              "   11: 1.8943225847690504,\n",
              "   12: 2.64240116480991,\n",
              "   13: 7.779508193522805,\n",
              "   14: 19.200158802790142,\n",
              "   15: 1.9020406896013506,\n",
              "   16: 3.0736263554451404,\n",
              "   17: 2.860981158875642,\n",
              "   18: 2.827663475878465,\n",
              "   19: 1.8471444475238887,\n",
              "   20: 13.534386238589006,\n",
              "   21: 3.5931654171462686,\n",
              "   22: 0.4656365758826737,\n",
              "   23: 1.320063770782737,\n",
              "   24: 4.060690223886379,\n",
              "   25: 4.537514086087969,\n",
              "   26: 1.8446242070084413,\n",
              "   27: 2.320615433067037,\n",
              "   28: 1.4901343107513947,\n",
              "   29: 3.7319676311681347,\n",
              "   30: 5.980255965855461,\n",
              "   31: 5.124391167877644},\n",
              "  2: {0: 3.3007249199980513,\n",
              "   1: 0.9801725778437148,\n",
              "   2: 5.591645011723691,\n",
              "   3: 2.8542722651767365,\n",
              "   4: 2.871833705282402,\n",
              "   5: 5.6816290443302355,\n",
              "   6: 1.6037887270451932,\n",
              "   7: 7.388144962391471,\n",
              "   8: 4.230590951691915,\n",
              "   9: 1.0003298077029836,\n",
              "   10: 2.7077628413902346,\n",
              "   11: 1.6738699039726994,\n",
              "   12: 2.7022595167396246,\n",
              "   13: 2.395125846672986,\n",
              "   14: 8.640064477497734,\n",
              "   15: 9.693688690897655,\n",
              "   16: 2.48786598377568,\n",
              "   17: 1.9898190115557688,\n",
              "   18: 4.341361962017675,\n",
              "   19: 4.140687345978448,\n",
              "   20: 2.5360860025108836,\n",
              "   21: 6.153958059938889,\n",
              "   22: 3.31563451801789,\n",
              "   23: 2.291469483643478,\n",
              "   24: 13.978101399852697,\n",
              "   25: 9.960319777459729,\n",
              "   26: 3.643185421615383,\n",
              "   27: 3.626219413605397,\n",
              "   28: 5.820040214673676,\n",
              "   29: 1.9987811596377414,\n",
              "   30: 4.046139760153281,\n",
              "   31: 2.8733919674963517},\n",
              "  3: {0: 4.1753039622902435,\n",
              "   1: 3.629143671753474,\n",
              "   2: 2.1767383514340226,\n",
              "   3: 4.914675163731484,\n",
              "   4: 5.827661749781001,\n",
              "   5: 2.710948557987908,\n",
              "   6: 16.13340519453022,\n",
              "   7: 7.674513041836933,\n",
              "   8: 2.5601803605362092,\n",
              "   9: 2.9280859270605775,\n",
              "   10: 1.922312129944751,\n",
              "   11: 3.3832211798028387,\n",
              "   12: 2.7282642380520823,\n",
              "   13: 3.051404930544255,\n",
              "   14: 0.9803744013816931,\n",
              "   15: 2.2577610367690952,\n",
              "   16: 8.737957311785658,\n",
              "   17: 6.430572477794436,\n",
              "   18: 6.584935554217731,\n",
              "   19: 2.935177856663029,\n",
              "   20: 3.64275821309144,\n",
              "   21: 3.1877793003860235,\n",
              "   22: 0.9245096193887333,\n",
              "   23: 3.233307718576931,\n",
              "   24: 5.204965111347625,\n",
              "   25: 0.925842523660285,\n",
              "   26: 3.798273444242829,\n",
              "   27: 1.4690218681240075,\n",
              "   28: 4.609185651831122,\n",
              "   29: 3.5205821922130953,\n",
              "   30: 2.133225893881682,\n",
              "   31: 3.8393072484016706},\n",
              "  4: {0: 3.6257969389319626,\n",
              "   1: 2.272105510506824,\n",
              "   2: 18.718456060965835,\n",
              "   3: 1.82134373617284,\n",
              "   4: 5.174515950182137,\n",
              "   5: 3.1436739001498126,\n",
              "   6: 4.61251428852793,\n",
              "   7: 9.911822865516012,\n",
              "   8: 0.7061199026281684,\n",
              "   9: 6.364209060629705,\n",
              "   10: 5.050064293060813,\n",
              "   11: 0.9659597036457284,\n",
              "   12: 2.1584172709263236,\n",
              "   13: 3.971591449203606,\n",
              "   14: 4.242277580447857,\n",
              "   15: 5.02558333486917,\n",
              "   16: 2.3096314939577596,\n",
              "   17: 3.542481931796063,\n",
              "   18: 5.9193040769950285,\n",
              "   19: 8.706935835302502,\n",
              "   20: 1.5766767175214906,\n",
              "   21: 1.3142690887468733,\n",
              "   22: 7.024879444593859,\n",
              "   23: 5.136691929501455,\n",
              "   24: 3.072233132974162,\n",
              "   25: 2.8517437742510285,\n",
              "   26: 1.393246427390128,\n",
              "   27: 1.2402451233166651,\n",
              "   28: 7.445768499342233,\n",
              "   29: 0.9187908632595767,\n",
              "   30: 9.219333101602441,\n",
              "   31: 8.443479202144893},\n",
              "  5: {0: 8.396818480027157,\n",
              "   1: 5.346278526404703,\n",
              "   2: 3.106911634145283,\n",
              "   3: 6.285051976527632,\n",
              "   4: 5.347045672228772,\n",
              "   5: 0.9976385182384734,\n",
              "   6: 4.046565792631681,\n",
              "   7: 3.1208905211091316,\n",
              "   8: 2.0448816719787155,\n",
              "   9: 2.3913725578072746,\n",
              "   10: 6.114757993569887,\n",
              "   11: 8.62850967242392,\n",
              "   12: 3.704506946928812,\n",
              "   13: 4.131485208019308,\n",
              "   14: 3.4229945776222297,\n",
              "   15: 4.73873497100943,\n",
              "   16: 9.275909662727926,\n",
              "   17: 5.3086754397648726,\n",
              "   18: 3.72404319640944,\n",
              "   19: 1.8784607135734324,\n",
              "   20: 4.1848378693684465,\n",
              "   21: 1.3217151082760152,\n",
              "   22: 2.103571442532404,\n",
              "   23: 3.607493298281633,\n",
              "   24: 1.7632528210172937,\n",
              "   25: 4.968953586786336,\n",
              "   26: 3.5933677482764104,\n",
              "   27: 1.2560909888949743,\n",
              "   28: 1.0433432181432898,\n",
              "   29: 1.6228360147430618,\n",
              "   30: 11.8389621755997,\n",
              "   31: 3.253793329606731},\n",
              "  6: {0: 4.93548553679029,\n",
              "   1: 3.586910637737117,\n",
              "   2: 2.026633305890164,\n",
              "   3: 6.059976605768245,\n",
              "   4: 6.494721775933118,\n",
              "   5: 3.6987175290104948,\n",
              "   6: 2.8331612425772095,\n",
              "   7: 5.367293722854756,\n",
              "   8: 4.070882477868848,\n",
              "   9: 3.9888335754013,\n",
              "   10: 4.4329276887051705,\n",
              "   11: 6.021348652876535,\n",
              "   12: 3.893485931264456,\n",
              "   13: 4.656174270190831,\n",
              "   14: 3.1313425501098933,\n",
              "   15: 2.8707415718267058,\n",
              "   16: 3.02582584783807,\n",
              "   17: 2.774886712752612,\n",
              "   18: 23.31640597905372,\n",
              "   19: 1.501105134970988,\n",
              "   20: 5.464565711170552,\n",
              "   21: 2.221943551480486,\n",
              "   22: 2.455973417689021,\n",
              "   23: 3.6431560346521734,\n",
              "   24: 2.4180310509850456,\n",
              "   25: 2.424168814180827,\n",
              "   26: 3.1876465002212875,\n",
              "   27: 7.131841002049018,\n",
              "   28: 1.6257735526816082,\n",
              "   29: 1.5237493622291305,\n",
              "   30: 2.9711210373936536,\n",
              "   31: 4.941196708986424},\n",
              "  7: {0: 5.184083865422473,\n",
              "   1: 4.083739100441974,\n",
              "   2: 5.927908323139302,\n",
              "   3: 2.594458623715839,\n",
              "   4: 11.425237876342528,\n",
              "   5: 2.851827314315671,\n",
              "   6: 4.022276769028449,\n",
              "   7: 4.7152291194544915,\n",
              "   8: 1.6696073307948534,\n",
              "   9: 4.979255746014996,\n",
              "   10: 5.5261964996646675,\n",
              "   11: 6.016619729355079,\n",
              "   12: 3.7437139518874196,\n",
              "   13: 1.6295959326545357,\n",
              "   14: 1.5785597298439549,\n",
              "   15: 7.708524649565682,\n",
              "   16: 4.234672143234979,\n",
              "   17: 2.118948628165922,\n",
              "   18: 4.24403324784384,\n",
              "   19: 5.205735813325462,\n",
              "   20: 2.1278552113059357,\n",
              "   21: 12.389299472294804,\n",
              "   22: 1.1480116275804941,\n",
              "   23: 1.7133571413498048,\n",
              "   24: 2.5039292595135967,\n",
              "   25: 8.064626210019394,\n",
              "   26: 1.058400198358814,\n",
              "   27: 3.8084293690773254,\n",
              "   28: 1.9925088482358853,\n",
              "   29: 12.024225556574716,\n",
              "   30: 5.499296487975023,\n",
              "   31: 2.3698439537985303},\n",
              "  8: {0: 5.601693037976685,\n",
              "   1: 2.4491291571042595,\n",
              "   2: 5.232969962871138,\n",
              "   3: 3.1605716502538526,\n",
              "   4: 2.502523550281976,\n",
              "   5: 0.8532746666460929,\n",
              "   6: 5.14643478141743,\n",
              "   7: 1.4647963249833178,\n",
              "   8: 4.837085563246373,\n",
              "   9: 4.503176008443756,\n",
              "   10: 3.405083397987603,\n",
              "   11: 2.9064561123507584,\n",
              "   12: 2.9672441560424705,\n",
              "   13: 7.711627392278154,\n",
              "   14: 2.8176025004341168,\n",
              "   15: 4.481002464170095,\n",
              "   16: 0.8978936052544662,\n",
              "   17: 2.9335982550458404,\n",
              "   18: 6.909307150251602,\n",
              "   19: 3.410522094398824,\n",
              "   20: 5.1482943017964455,\n",
              "   21: 3.8311133483606863,\n",
              "   22: 2.4611675040603576,\n",
              "   23: 1.7850605597935105,\n",
              "   24: 1.8546654021654791,\n",
              "   25: 2.747969081169493,\n",
              "   26: 2.278579273948485,\n",
              "   27: 5.5246039583447875,\n",
              "   28: 4.301892595194979,\n",
              "   29: 2.852504201796765,\n",
              "   30: 6.045339206321001,\n",
              "   31: 0.6967798531424402},\n",
              "  9: {0: 4.4682870506975565,\n",
              "   1: 5.138678276887184,\n",
              "   2: 3.9797513099537944,\n",
              "   3: 2.487542298400721,\n",
              "   4: 7.017964659328261,\n",
              "   5: 1.6333627309016883,\n",
              "   6: 1.4781931816745595,\n",
              "   7: 3.353386258579708,\n",
              "   8: 4.604712448044744,\n",
              "   9: 2.0352332067533956,\n",
              "   10: 5.747911961995458,\n",
              "   11: 1.7659073060429562,\n",
              "   12: 6.620905162463849,\n",
              "   13: 8.738935240088324,\n",
              "   14: 4.686979811511993,\n",
              "   15: 1.9502753817691163,\n",
              "   16: 5.876604931291502,\n",
              "   17: 4.179749957683137,\n",
              "   18: 1.988592786553723,\n",
              "   19: 6.592543336902365,\n",
              "   20: 1.2851849214677902,\n",
              "   21: 1.8677501722700467,\n",
              "   22: 10.265349629989196,\n",
              "   23: 1.4810138514001872,\n",
              "   24: 7.284632210518559,\n",
              "   25: 8.1844650525943,\n",
              "   26: 0.5418326553864432,\n",
              "   27: 7.065102957017448,\n",
              "   28: 4.735171542386762,\n",
              "   29: 2.5165986645627596,\n",
              "   30: 5.1828950694834806,\n",
              "   31: 3.443496678887963},\n",
              "  10: {0: 4.5057164992236896,\n",
              "   1: 3.4285062792536607,\n",
              "   2: 3.773298730039145,\n",
              "   3: 2.748063978162957,\n",
              "   4: 6.982824306332405,\n",
              "   5: 5.650299590409,\n",
              "   6: 0.7668699269119251,\n",
              "   7: 4.826024562850593,\n",
              "   8: 2.007458930105248,\n",
              "   9: 12.057752566562428,\n",
              "   10: 4.37821802677975,\n",
              "   11: 7.352031738837466,\n",
              "   12: 3.4257635773296884,\n",
              "   13: 15.81200989528977,\n",
              "   14: 3.7945334885086544,\n",
              "   15: 5.472484895425989,\n",
              "   16: 2.214764101744632,\n",
              "   17: 5.685570547686096,\n",
              "   18: 2.0573717535544658,\n",
              "   19: 6.209996858719757,\n",
              "   20: 6.7107539486652765,\n",
              "   21: 11.595994407029096,\n",
              "   22: 4.9943857136280165,\n",
              "   23: 3.15861673145395,\n",
              "   24: 6.052217314644299,\n",
              "   25: 12.798364901268021,\n",
              "   26: 4.124421921892967,\n",
              "   27: 2.348958163171711,\n",
              "   28: 1.3199323211807794,\n",
              "   29: 5.750747264884053,\n",
              "   30: 2.8229013866573984,\n",
              "   31: 3.144415946771321},\n",
              "  11: {0: 2.2969017064811,\n",
              "   1: 3.6647476056858714,\n",
              "   2: 1.9110467351541849,\n",
              "   3: 3.122818139326406,\n",
              "   4: 6.2626203456267255,\n",
              "   5: 3.8199279453129544,\n",
              "   6: 4.196609895070614,\n",
              "   7: 2.262075301034141,\n",
              "   8: 3.750980439428931,\n",
              "   9: 7.122855025576952,\n",
              "   10: 5.57230451935032,\n",
              "   11: 2.558886370952078,\n",
              "   12: 4.752566006412685,\n",
              "   13: 1.5906909344852647,\n",
              "   14: 3.2608436114764574,\n",
              "   15: 1.8928249640759454,\n",
              "   16: 1.6314959891726033,\n",
              "   17: 5.559022826339535,\n",
              "   18: 3.126020602221493,\n",
              "   19: 1.0168932532825208,\n",
              "   20: 5.345486869709051,\n",
              "   21: 2.9392655592355825,\n",
              "   22: 5.450476304971164,\n",
              "   23: 4.105538940785182,\n",
              "   24: 2.811410361252317,\n",
              "   25: 4.190414569899046,\n",
              "   26: 4.7073879526658695,\n",
              "   27: 4.076295537639192,\n",
              "   28: 3.9690785142190275,\n",
              "   29: 3.462228761940091,\n",
              "   30: 2.930630737097321,\n",
              "   31: 1.7768673088953024},\n",
              "  12: {0: 8.330025421135586,\n",
              "   1: 1.8400751322840345,\n",
              "   2: 1.4008756186324915,\n",
              "   3: 1.77710371570548,\n",
              "   4: 45.50527166907851,\n",
              "   5: 6.671032377675413,\n",
              "   6: 12.44554961316382,\n",
              "   7: 0.8351807325866001,\n",
              "   8: 19.425666545106942,\n",
              "   9: 2.4142136409607144,\n",
              "   10: 5.85937922569763,\n",
              "   11: 4.000906803263911,\n",
              "   12: 5.256611175510856,\n",
              "   13: 1.943976075103854,\n",
              "   14: 4.095774108755884,\n",
              "   15: 2.8678976826844056,\n",
              "   16: 6.614790063912741,\n",
              "   17: 3.8354166668857435,\n",
              "   18: 2.5682366032100816,\n",
              "   19: 6.6463239370602984,\n",
              "   20: 16.729478112522393,\n",
              "   21: 1.1414360487944337,\n",
              "   22: 2.290613760894193,\n",
              "   23: 2.757186052837865,\n",
              "   24: 2.0885424334475986,\n",
              "   25: 1.5250540327081203,\n",
              "   26: 4.958524925219244,\n",
              "   27: 2.2085832244188426,\n",
              "   28: 2.311620082271364,\n",
              "   29: 2.7133240656685276,\n",
              "   30: 10.766263171731119,\n",
              "   31: 2.54860406682693},\n",
              "  13: {0: 9.27167731791691,\n",
              "   1: 5.294263242611272,\n",
              "   2: 3.2234772379126415,\n",
              "   3: 7.317599152649977,\n",
              "   4: 2.4687449232843233,\n",
              "   5: 4.801046517926127,\n",
              "   6: 1.0923156871489017,\n",
              "   7: 2.201286607138724,\n",
              "   8: 7.6808270585253435,\n",
              "   9: 0.5695736699918463,\n",
              "   10: 2.377718363145968,\n",
              "   11: 4.831030035064078,\n",
              "   12: 3.752238245560335,\n",
              "   13: 2.5997214027004123,\n",
              "   14: 4.538073362423403,\n",
              "   15: 0.9692148274178888,\n",
              "   16: 2.8060170853362387,\n",
              "   17: 2.704330394530598,\n",
              "   18: 4.7539695776859014,\n",
              "   19: 1.1841134676432397,\n",
              "   20: 6.996292184698886,\n",
              "   21: 12.335294765030335,\n",
              "   22: 2.2981626489534,\n",
              "   23: 3.7038595824597436,\n",
              "   24: 4.861613903912721,\n",
              "   25: 1.6109001395473437,\n",
              "   26: 2.7051825430892875,\n",
              "   27: 1.093192520098687,\n",
              "   28: 1.8031575852497168,\n",
              "   29: 5.1779967604223405,\n",
              "   30: 0.8675256459996272,\n",
              "   31: 2.540362061884225},\n",
              "  14: {0: 2.3981671435368463,\n",
              "   1: 3.269278195679317,\n",
              "   2: 2.0645494079890256,\n",
              "   3: 6.27249715566345,\n",
              "   4: 1.7763643989271478,\n",
              "   5: 0.94861525234801,\n",
              "   6: 2.1565081429815303,\n",
              "   7: 8.979980764023459,\n",
              "   8: 3.112591297094177,\n",
              "   9: 1.7688620071393775,\n",
              "   10: 6.6921982525890185,\n",
              "   11: 1.2511475982219478,\n",
              "   12: 2.4541701401762146,\n",
              "   13: 8.561304005970948,\n",
              "   14: 2.8798778122217312,\n",
              "   15: 1.5158078803080637,\n",
              "   16: 7.03513367490957,\n",
              "   17: 2.762006418670828,\n",
              "   18: 4.0411426594096636,\n",
              "   19: 6.034971302793421,\n",
              "   20: 2.6879315783627256,\n",
              "   21: 5.2187163972968005,\n",
              "   22: 2.87449651778702,\n",
              "   23: 3.4932559539071177,\n",
              "   24: 3.9299810517237574,\n",
              "   25: 3.8143941323531205,\n",
              "   26: 6.806082645599656,\n",
              "   27: 8.002881447935936,\n",
              "   28: 0.8065928624293249,\n",
              "   29: 1.4127608186478642,\n",
              "   30: 6.009541792234042,\n",
              "   31: 3.7675532977543784},\n",
              "  15: {0: 2.5310665878910963,\n",
              "   1: 8.39859664362576,\n",
              "   2: 1.0687897365769066,\n",
              "   3: 13.452700084315925,\n",
              "   4: 4.182358560193606,\n",
              "   5: 6.932118378838573,\n",
              "   6: 2.043632196089513,\n",
              "   7: 6.827933883724686,\n",
              "   8: 4.366812670879296,\n",
              "   9: 3.2393143309253616,\n",
              "   10: 4.217040706595707,\n",
              "   11: 2.7011980185596203,\n",
              "   12: 6.608555278444641,\n",
              "   13: 3.5879231761681294,\n",
              "   14: 13.885885342933003,\n",
              "   15: 3.717478834925287,\n",
              "   16: 5.305547211009019,\n",
              "   17: 3.577326016225564,\n",
              "   18: 1.8263573946061888,\n",
              "   19: 5.316459045545301,\n",
              "   20: 3.171583966388329,\n",
              "   21: 6.457521786327023,\n",
              "   22: 6.882252426791685,\n",
              "   23: 4.417821655936223,\n",
              "   24: 4.323232837336647,\n",
              "   25: 3.5437090896269945,\n",
              "   26: 3.58099351903596,\n",
              "   27: 5.507796820758006,\n",
              "   28: 1.161161075388012,\n",
              "   29: 6.106271942558119,\n",
              "   30: 6.02222359809136,\n",
              "   31: 4.004301581256045},\n",
              "  16: {0: 1.565873103012316,\n",
              "   1: 7.351422000666915,\n",
              "   2: 5.012456275600975,\n",
              "   3: 4.69407978053897,\n",
              "   4: 2.4230211805133406,\n",
              "   5: 5.959588980216998,\n",
              "   6: 3.560952476690092,\n",
              "   7: 5.6433755772751795,\n",
              "   8: 2.5607259795732733,\n",
              "   9: 4.282752877129984,\n",
              "   10: 7.770309321801767,\n",
              "   11: 2.7282980679678874,\n",
              "   12: 3.272599785602889,\n",
              "   13: 2.838935293590556,\n",
              "   14: 7.962372335817361,\n",
              "   15: 0.965817655715165,\n",
              "   16: 4.2115382202936775,\n",
              "   17: 1.4499423502521174,\n",
              "   18: 2.4824926489299592,\n",
              "   19: 3.367526535012229,\n",
              "   20: 0.8377397468527021,\n",
              "   21: 1.181674449774637,\n",
              "   22: 8.104667930697772,\n",
              "   23: 3.0971035719968825,\n",
              "   24: 1.2283409232028206,\n",
              "   25: 2.6206247440863493,\n",
              "   26: 3.4187788800028986,\n",
              "   27: 2.0840580360046905,\n",
              "   28: 2.357650436981308,\n",
              "   29: 1.3503562255205308,\n",
              "   30: 2.5360739023335643,\n",
              "   31: 4.2872972437818255},\n",
              "  17: {0: 6.147878979931415,\n",
              "   1: 0.5898307023545212,\n",
              "   2: 1.8116133911698278,\n",
              "   3: 5.371500888052394,\n",
              "   4: 1.7577413410173344,\n",
              "   5: 0.47702917925091387,\n",
              "   6: 2.0810854202473132,\n",
              "   7: 2.9120429816228404,\n",
              "   8: 4.432396573143956,\n",
              "   9: 6.578652780150281,\n",
              "   10: 4.725049329589025,\n",
              "   11: 3.256645396549916,\n",
              "   12: 2.5230907465578705,\n",
              "   13: 6.958001001600241,\n",
              "   14: 4.610903039449576,\n",
              "   15: 3.409855750036462,\n",
              "   16: 6.355787663934085,\n",
              "   17: 1.9231930231944419,\n",
              "   18: 3.404024414103085,\n",
              "   19: 0.6760794022921577,\n",
              "   20: 3.9139954334906175,\n",
              "   21: 1.7000000428821216,\n",
              "   22: 7.090386105748324,\n",
              "   23: 2.8794890348226243,\n",
              "   24: 6.404480985563874,\n",
              "   25: 7.690237678888961,\n",
              "   26: 3.0557156918896853,\n",
              "   27: 3.2762668694695525,\n",
              "   28: 4.04696834396292,\n",
              "   29: 3.483926254688768,\n",
              "   30: 3.5027029537377365,\n",
              "   31: 2.350605710470301},\n",
              "  18: {0: 5.8771789262724115,\n",
              "   1: 6.61631241758673,\n",
              "   2: 14.895620400174007,\n",
              "   3: 1.3514173724319276,\n",
              "   4: 3.587170133335384,\n",
              "   5: 8.009805075043442,\n",
              "   6: 3.086042653329563,\n",
              "   7: 3.307782226404389,\n",
              "   8: 9.551364276534631,\n",
              "   9: 2.5006496423289084,\n",
              "   10: 5.712003495262963,\n",
              "   11: 1.1667804767934928,\n",
              "   12: 5.858330612515566,\n",
              "   13: 3.383236865391104,\n",
              "   14: 14.791961943557972,\n",
              "   15: 1.6074366873987795,\n",
              "   16: 6.055289542808072,\n",
              "   17: 5.537917804503552,\n",
              "   18: 1.761655588597021,\n",
              "   19: 1.487766671836891,\n",
              "   20: 14.666985698080751,\n",
              "   21: 11.574344869845113,\n",
              "   22: 13.990656778638249,\n",
              "   23: 1.9139127974817673,\n",
              "   24: 3.6900265540432216,\n",
              "   25: 1.443178294362468,\n",
              "   26: 1.574989635060911,\n",
              "   27: 13.85367395856089,\n",
              "   28: 2.6651253061752382,\n",
              "   29: 2.319749312000212,\n",
              "   30: 3.3253230890745007,\n",
              "   31: 13.985787157724095},\n",
              "  19: {0: 9.46812331457733,\n",
              "   1: 8.90485223248291,\n",
              "   2: 2.5422728500849097,\n",
              "   3: 4.690430829248383,\n",
              "   4: 1.6044478319259894,\n",
              "   5: 1.2881121162184406,\n",
              "   6: 7.09465257223816,\n",
              "   7: 2.3190652881276947,\n",
              "   8: 2.1987635733685393,\n",
              "   9: 1.2021800317834426,\n",
              "   10: 2.0941753532700194,\n",
              "   11: 10.731052166106169,\n",
              "   12: 1.7737295033672744,\n",
              "   13: 1.017782111858072,\n",
              "   14: 5.841611098834758,\n",
              "   15: 3.7765581965386334,\n",
              "   16: 7.4351818706627375,\n",
              "   17: 5.09227808943113,\n",
              "   18: 5.41501455802536,\n",
              "   19: 4.982403857874175,\n",
              "   20: 2.329962523895568,\n",
              "   21: 2.4385399640930325,\n",
              "   22: 4.364104845998946,\n",
              "   23: 5.825933053273969,\n",
              "   24: 1.025316074974353,\n",
              "   25: 3.6741407930374774,\n",
              "   26: 6.438948749349257,\n",
              "   27: 6.144345192673901,\n",
              "   28: 4.545893325525653,\n",
              "   29: 8.520516917011367,\n",
              "   30: 2.483891983405664,\n",
              "   31: 2.3171509467907576},\n",
              "  20: {0: 0.9100844405226998,\n",
              "   1: 1.3715788628044556,\n",
              "   2: 2.2490099897305407,\n",
              "   3: 2.0287358194747345,\n",
              "   4: 3.797462290802715,\n",
              "   5: 1.1184407123787534,\n",
              "   6: 3.75422658753712,\n",
              "   7: 5.729493730215692,\n",
              "   8: 2.803209464870579,\n",
              "   9: 2.0423077824537152,\n",
              "   10: 1.8403244930645168,\n",
              "   11: 1.4249013597407476,\n",
              "   12: 7.556060718864739,\n",
              "   13: 1.933735283740644,\n",
              "   14: 12.463151685554319,\n",
              "   15: 3.992773101314616,\n",
              "   16: 4.777495362695343,\n",
              "   17: 2.800536999227139,\n",
              "   18: 3.54741496187078,\n",
              "   19: 2.809561355704802,\n",
              "   20: 2.038850582165972,\n",
              "   21: 1.1815325189729542,\n",
              "   22: 2.693925546523876,\n",
              "   23: 2.0130036066949537,\n",
              "   24: 3.600754176556705,\n",
              "   25: 3.5213690266437627,\n",
              "   26: 1.34404914204105,\n",
              "   27: 2.3850040911323487,\n",
              "   28: 6.371103919887476,\n",
              "   29: 2.4009361838182337,\n",
              "   30: 32.56590867934472,\n",
              "   31: 2.879089531253901},\n",
              "  21: {0: 10.302898525197694,\n",
              "   1: 3.381206721229076,\n",
              "   2: 4.941875623177079,\n",
              "   3: 4.872063577292226,\n",
              "   4: 4.082450423748141,\n",
              "   5: 5.383982728279481,\n",
              "   6: 1.7293234599652123,\n",
              "   7: 4.050903423997495,\n",
              "   8: 4.509016342754438,\n",
              "   9: 1.8761967389474474,\n",
              "   10: 4.729603639406982,\n",
              "   11: 3.0223567847666795,\n",
              "   12: 1.66996249296472,\n",
              "   13: 1.5837715462031108,\n",
              "   14: 2.329418954515683,\n",
              "   15: 1.3970009890651007,\n",
              "   16: 4.452441604442928,\n",
              "   17: 9.497685637857844,\n",
              "   18: 10.37902101308957,\n",
              "   19: 6.130023333317432,\n",
              "   20: 1.5279027371659644,\n",
              "   21: 6.2083586508357556,\n",
              "   22: 4.568858893003196,\n",
              "   23: 6.025154986906914,\n",
              "   24: 1.569296511101144,\n",
              "   25: 6.5548056362173215,\n",
              "   26: 8.91652018188783,\n",
              "   27: 1.9452482342926665,\n",
              "   28: 2.618235821576077,\n",
              "   29: 3.108749154964905,\n",
              "   30: 1.7889735945360612,\n",
              "   31: 4.461242871792327},\n",
              "  22: {0: 4.347082969533921,\n",
              "   1: 1.5589445295237456,\n",
              "   2: 1.605719576430417,\n",
              "   3: 5.554071874275909,\n",
              "   4: 7.3773612820514245,\n",
              "   5: 2.354662456964215,\n",
              "   6: 2.578320049839344,\n",
              "   7: 4.533307983528194,\n",
              "   8: 1.0292550967298078,\n",
              "   9: 4.805631442932036,\n",
              "   10: 2.6588685497389104,\n",
              "   11: 3.6468878332540964,\n",
              "   12: 2.240530170804166,\n",
              "   13: 1.711597984012153,\n",
              "   14: 2.2826205493412224,\n",
              "   15: 3.817995258404121,\n",
              "   16: 9.348961342291137,\n",
              "   17: 4.682188840281611,\n",
              "   18: 2.0874356588523826,\n",
              "   19: 2.926142611682093,\n",
              "   20: 5.107285028233177,\n",
              "   21: 1.2320115236474758,\n",
              "   22: 3.5098426182829425,\n",
              "   23: 4.3468349405985425,\n",
              "   24: 4.096115446498833,\n",
              "   25: 2.8975615854139654,\n",
              "   26: 8.806573143628295,\n",
              "   27: 3.5970480697336455,\n",
              "   28: 3.7399363853869776,\n",
              "   29: 4.121981189597312,\n",
              "   30: 10.748154930007972,\n",
              "   31: 4.957053268641063},\n",
              "  23: {0: 5.709208050330274,\n",
              "   1: 4.48108601635383,\n",
              "   2: 0.5854566708277313,\n",
              "   3: 4.892445885254521,\n",
              "   4: 4.836377753294193,\n",
              "   5: 0.9685826878176417,\n",
              "   6: 11.437427676547662,\n",
              "   7: 5.690166262603191,\n",
              "   8: 6.62171629126782,\n",
              "   9: 2.843680740243281,\n",
              "   10: 1.978878179897355,\n",
              "   11: 3.150413451901427,\n",
              "   12: 2.9910521638012875,\n",
              "   13: 7.011943183733296,\n",
              "   14: 2.568194553396199,\n",
              "   15: 4.172232254536169,\n",
              "   16: 0.843926310434333,\n",
              "   17: 3.717239079195192,\n",
              "   18: 7.661877174469176,\n",
              "   19: 5.183652315225989,\n",
              "   20: 4.101953509520862,\n",
              "   21: 1.4244689430057371,\n",
              "   22: 0.8068103124673323,\n",
              "   23: 2.8552503043895863,\n",
              "   24: 8.375046275032245,\n",
              "   25: 3.074122105566816,\n",
              "   26: 2.708017499240134,\n",
              "   27: 2.8814597810402702,\n",
              "   28: 6.895442061657383,\n",
              "   29: 2.5921000011054476,\n",
              "   30: 4.03472749764031,\n",
              "   31: 2.215316738541678},\n",
              "  24: {0: 9.793724476844178,\n",
              "   1: 3.3965122797243987,\n",
              "   2: 7.132876557892745,\n",
              "   3: 3.6791054777448515,\n",
              "   4: 2.6432484646921184,\n",
              "   5: 1.7540693253207387,\n",
              "   6: 1.3042539331446998,\n",
              "   7: 4.387453625414225,\n",
              "   8: 4.454552401680093,\n",
              "   9: 1.1457536607758343,\n",
              "   10: 4.414253995065584,\n",
              "   11: 7.303206655508528,\n",
              "   12: 1.5864111110024166,\n",
              "   13: 4.020922628903353,\n",
              "   14: 3.188052579969784,\n",
              "   15: 1.6169601786415573,\n",
              "   16: 4.465268913836686,\n",
              "   17: 6.2800803346404575,\n",
              "   18: 4.534647424900216,\n",
              "   19: 0.660513652596409,\n",
              "   20: 3.65169260798472,\n",
              "   21: 4.885469949017922,\n",
              "   22: 4.042637968941082,\n",
              "   23: 3.3697456499651763,\n",
              "   24: 16.583187838978247,\n",
              "   25: 2.6695960033920914,\n",
              "   26: 3.3140537570578106,\n",
              "   27: 0.5083768712119248,\n",
              "   28: 4.048400949727155,\n",
              "   29: 3.329918780690085,\n",
              "   30: 7.969536437495224,\n",
              "   31: 0.8204477613681872},\n",
              "  25: {0: 2.5925391940939306,\n",
              "   1: 5.0449523367570785,\n",
              "   2: 7.822648812901793,\n",
              "   3: 2.263709463636311,\n",
              "   4: 2.7027723551112044,\n",
              "   5: 3.847833914992159,\n",
              "   6: 3.861186893882059,\n",
              "   7: 4.446883459970006,\n",
              "   8: 3.0634102492561155,\n",
              "   9: 2.1005047010219458,\n",
              "   10: 1.7173319497350437,\n",
              "   11: 1.9294401098155591,\n",
              "   12: 1.3499793427526798,\n",
              "   13: 3.838811030630307,\n",
              "   14: 8.519192020166326,\n",
              "   15: 3.544891628863219,\n",
              "   16: 18.16920412699533,\n",
              "   17: 7.1775074445260465,\n",
              "   18: 6.147549858559682,\n",
              "   19: 1.8894889470723821,\n",
              "   20: 5.991536946989221,\n",
              "   21: 0.930327896664042,\n",
              "   22: 4.03126616361558,\n",
              "   23: 3.2799380583377236,\n",
              "   24: 3.008764934216314,\n",
              "   25: 4.604765054413842,\n",
              "   26: 1.420697649608674,\n",
              "   27: 2.241044567549312,\n",
              "   28: 4.150522286156192,\n",
              "   29: 1.5947852642087028,\n",
              "   30: 5.818523837314442,\n",
              "   31: 1.4403870393150586},\n",
              "  26: {0: 1.2505688865157623,\n",
              "   1: 2.240754379634211,\n",
              "   2: 3.3142057689078284,\n",
              "   3: 2.2928379463682385,\n",
              "   4: 1.497152511354788,\n",
              "   5: 1.6045596427233704,\n",
              "   6: 2.997841623978994,\n",
              "   7: 5.461739612126824,\n",
              "   8: 3.0066015153187458,\n",
              "   9: 4.726713089929328,\n",
              "   10: 2.086164546687006,\n",
              "   11: 4.87383782814843,\n",
              "   12: 4.280023232490286,\n",
              "   13: 3.2081798105023025,\n",
              "   14: 4.9164303791393245,\n",
              "   15: 8.734947015650203,\n",
              "   16: 1.1652401561938763,\n",
              "   17: 2.5340682807568715,\n",
              "   18: 4.283002898523329,\n",
              "   19: 6.372781681035933,\n",
              "   20: 3.0725224243267166,\n",
              "   21: 5.2003000172797,\n",
              "   22: 8.327856402746981,\n",
              "   23: 4.622081067227443,\n",
              "   24: 3.0704748736825866,\n",
              "   25: 1.4106595725700348,\n",
              "   26: 1.7179562899497844,\n",
              "   27: 0.36880050420450294,\n",
              "   28: 2.431888600088764,\n",
              "   29: 3.3469125857006006,\n",
              "   30: 4.147296687003742,\n",
              "   31: 7.319952343368151},\n",
              "  27: {0: 4.535301789980911,\n",
              "   1: 6.179128126708253,\n",
              "   2: 1.9837724614167147,\n",
              "   3: 3.699622079760576,\n",
              "   4: 3.5487028155984994,\n",
              "   5: 3.1652162031969597,\n",
              "   6: 0.8226887674909955,\n",
              "   7: 3.44035279148128,\n",
              "   8: 3.622215312715669,\n",
              "   9: 4.380850915447702,\n",
              "   10: 3.3658300935701595,\n",
              "   11: 1.5428507828154836,\n",
              "   12: 13.471621595272799,\n",
              "   13: 4.6413776284941015,\n",
              "   14: 4.859322116768698,\n",
              "   15: 3.2437914767613503,\n",
              "   16: 3.5466961300158486,\n",
              "   17: 6.900654660233138,\n",
              "   18: 1.7308742510886628,\n",
              "   19: 1.0034285565739118,\n",
              "   20: 1.4345855310465987,\n",
              "   21: 3.7143683323507934,\n",
              "   22: 8.978129707650481,\n",
              "   23: 6.632899734878715,\n",
              "   24: 3.241598642091971,\n",
              "   25: 2.8919953093576907,\n",
              "   26: 3.1740947262039505,\n",
              "   27: 1.445639747764445,\n",
              "   28: 1.5057045075778737,\n",
              "   29: 1.5156787895238606,\n",
              "   30: 2.205862138919764,\n",
              "   31: 2.4494014683907808},\n",
              "  28: {0: 4.360427444471967,\n",
              "   1: 0.8724792543995793,\n",
              "   2: 7.530179584647765,\n",
              "   3: 2.2102180055904492,\n",
              "   4: 3.010099485373626,\n",
              "   5: 2.5938908949786206,\n",
              "   6: 3.84159236831785,\n",
              "   7: 4.326290202947557,\n",
              "   8: 3.664303344399486,\n",
              "   9: 4.638398449412813,\n",
              "   10: 4.1192196585659975,\n",
              "   11: 5.171488457246548,\n",
              "   12: 4.490762369570971,\n",
              "   13: 0.8528229720282908,\n",
              "   14: 5.984585854846852,\n",
              "   15: 14.375763578088884,\n",
              "   16: 2.3334414343749565,\n",
              "   17: 4.131658335668959,\n",
              "   18: 1.4016303456890264,\n",
              "   19: 2.500518791257031,\n",
              "   20: 4.916004750366049,\n",
              "   21: 5.414151572127569,\n",
              "   22: 2.9052316287543727,\n",
              "   23: 1.7042701096299728,\n",
              "   24: 3.27109936192738,\n",
              "   25: 4.905752775904942,\n",
              "   26: 1.928478875525954,\n",
              "   27: 3.936542581815617,\n",
              "   28: 9.273280060467437,\n",
              "   29: 1.1802471950001716,\n",
              "   30: 2.8881482072211955,\n",
              "   31: 9.29442321329233},\n",
              "  29: {0: 0.47701080536501594,\n",
              "   1: 7.544025443724306,\n",
              "   2: 2.7374094425972193,\n",
              "   3: 6.412046098836783,\n",
              "   4: 2.2820868001701777,\n",
              "   5: 0.6810596982111656,\n",
              "   6: 3.004330084450301,\n",
              "   7: 4.130303354852645,\n",
              "   8: 2.9897937616973476,\n",
              "   9: 9.643856524457686,\n",
              "   10: 4.375689503977609,\n",
              "   11: 4.576426262854355,\n",
              "   12: 0.18389056461418055,\n",
              "   13: 4.601576311688917,\n",
              "   14: 4.940405428869548,\n",
              "   15: 1.3261903669924224,\n",
              "   16: 19.0062064815506,\n",
              "   17: 1.156333088676232,\n",
              "   18: 4.253904228883567,\n",
              "   19: 1.3361568224619462,\n",
              "   20: 3.355565833480574,\n",
              "   21: 1.4084223863554,\n",
              "   22: 6.2734162458856835,\n",
              "   23: 3.311133429163709,\n",
              "   24: 6.727344852397093,\n",
              "   25: 20.015481336065168,\n",
              "   26: 7.597073752854669,\n",
              "   27: 1.376532170299082,\n",
              "   28: 6.089864070900336,\n",
              "   29: 14.468014413062846,\n",
              "   30: 2.7425302254578745,\n",
              "   31: 17.75122564644087},\n",
              "  30: {0: 1.5711968437724535,\n",
              "   1: 5.483039309135101,\n",
              "   2: 4.199709473089892,\n",
              "   3: 6.012674684475851,\n",
              "   4: 4.568205720340018,\n",
              "   5: 1.563268234050982,\n",
              "   6: 2.024440633720942,\n",
              "   7: 12.070020577024804,\n",
              "   8: 6.094795494875609,\n",
              "   9: 3.0599836834326357,\n",
              "   10: 3.3788620231787747,\n",
              "   11: 2.938143534284367,\n",
              "   12: 15.543589740109976,\n",
              "   13: 6.508041457961464,\n",
              "   14: 2.1151642927926466,\n",
              "   15: 4.323851486648877,\n",
              "   16: 4.344956168044729,\n",
              "   17: 1.9066461958464462,\n",
              "   18: 1.6356445261756836,\n",
              "   19: 2.302843445867337,\n",
              "   20: 4.730224289055412,\n",
              "   21: 5.61349994360637,\n",
              "   22: 5.784072924502652,\n",
              "   23: 2.4217868881155353,\n",
              "   24: 2.0370946451213197,\n",
              "   25: 3.3483533676444104,\n",
              "   26: 4.101451358408378,\n",
              "   27: 4.046719148470451,\n",
              "   28: 0.2451214894026326,\n",
              "   29: 8.44016115944037,\n",
              "   30: 3.6547117823830213,\n",
              "   31: 8.754783115114336},\n",
              "  31: {0: 5.759624877344207,\n",
              "   1: 5.0691244994162705,\n",
              "   2: 3.328490762740168,\n",
              "   3: 2.2066899704368472,\n",
              "   4: 3.122038428009276,\n",
              "   5: 4.8203610773093475,\n",
              "   6: 7.887227013763344,\n",
              "   7: 10.498327193966887,\n",
              "   8: 1.889273220428258,\n",
              "   9: 2.231626563998707,\n",
              "   10: 4.1878508756781585,\n",
              "   11: 2.3930826290740868,\n",
              "   12: 6.256852678571962,\n",
              "   13: 3.911042056924625,\n",
              "   14: 6.052080108019206,\n",
              "   15: 2.8437775022061036,\n",
              "   16: 5.032854074478326,\n",
              "   17: 1.8261861780343767,\n",
              "   18: 5.7887447690415925,\n",
              "   19: 3.855111169707547,\n",
              "   20: 1.245246719097744,\n",
              "   21: 12.886207882053393,\n",
              "   22: 2.0101856814325845,\n",
              "   23: 6.488819800710669,\n",
              "   24: 0.7589528835146422,\n",
              "   25: 4.61521499616264,\n",
              "   26: 6.490806885257513,\n",
              "   27: 2.439215700281319,\n",
              "   28: 3.130700968050254,\n",
              "   29: 5.389458105303852,\n",
              "   30: 2.3629674789303774,\n",
              "   31: 3.998935344082685}}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "filter_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYv_f--Fr1hi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_filter_ranking_combined(filter_ranking):\n",
        "    \"\"\"\n",
        "    Affiche tous les filtres de toutes les couches dans un seul graphe,\n",
        "    avec une ligne rouge séparant les couches.\n",
        "\n",
        "    Args:\n",
        "        filter_ranking : dict[layer_idx][out_ch][in_ch] = score\n",
        "    \"\"\"\n",
        "    all_scores = []\n",
        "    layer_boundaries = []\n",
        "    current_idx = 0\n",
        "\n",
        "    # Parcourir les couches\n",
        "    for l_idx in sorted(filter_ranking.keys()):\n",
        "        layer_dict = filter_ranking[l_idx]\n",
        "        # Moyenne sur les canaux d'entrée pour chaque filtre de sortie\n",
        "        out_scores = [np.mean(list(layer_dict[oc].values())) for oc in sorted(layer_dict.keys())]\n",
        "        all_scores.extend(out_scores)\n",
        "        current_idx += len(out_scores)\n",
        "        layer_boundaries.append(current_idx)  # position pour la ligne rouge\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.bar(range(len(all_scores)), all_scores)\n",
        "    plt.xlabel(\"Filtres (toutes couches concaténées)\")\n",
        "    plt.ylabel(\"Score d'importance moyen\")\n",
        "    plt.title(\"Importance des filtres par couche\")\n",
        "\n",
        "    # Tracer les lignes rouges pour séparer les couches\n",
        "    for b in layer_boundaries[:-1]:  # pas besoin de la dernière\n",
        "        plt.axvline(x=b-0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "uRTxF81tr4bU",
        "outputId": "a26abd91-7ee3-4a82-ec47-8ae1b1cf706a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_filter_ranking_combined(filter_ranking)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"reg_pure_20.json\", \"w\") as f:\n",
        "    json.dump(filter_ranking, f, indent=4)\n",
        "from google.colab import files\n",
        "files.download(\"reg_pure_20.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AGS60Uf9RwYI",
        "outputId": "6e906fa1-2911-49b5-b429-02d566e71457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c458c694-6241-4999-a1c9-c21a34ccb684\", \"reg_pure_20.json\", 70515)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtoD_SR1FFG7"
      },
      "source": [
        "**Sélection des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5lUEDEW9J1V"
      },
      "outputs": [],
      "source": [
        "def keep_top_percentile_filters(filter_ranking, percentile):\n",
        "    \"\"\"\n",
        "    Keeps the top 'percentile' of filters based on their base_importance score.\n",
        "\n",
        "    Args:\n",
        "        filter_ranking (dict): A dictionary containing the ranking of filters.\n",
        "                               Expected format: {layer_idx: {out_channel_idx: {in_channel_idx: base_importance}}}\n",
        "        percentile (int): The percentile to keep (e.g., 10 for top 10%).\n",
        "\n",
        "    Returns:\n",
        "        dict: A new dictionary containing only the top percentile filters.\n",
        "    \"\"\"\n",
        "    all_importances = []\n",
        "    # Collect all base_importance values\n",
        "    for layer_idx, out_channels in filter_ranking.items():\n",
        "        for out_channel_idx, in_channels in out_channels.items():\n",
        "            for in_channel_idx, importance in in_channels.items():\n",
        "                # Only consider non-NaN importance values\n",
        "                if not np.isnan(importance):\n",
        "                    all_importances.append(importance)\n",
        "\n",
        "    if not all_importances:\n",
        "        print(\"No valid importance values found.\")\n",
        "        return {}\n",
        "\n",
        "    # Calculate the threshold based on the percentile\n",
        "    threshold = np.percentile(all_importances, 100 - percentile) # Keep values >= threshold\n",
        "\n",
        "    # Create a new dictionary with only the top percentile filters\n",
        "    top_filters_ranking = {}\n",
        "    for layer_idx, out_channels in filter_ranking.items():\n",
        "        top_filters_ranking[layer_idx] = {}\n",
        "        for out_channel_idx, in_channels in out_channels.items():\n",
        "            top_filters_ranking[layer_idx][out_channel_idx] = {}\n",
        "            for in_channel_idx, importance in in_channels.items():\n",
        "                if not np.isnan(importance) and importance <= threshold:\n",
        "                    top_filters_ranking[layer_idx][out_channel_idx][in_channel_idx] = importance\n",
        "\n",
        "    return top_filters_ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg-VzejFbTq"
      },
      "source": [
        "**Pruning du modèle*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "model_test = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "wskXZsI5ShKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8xk3vXFuog"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def prune_model_by_filters_removal(model, top_indices_list, input_size=(3, 32, 32)):\n",
        "    \"\"\"\n",
        "    VERSION CORRIGÉE: Supprime réellement les filtres pour réduire les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle PyTorch nn.Sequential\n",
        "        top_indices_list: [(layer_idx, out_ch, in_ch), ...] - filtres à CONSERVER\n",
        "        input_size: taille d'entrée (channels, height, width)\n",
        "\n",
        "    Returns:\n",
        "        Modèle pruné avec moins de paramètres\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model_copy = copy.deepcopy(model)\n",
        "\n",
        "    # Organiser les filtres à conserver par couche\n",
        "    filters_to_keep = defaultdict(set)\n",
        "    for layer_idx, out_ch, in_ch in top_indices_list:\n",
        "        filters_to_keep[layer_idx].add(out_ch)\n",
        "\n",
        "    # Convertir en listes triées\n",
        "    for layer_idx in filters_to_keep:\n",
        "        filters_to_keep[layer_idx] = sorted(list(filters_to_keep[layer_idx]))\n",
        "\n",
        "    new_layers = []\n",
        "    conv_layers = [i for i, layer in enumerate(model_copy) if isinstance(layer, nn.Conv2d)]\n",
        "    prev_kept_channels = None\n",
        "\n",
        "    for i, layer in enumerate(model_copy):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Trouver l'index de cette couche conv\n",
        "            conv_idx = conv_layers.index(i)\n",
        "\n",
        "            # Déterminer les canaux de sortie à conserver\n",
        "            if conv_idx in filters_to_keep:\n",
        "                keep_out_channels = filters_to_keep[conv_idx]\n",
        "            else:\n",
        "                # Si pas spécifié, garder tous les canaux\n",
        "                keep_out_channels = list(range(layer.out_channels))\n",
        "\n",
        "            # Déterminer les canaux d'entrée\n",
        "            if conv_idx == 0:\n",
        "                # Première couche: garder tous les canaux d'entrée (RGB)\n",
        "                new_in_channels = layer.in_channels\n",
        "                keep_in_channels = list(range(layer.in_channels))\n",
        "            else:\n",
        "                # Couches suivantes: s'adapter aux canaux conservés de la couche précédente\n",
        "                new_in_channels = len(prev_kept_channels) if prev_kept_channels else layer.in_channels\n",
        "                keep_in_channels = prev_kept_channels if prev_kept_channels else list(range(layer.in_channels))\n",
        "\n",
        "            new_out_channels = len(keep_out_channels)\n",
        "\n",
        "            # Créer la nouvelle couche Conv2d RÉDUITE\n",
        "            new_conv = nn.Conv2d(\n",
        "                in_channels=new_in_channels,\n",
        "                out_channels=new_out_channels,\n",
        "                kernel_size=layer.kernel_size,\n",
        "                stride=layer.stride,\n",
        "                padding=layer.padding,\n",
        "                bias=(layer.bias is not None)\n",
        "            ).to(device)\n",
        "\n",
        "            # Copier uniquement les poids des filtres conservés\n",
        "            with torch.no_grad():\n",
        "                for new_out_idx, old_out_idx in enumerate(keep_out_channels):\n",
        "                    for new_in_idx, old_in_idx in enumerate(keep_in_channels):\n",
        "                        new_conv.weight[new_out_idx, new_in_idx] = layer.weight[old_out_idx, old_in_idx]\n",
        "\n",
        "                    if layer.bias is not None:\n",
        "                        new_conv.bias[new_out_idx] = layer.bias[old_out_idx]\n",
        "\n",
        "            new_layers.append(new_conv)\n",
        "            prev_kept_channels = keep_out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            # Adapter BatchNorm aux canaux conservés\n",
        "            if prev_kept_channels is not None:\n",
        "                new_bn = nn.BatchNorm2d(len(prev_kept_channels)).to(device)\n",
        "                with torch.no_grad():\n",
        "                    for new_idx, old_idx in enumerate(prev_kept_channels):\n",
        "                        new_bn.weight[new_idx] = layer.weight[old_idx]\n",
        "                        new_bn.bias[new_idx] = layer.bias[old_idx]\n",
        "                        new_bn.running_mean[new_idx] = layer.running_mean[old_idx]\n",
        "                        new_bn.running_var[new_idx] = layer.running_var[old_idx]\n",
        "                new_layers.append(new_bn)\n",
        "            else:\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            # Ajuster la première couche Linear après Flatten\n",
        "            if len([l for l in new_layers if isinstance(l, nn.Linear)]) == 0:\n",
        "                # Calculer la nouvelle taille après les couches conv\n",
        "                new_input_features = calculate_linear_input_size(new_layers, input_size)\n",
        "\n",
        "                new_linear = nn.Linear(\n",
        "                    in_features=new_input_features,\n",
        "                    out_features=layer.out_features,\n",
        "                    bias=(layer.bias is not None)\n",
        "                ).to(device)\n",
        "\n",
        "                # Copier les poids (avec adaptation de taille)\n",
        "                with torch.no_grad():\n",
        "                    min_features = min(new_input_features, layer.in_features)\n",
        "                    new_linear.weight[:, :min_features] = layer.weight[:, :min_features]\n",
        "                    if layer.bias is not None:\n",
        "                        new_linear.bias[:] = layer.bias[:]\n",
        "\n",
        "                new_layers.append(new_linear)\n",
        "            else:\n",
        "                # Autres couches Linear: copier tel quel\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "        else:\n",
        "            # Autres couches (ReLU, MaxPool, Dropout, Flatten)\n",
        "            new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "    return nn.Sequential(*new_layers).to(device)\n",
        "\n",
        "def calculate_linear_input_size(conv_layers, input_size):\n",
        "    \"\"\"\n",
        "    Calcule la taille d'entrée pour la première couche Linear\n",
        "    en simulant une passe avant à travers les couches conv.\n",
        "    \"\"\"\n",
        "    channels, h, w = input_size\n",
        "\n",
        "    for layer in conv_layers:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Calculer nouvelle taille après convolution\n",
        "            kernel_size = layer.kernel_size[0] if isinstance(layer.kernel_size, tuple) else layer.kernel_size\n",
        "            stride = layer.stride[0] if isinstance(layer.stride, tuple) else layer.stride\n",
        "            padding = layer.padding[0] if isinstance(layer.padding, tuple) else layer.padding\n",
        "\n",
        "            h = (h + 2*padding - kernel_size) // stride + 1\n",
        "            w = (w + 2*padding - kernel_size) // stride + 1\n",
        "            channels = layer.out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.MaxPool2d):\n",
        "            kernel_size = layer.kernel_size\n",
        "            stride = layer.stride if layer.stride else kernel_size\n",
        "            h = h // stride\n",
        "            w = w // stride\n",
        "\n",
        "    return channels * h * w\n",
        "\n",
        "def structured_channel_pruning(model, importance_dict, keep_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Pruning structuré: supprime des canaux entiers basé sur leur importance moyenne.\n",
        "    Plus efficace pour réduire réellement les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle à pruner\n",
        "        importance_dict: dict[layer][out_ch][in_ch] = importance\n",
        "        keep_ratio: fraction de canaux à conserver (0.5 = 50%)\n",
        "    \"\"\"\n",
        "    # Calculer l'importance moyenne par canal de sortie\n",
        "    channel_importance = {}\n",
        "\n",
        "    for layer_idx in importance_dict:\n",
        "        channel_importance[layer_idx] = {}\n",
        "        for out_ch in importance_dict[layer_idx]:\n",
        "            # Moyenne d'importance sur tous les canaux d'entrée pour ce canal de sortie\n",
        "            avg_importance = np.mean(list(importance_dict[layer_idx][out_ch].values()))\n",
        "            channel_importance[layer_idx][out_ch] = avg_importance\n",
        "\n",
        "    # Sélectionner les top canaux pour chaque couche\n",
        "    top_indices = []\n",
        "    for layer_idx in channel_importance:\n",
        "        # Trier par importance décroissante\n",
        "        channels_by_importance = sorted(\n",
        "            channel_importance[layer_idx].items(),\n",
        "            key=lambda x: x[1],\n",
        "            reverse=False\n",
        "        )\n",
        "\n",
        "        # Garder le top keep_ratio\n",
        "        n_keep = max(1, int(len(channels_by_importance) * keep_ratio))\n",
        "        top_channels = [ch for ch, _ in channels_by_importance[:n_keep]]\n",
        "\n",
        "        # Créer les indices pour tous les canaux d'entrée de ces canaux de sortie\n",
        "        for out_ch in top_channels:\n",
        "            for in_ch in importance_dict[layer_idx][out_ch]:\n",
        "                top_indices.append((layer_idx, out_ch, in_ch))\n",
        "\n",
        "    return top_indices\n",
        "\n",
        "def test_effective_pruning(model, importance_dict, trn_dl, val_dl, loss_fn, keep_ratios=[0.8, 0.6, 0.4, 0.2]):\n",
        "    \"\"\"\n",
        "    Test de pruning avec réduction EFFECTIVE des paramètres.\n",
        "    \"\"\"\n",
        "    print(\"Test de Pruning avec Réduction Effective des Paramètres\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Baseline\n",
        "    orig_params = sum(p.numel() for p in model.parameters())\n",
        "    orig_loss, orig_acc = evaluate_model(model, val_dl, loss_fn)\n",
        "\n",
        "    print(f\"Modèle original: {orig_acc:.4f} accuracy, {orig_params:,} paramètres\")\n",
        "    print()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for keep_ratio in keep_ratios:\n",
        "        print(f\"Test avec keep_ratio = {keep_ratio} ({keep_ratio*100:.0f}% des canaux)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            # Pruning structuré par canaux\n",
        "            top_indices = structured_channel_pruning(model, importance_dict, keep_ratio)\n",
        "            print(f\"Filtres sélectionnés: {len(top_indices)}\")\n",
        "\n",
        "            # Appliquer le pruning EFFECTIF\n",
        "            pruned_model = prune_model_by_filters_removal(model, top_indices, input_size=(3, 32, 32))\n",
        "\n",
        "            # Vérifier la réduction\n",
        "            pruned_params = sum(p.numel() for p in pruned_model.parameters())\n",
        "            actual_reduction = (orig_params - pruned_params) / orig_params * 100\n",
        "\n",
        "            print(f\"Paramètres avant: {orig_params:,}\")\n",
        "            print(f\"Paramètres après: {pruned_params:,}\")\n",
        "            print(f\"Réduction RÉELLE: {actual_reduction:.1f}%\")\n",
        "\n",
        "            # Test du modèle pruné\n",
        "            val_loss_before, val_acc_before = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "            print(f\"Accuracy avant fine-tuning: {val_acc_before:.4f}\")\n",
        "\n",
        "            # Fine-tuning\n",
        "            print(\"Fine-tuning...\")\n",
        "            pruned_model = fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=5, lr=1e-3)\n",
        "\n",
        "            val_loss_final, val_acc_final = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "\n",
        "            accuracy_retention = (val_acc_final / orig_acc) * 100\n",
        "            compression_ratio = orig_params / pruned_params\n",
        "\n",
        "            print(f\"Accuracy finale: {val_acc_final:.4f}\")\n",
        "            print(f\"Rétention accuracy: {accuracy_retention:.1f}%\")\n",
        "            print(f\"Ratio de compression: {compression_ratio:.1f}x\")\n",
        "            print()\n",
        "\n",
        "            results.append({\n",
        "                'keep_ratio': keep_ratio,\n",
        "                'actual_reduction': actual_reduction,\n",
        "                'final_accuracy': val_acc_final,\n",
        "                'accuracy_retention': accuracy_retention,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'pruned_params': pruned_params\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur avec keep_ratio {keep_ratio}: {e}\")\n",
        "            print()\n",
        "\n",
        "    # Résumé des résultats\n",
        "    print(\"RÉSUMÉ DES RÉSULTATS\")\n",
        "    print(\"=\"*40)\n",
        "    for r in results:\n",
        "        print(f\"Keep {r['keep_ratio']*100:.0f}%: {r['actual_reduction']:.1f}% réduction, \"\n",
        "              f\"{r['accuracy_retention']:.1f}% accuracy, {r['compression_ratio']:.1f}x compression\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Fonction d'évaluation (si pas déjà définie)\n",
        "def evaluate_model(model, val_dl, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            device = next(model.parameters()).device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += x.size(0)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "def fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=10, lr=1e-4):\n",
        "    \"\"\"Fine-tune le modèle pruné pour récupérer l'accuracy.\"\"\"\n",
        "    from torch.optim import Adam\n",
        "\n",
        "    device = next(pruned_model.parameters()).device\n",
        "    optimizer = Adam(pruned_model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pruned_model.train()\n",
        "        for x, y in trn_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = pruned_model(x)\n",
        "            loss = loss_fn(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation check\n",
        "        val_loss, val_acc = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "        if epoch == 0 or (epoch + 1) % 2 == 0:\n",
        "            print(f\"  Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "# Usage example:\n",
        "# Remplacer votre appel par:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyvjgo6gajdQ",
        "outputId": "994aed55-39f0-4a35-944b-74eb66680323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test de Pruning avec Réduction Effective des Paramètres\n",
            "============================================================\n",
            "Modèle original: 0.7307 accuracy, 120,858 paramètres\n",
            "\n",
            "Test avec keep_ratio = 0.8 (80% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1428\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 88,081\n",
            "Réduction RÉELLE: 27.1%\n",
            "Accuracy avant fine-tuning: 0.1038\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6595\n",
            "  Epoch 2: Val Acc = 0.6672\n",
            "  Epoch 4: Val Acc = 0.6983\n",
            "Accuracy finale: 0.7235\n",
            "Rétention accuracy: 99.0%\n",
            "Ratio de compression: 1.4x\n",
            "\n",
            "Test avec keep_ratio = 0.6 (60% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1083\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 64,114\n",
            "Réduction RÉELLE: 47.0%\n",
            "Accuracy avant fine-tuning: 0.1258\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6033\n",
            "  Epoch 2: Val Acc = 0.6472\n",
            "  Epoch 4: Val Acc = 0.6754\n",
            "Accuracy finale: 0.6910\n",
            "Rétention accuracy: 94.6%\n",
            "Ratio de compression: 1.9x\n",
            "\n",
            "Test avec keep_ratio = 0.4 (40% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 690\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 40,468\n",
            "Réduction RÉELLE: 66.5%\n",
            "Accuracy avant fine-tuning: 0.1000\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.4063\n",
            "  Epoch 2: Val Acc = 0.4706\n",
            "  Epoch 4: Val Acc = 0.5470\n",
            "Accuracy finale: 0.5697\n",
            "Rétention accuracy: 78.0%\n",
            "Ratio de compression: 3.0x\n",
            "\n",
            "Test avec keep_ratio = 0.2 (20% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 345\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 23,176\n",
            "Réduction RÉELLE: 80.8%\n",
            "Accuracy avant fine-tuning: 0.1000\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.3098\n",
            "  Epoch 2: Val Acc = 0.4075\n",
            "  Epoch 4: Val Acc = 0.4521\n",
            "Accuracy finale: 0.4640\n",
            "Rétention accuracy: 63.5%\n",
            "Ratio de compression: 5.2x\n",
            "\n",
            "RÉSUMÉ DES RÉSULTATS\n",
            "========================================\n",
            "Keep 80%: 27.1% réduction, 99.0% accuracy, 1.4x compression\n",
            "Keep 60%: 47.0% réduction, 94.6% accuracy, 1.9x compression\n",
            "Keep 40%: 66.5% réduction, 78.0% accuracy, 3.0x compression\n",
            "Keep 20%: 80.8% réduction, 63.5% accuracy, 5.2x compression\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'keep_ratio': 0.8,\n",
              "  'actual_reduction': 27.120256830329808,\n",
              "  'final_accuracy': 0.7235,\n",
              "  'accuracy_retention': 99.0146434925414,\n",
              "  'compression_ratio': 1.372123386428401,\n",
              "  'pruned_params': 88081},\n",
              " {'keep_ratio': 0.6,\n",
              "  'actual_reduction': 46.950967250823275,\n",
              "  'final_accuracy': 0.691,\n",
              "  'accuracy_retention': 94.56685370192965,\n",
              "  'compression_ratio': 1.8850485073462895,\n",
              "  'pruned_params': 64114},\n",
              " {'keep_ratio': 0.4,\n",
              "  'actual_reduction': 66.51607671813203,\n",
              "  'final_accuracy': 0.5697,\n",
              "  'accuracy_retention': 77.96633365266182,\n",
              "  'compression_ratio': 2.98650785806069,\n",
              "  'pruned_params': 40468},\n",
              " {'keep_ratio': 0.2,\n",
              "  'actual_reduction': 80.82377666352248,\n",
              "  'final_accuracy': 0.464,\n",
              "  'accuracy_retention': 63.50075270288764,\n",
              "  'compression_ratio': 5.214791163272351,\n",
              "  'pruned_params': 23176}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import copy\n",
        "model_test = copy.deepcopy(model)\n",
        "test_effective_pruning(model_test,filter_ranking,trn_dl, val_dl, loss_fn) #gardant 50 plus régulière"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333c463d-4010-477b-c696-a4ee1c4e49ca",
        "id": "C8Mebi1rDOiq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de Pruning avec Réduction Effective des Paramètres\n",
            "============================================================\n",
            "Modèle original: 0.7409 accuracy, 120,858 paramètres\n",
            "\n",
            "Test avec keep_ratio = 0.8 (80% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1428\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 88,081\n",
            "Réduction RÉELLE: 27.1%\n",
            "Accuracy avant fine-tuning: 0.1443\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6796\n",
            "  Epoch 2: Val Acc = 0.6841\n",
            "  Epoch 4: Val Acc = 0.7129\n",
            "Accuracy finale: 0.7271\n",
            "Rétention accuracy: 98.1%\n",
            "Ratio de compression: 1.4x\n",
            "\n",
            "Test avec keep_ratio = 0.6 (60% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1083\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 64,114\n",
            "Réduction RÉELLE: 47.0%\n",
            "Accuracy avant fine-tuning: 0.0966\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6367\n",
            "  Epoch 2: Val Acc = 0.6618\n",
            "  Epoch 4: Val Acc = 0.6960\n",
            "Accuracy finale: 0.6973\n",
            "Rétention accuracy: 94.1%\n",
            "Ratio de compression: 1.9x\n",
            "\n",
            "Test avec keep_ratio = 0.4 (40% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 690\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 40,468\n",
            "Réduction RÉELLE: 66.5%\n",
            "Accuracy avant fine-tuning: 0.1115\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.5514\n",
            "  Epoch 2: Val Acc = 0.6090\n",
            "  Epoch 4: Val Acc = 0.6388\n",
            "Accuracy finale: 0.6517\n",
            "Rétention accuracy: 88.0%\n",
            "Ratio de compression: 3.0x\n",
            "\n",
            "Test avec keep_ratio = 0.2 (20% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 345\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 23,176\n",
            "Réduction RÉELLE: 80.8%\n",
            "Accuracy avant fine-tuning: 0.1232\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.4249\n",
            "  Epoch 2: Val Acc = 0.4735\n",
            "  Epoch 4: Val Acc = 0.5115\n",
            "Accuracy finale: 0.5286\n",
            "Rétention accuracy: 71.3%\n",
            "Ratio de compression: 5.2x\n",
            "\n",
            "RÉSUMÉ DES RÉSULTATS\n",
            "========================================\n",
            "Keep 80%: 27.1% réduction, 98.1% accuracy, 1.4x compression\n",
            "Keep 60%: 47.0% réduction, 94.1% accuracy, 1.9x compression\n",
            "Keep 40%: 66.5% réduction, 88.0% accuracy, 3.0x compression\n",
            "Keep 20%: 80.8% réduction, 71.3% accuracy, 5.2x compression\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'keep_ratio': 0.8,\n",
              "  'actual_reduction': 27.120256830329808,\n",
              "  'final_accuracy': 0.7271,\n",
              "  'accuracy_retention': 98.13740045890134,\n",
              "  'compression_ratio': 1.372123386428401,\n",
              "  'pruned_params': 88081},\n",
              " {'keep_ratio': 0.6,\n",
              "  'actual_reduction': 46.950967250823275,\n",
              "  'final_accuracy': 0.6973,\n",
              "  'accuracy_retention': 94.11526521797813,\n",
              "  'compression_ratio': 1.8850485073462895,\n",
              "  'pruned_params': 64114},\n",
              " {'keep_ratio': 0.4,\n",
              "  'actual_reduction': 66.51607671813203,\n",
              "  'final_accuracy': 0.6517,\n",
              "  'accuracy_retention': 87.9605884734782,\n",
              "  'compression_ratio': 2.98650785806069,\n",
              "  'pruned_params': 40468},\n",
              " {'keep_ratio': 0.2,\n",
              "  'actual_reduction': 80.82377666352248,\n",
              "  'final_accuracy': 0.5286,\n",
              "  'accuracy_retention': 71.34566068295317,\n",
              "  'compression_ratio': 5.214791163272351,\n",
              "  'pruned_params': 23176}]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_effective_pruning(model_test,filter_ranking,trn_dl, val_dl, loss_fn) #gardant 20 plus régulière"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}