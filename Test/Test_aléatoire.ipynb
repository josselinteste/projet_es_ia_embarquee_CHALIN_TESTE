{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP697LuRwBgo",
        "outputId": "b76a70fd-dd8f-4d5a-d5d3-a64294ab594b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "import torch\n",
        "data_folder = '/content/' # This can be any directory you want to download FMNIST to\n",
        "fmnist = datasets.CIFAR10(data_folder, download=True, train=True)\n",
        "\n",
        "tr_images = fmnist.data\n",
        "tr_targets = fmnist.targets\n",
        "\n",
        "val_fmnist = datasets.CIFAR10(data_folder, download=True, train=False)\n",
        "val_images = val_fmnist.data\n",
        "val_targets = val_fmnist.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2cuyLuLPwCeA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, images, targets, device='cpu'):\n",
        "        # Convertir les tableaux NumPy en tenseurs PyTorch\n",
        "        images = torch.from_numpy(images).float() / 255.0\n",
        "        targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "        # CIFAR10 : images en 3x32x32, format (N, H, W, C) -> (N, C, H, W)\n",
        "        images = images.permute(0, 3, 1, 2)\n",
        "\n",
        "        self.x = images\n",
        "        self.y = targets\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        x = self.x[ix].to(self.device)\n",
        "        y = self.y[ix].to(self.device)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BHGn69pmwFCk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_model(device='cpu'):\n",
        "    model = nn.Sequential(\n",
        "        # Bloc 1\n",
        "        nn.Conv2d(3, 16, kernel_size=5, padding=2, bias=True),  # 64 → 16\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "\n",
        "        nn.Conv2d(16, 16, kernel_size=5, padding=2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.MaxPool2d(2),  # 32x32 → 16x16\n",
        "\n",
        "        # Bloc 2\n",
        "        nn.Conv2d(16, 32, kernel_size=5, padding=2, bias=True),  # 128 → 32\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),  # 16x16 → 8x8\n",
        "\n",
        "        # Bloc 3\n",
        "        nn.Conv2d(32, 32, kernel_size=5, padding=2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout2d(0.1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2),  # 8x8 → 4x4\n",
        "\n",
        "        # Classificateur\n",
        "        nn.Flatten(),              # 32 * 4 * 4 = 512\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(64, 10)\n",
        "    ).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    return model, loss_fn, optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F8B-MtQwIrx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oABLdS0NwJQx"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    train = CIFAR10Dataset(tr_images, tr_targets)\n",
        "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
        "    val = CIFAR10Dataset(val_images, val_targets)\n",
        "    val_dl = DataLoader(val, batch_size=len(val_images), shuffle=True)\n",
        "    return trn_dl, val_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGA7dXVLwLO5",
        "outputId": "e802d85a-b044-4161-9d89-9c14571858c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]           1,216\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "            Conv2d-4           [-1, 16, 32, 32]           6,416\n",
            "              ReLU-5           [-1, 16, 32, 32]               0\n",
            "         Dropout2d-6           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
            "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]          12,832\n",
            "             ReLU-10           [-1, 32, 16, 16]               0\n",
            "        Dropout2d-11           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
            "        MaxPool2d-13             [-1, 32, 8, 8]               0\n",
            "           Conv2d-14             [-1, 32, 8, 8]          25,632\n",
            "             ReLU-15             [-1, 32, 8, 8]               0\n",
            "        Dropout2d-16             [-1, 32, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 32, 8, 8]              64\n",
            "        MaxPool2d-18             [-1, 32, 4, 4]               0\n",
            "          Flatten-19                  [-1, 512]               0\n",
            "           Linear-20                  [-1, 128]          65,664\n",
            "             ReLU-21                  [-1, 128]               0\n",
            "          Dropout-22                  [-1, 128]               0\n",
            "           Linear-23                   [-1, 64]           8,256\n",
            "             ReLU-24                   [-1, 64]               0\n",
            "          Dropout-25                   [-1, 64]               0\n",
            "           Linear-26                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 120,858\n",
            "Trainable params: 120,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.25\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 1.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Définir le device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Charger les données\n",
        "trn_dl, val_dl = get_data()\n",
        "\n",
        "# Initialiser le modèle\n",
        "model, loss_fn, optimizer = get_model(device=device)\n",
        "\n",
        "# Afficher un résumé du modèle\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))  # CIFAR10 : 3 canaux, 32x32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c43c5VK8wOVy"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    prediction = model(x)\n",
        "    batch_loss = loss_fn(prediction, y)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return batch_loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    max_values, argmaxes = prediction.max(-1)\n",
        "    is_correct = argmaxes == y\n",
        "    return is_correct.cpu().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N8s7IsyUwR-Q"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def val_loss(x, y, model):\n",
        "    model.eval()\n",
        "    prediction = model(x)\n",
        "    val_loss = loss_fn(prediction, y)\n",
        "    return val_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-blw4yXLwTnb",
        "outputId": "52fb7525-09d5-413e-eb81-1dbf8d43ed4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "for epoch in range(6):\n",
        "    print(epoch)\n",
        "    train_epoch_losses, train_epoch_accuracies = [], []\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
        "        train_epoch_losses.append(batch_loss)\n",
        "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
        "\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        is_correct = accuracy(x, y, model)\n",
        "        train_epoch_accuracies.extend(is_correct)\n",
        "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
        "\n",
        "    for ix, batch in enumerate(iter(val_dl)):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        val_is_correct = accuracy(x, y, model)\n",
        "        validation_loss = val_loss(x, y, model)\n",
        "    val_epoch_accuracy = np.mean(val_is_correct)\n",
        "\n",
        "    train_losses.append(train_epoch_loss)\n",
        "    train_accuracies.append(train_epoch_accuracy)\n",
        "    val_losses.append(validation_loss)\n",
        "    val_accuracies.append(val_epoch_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvxloP_xpeU"
      },
      "source": [
        "**INTERPOLATION DU FILTRE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI3eqSuFxubf"
      },
      "source": [
        "**Projection dans schwartz**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjFLTC0414E0"
      },
      "source": [
        "Mesure de valeur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp20qDf12KYW"
      },
      "source": [
        "**Classement des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcI5tkbgCpjr",
        "outputId": "780f27fa-1ad8-4fc3-bd04-8e5476b58a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]           1,216\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "            Conv2d-4           [-1, 16, 32, 32]           6,416\n",
            "              ReLU-5           [-1, 16, 32, 32]               0\n",
            "         Dropout2d-6           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
            "         MaxPool2d-8           [-1, 16, 16, 16]               0\n",
            "            Conv2d-9           [-1, 32, 16, 16]          12,832\n",
            "             ReLU-10           [-1, 32, 16, 16]               0\n",
            "        Dropout2d-11           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-12           [-1, 32, 16, 16]              64\n",
            "        MaxPool2d-13             [-1, 32, 8, 8]               0\n",
            "           Conv2d-14             [-1, 32, 8, 8]          25,632\n",
            "             ReLU-15             [-1, 32, 8, 8]               0\n",
            "        Dropout2d-16             [-1, 32, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 32, 8, 8]              64\n",
            "        MaxPool2d-18             [-1, 32, 4, 4]               0\n",
            "          Flatten-19                  [-1, 512]               0\n",
            "           Linear-20                  [-1, 128]          65,664\n",
            "             ReLU-21                  [-1, 128]               0\n",
            "          Dropout-22                  [-1, 128]               0\n",
            "           Linear-23                   [-1, 64]           8,256\n",
            "             ReLU-24                   [-1, 64]               0\n",
            "          Dropout-25                   [-1, 64]               0\n",
            "           Linear-26                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 120,858\n",
            "Trainable params: 120,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.25\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 1.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgwbKDtt6rmd",
        "outputId": "6147001a-043c-40ee-945a-81d3a2c0040d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Couche 1/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "   Couche 2/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "   Couche 3/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "6\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "7\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "8\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "9\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "10\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "11\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "17\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "18\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "19\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "20\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "21\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "22\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "23\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "24\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "25\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "26\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "27\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "28\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "29\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "30\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "31\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "   Couche 4/4...\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "5\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "6\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "from scipy.interpolate import RegularGridInterpolator\n",
        "conv_layers = [module for module in model.modules() if isinstance(module, nn.Conv2d)]\n",
        "\n",
        "filter_ranking = {}\n",
        "conv_layers = [m for m in model.modules() if isinstance(m, torch.nn.Conv2d)]\n",
        "\n",
        "for m_idx, conv_layer in enumerate(conv_layers):\n",
        "    print(f\"   Couche {m_idx+1}/{len(conv_layers)}...\")\n",
        "    filter_ranking[m_idx] = {}\n",
        "\n",
        "    out_channels, in_channels, h, w = conv_layer.weight.shape\n",
        "\n",
        "    for oc in range(out_channels):\n",
        "        print(oc)\n",
        "        filter_ranking[m_idx][oc] = {}\n",
        "        for ic in range(in_channels):\n",
        "            print(ic)\n",
        "                # 1. Importance GraphCut multi-échelle + structurelle\n",
        "            filter_weights = conv_layer.weight[oc, ic].detach().cpu().numpy()\n",
        "            base_importance = ultimate_graphcut_filter_analysis(filter_weights)\n",
        "\n",
        "                # 2. Correction contextuelle (redondance)\n",
        "            #redundancy_factor = contextual_redundancy_check(conv_layer, oc, ic)\n",
        "\n",
        "                # 3. Score final\n",
        "            #final_importance = base_importance * redundancy_factor\n",
        "            filter_ranking[m_idx][oc][ic] = float(base_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QtoD_SR1FFG7"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "model_test = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtB4MCV6FXgU"
      },
      "source": [
        "**Sélection des filtres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_channel_pruning(model, importance_dict, keep_ratio=0.5, seed=None):\n",
        "    \"\"\"\n",
        "    Pruning structuré aléatoire: supprime des canaux entiers choisis aléatoirement.\n",
        "    Contrairement à structured_channel_pruning, on ignore l'importance\n",
        "    et on garde des filtres au hasard.\n",
        "\n",
        "    Args:\n",
        "        model: modèle à pruner\n",
        "        importance_dict: dict[layer][out_ch][in_ch] = importance (ici ignoré sauf pour structure)\n",
        "        keep_ratio: fraction de canaux à conserver\n",
        "        seed: entier pour reproductibilité (None = tirage aléatoire à chaque appel)\n",
        "\n",
        "    Returns:\n",
        "        Liste des indices [(layer_idx, out_ch, in_ch), ...] des filtres à conserver\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    random_indices = []\n",
        "\n",
        "    for layer_idx in importance_dict:\n",
        "        out_channels = list(importance_dict[layer_idx].keys())\n",
        "        n_keep = max(1, int(len(out_channels) * keep_ratio))\n",
        "\n",
        "        # Tirage aléatoire sans remise\n",
        "        kept_out_channels = np.random.choice(out_channels, size=n_keep, replace=False)\n",
        "\n",
        "        # Ajouter tous les in_channels correspondants\n",
        "        for out_ch in kept_out_channels:\n",
        "            for in_ch in importance_dict[layer_idx][out_ch]:\n",
        "                random_indices.append((layer_idx, out_ch, in_ch))\n",
        "\n",
        "    return random_indices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg-VzejFbTq"
      },
      "source": [
        "**Pruning du modèle*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf8xk3vXFuog"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def prune_model_by_filters_removal(model, top_indices_list, input_size=(3, 32, 32)):\n",
        "    \"\"\"\n",
        "    VERSION CORRIGÉE: Supprime réellement les filtres pour réduire les paramètres.\n",
        "\n",
        "    Args:\n",
        "        model: modèle PyTorch nn.Sequential\n",
        "        top_indices_list: [(layer_idx, out_ch, in_ch), ...] - filtres à CONSERVER\n",
        "        input_size: taille d'entrée (channels, height, width)\n",
        "\n",
        "    Returns:\n",
        "        Modèle pruné avec moins de paramètres\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    model_copy = copy.deepcopy(model)\n",
        "\n",
        "    # Organiser les filtres à conserver par couche\n",
        "    filters_to_keep = defaultdict(set)\n",
        "    for layer_idx, out_ch, in_ch in top_indices_list:\n",
        "        filters_to_keep[layer_idx].add(out_ch)\n",
        "\n",
        "    # Convertir en listes triées\n",
        "    for layer_idx in filters_to_keep:\n",
        "        filters_to_keep[layer_idx] = sorted(list(filters_to_keep[layer_idx]))\n",
        "\n",
        "    new_layers = []\n",
        "    conv_layers = [i for i, layer in enumerate(model_copy) if isinstance(layer, nn.Conv2d)]\n",
        "    prev_kept_channels = None\n",
        "\n",
        "    for i, layer in enumerate(model_copy):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Trouver l'index de cette couche conv\n",
        "            conv_idx = conv_layers.index(i)\n",
        "\n",
        "            # Déterminer les canaux de sortie à conserver\n",
        "            if conv_idx in filters_to_keep:\n",
        "                keep_out_channels = filters_to_keep[conv_idx]\n",
        "            else:\n",
        "                # Si pas spécifié, garder tous les canaux\n",
        "                keep_out_channels = list(range(layer.out_channels))\n",
        "\n",
        "            # Déterminer les canaux d'entrée\n",
        "            if conv_idx == 0:\n",
        "                # Première couche: garder tous les canaux d'entrée (RGB)\n",
        "                new_in_channels = layer.in_channels\n",
        "                keep_in_channels = list(range(layer.in_channels))\n",
        "            else:\n",
        "                # Couches suivantes: s'adapter aux canaux conservés de la couche précédente\n",
        "                new_in_channels = len(prev_kept_channels) if prev_kept_channels else layer.in_channels\n",
        "                keep_in_channels = prev_kept_channels if prev_kept_channels else list(range(layer.in_channels))\n",
        "\n",
        "            new_out_channels = len(keep_out_channels)\n",
        "\n",
        "            # Créer la nouvelle couche Conv2d RÉDUITE\n",
        "            new_conv = nn.Conv2d(\n",
        "                in_channels=new_in_channels,\n",
        "                out_channels=new_out_channels,\n",
        "                kernel_size=layer.kernel_size,\n",
        "                stride=layer.stride,\n",
        "                padding=layer.padding,\n",
        "                bias=(layer.bias is not None)\n",
        "            ).to(device)\n",
        "\n",
        "            # Copier uniquement les poids des filtres conservés\n",
        "            with torch.no_grad():\n",
        "                for new_out_idx, old_out_idx in enumerate(keep_out_channels):\n",
        "                    for new_in_idx, old_in_idx in enumerate(keep_in_channels):\n",
        "                        new_conv.weight[new_out_idx, new_in_idx] = layer.weight[old_out_idx, old_in_idx]\n",
        "\n",
        "                    if layer.bias is not None:\n",
        "                        new_conv.bias[new_out_idx] = layer.bias[old_out_idx]\n",
        "\n",
        "            new_layers.append(new_conv)\n",
        "            prev_kept_channels = keep_out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.BatchNorm2d):\n",
        "            # Adapter BatchNorm aux canaux conservés\n",
        "            if prev_kept_channels is not None:\n",
        "                new_bn = nn.BatchNorm2d(len(prev_kept_channels)).to(device)\n",
        "                with torch.no_grad():\n",
        "                    for new_idx, old_idx in enumerate(prev_kept_channels):\n",
        "                        new_bn.weight[new_idx] = layer.weight[old_idx]\n",
        "                        new_bn.bias[new_idx] = layer.bias[old_idx]\n",
        "                        new_bn.running_mean[new_idx] = layer.running_mean[old_idx]\n",
        "                        new_bn.running_var[new_idx] = layer.running_var[old_idx]\n",
        "                new_layers.append(new_bn)\n",
        "            else:\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "        elif isinstance(layer, nn.Linear):\n",
        "            # Ajuster la première couche Linear après Flatten\n",
        "            if len([l for l in new_layers if isinstance(l, nn.Linear)]) == 0:\n",
        "                # Calculer la nouvelle taille après les couches conv\n",
        "                new_input_features = calculate_linear_input_size(new_layers, input_size)\n",
        "\n",
        "                new_linear = nn.Linear(\n",
        "                    in_features=new_input_features,\n",
        "                    out_features=layer.out_features,\n",
        "                    bias=(layer.bias is not None)\n",
        "                ).to(device)\n",
        "\n",
        "                # Copier les poids (avec adaptation de taille)\n",
        "                with torch.no_grad():\n",
        "                    min_features = min(new_input_features, layer.in_features)\n",
        "                    new_linear.weight[:, :min_features] = layer.weight[:, :min_features]\n",
        "                    if layer.bias is not None:\n",
        "                        new_linear.bias[:] = layer.bias[:]\n",
        "\n",
        "                new_layers.append(new_linear)\n",
        "            else:\n",
        "                # Autres couches Linear: copier tel quel\n",
        "                new_layers.append(copy.deepcopy(layer))\n",
        "        else:\n",
        "            # Autres couches (ReLU, MaxPool, Dropout, Flatten)\n",
        "            new_layers.append(copy.deepcopy(layer))\n",
        "\n",
        "    return nn.Sequential(*new_layers).to(device)\n",
        "\n",
        "def calculate_linear_input_size(conv_layers, input_size):\n",
        "    \"\"\"\n",
        "    Calcule la taille d'entrée pour la première couche Linear\n",
        "    en simulant une passe avant à travers les couches conv.\n",
        "    \"\"\"\n",
        "    channels, h, w = input_size\n",
        "\n",
        "    for layer in conv_layers:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Calculer nouvelle taille après convolution\n",
        "            kernel_size = layer.kernel_size[0] if isinstance(layer.kernel_size, tuple) else layer.kernel_size\n",
        "            stride = layer.stride[0] if isinstance(layer.stride, tuple) else layer.stride\n",
        "            padding = layer.padding[0] if isinstance(layer.padding, tuple) else layer.padding\n",
        "\n",
        "            h = (h + 2*padding - kernel_size) // stride + 1\n",
        "            w = (w + 2*padding - kernel_size) // stride + 1\n",
        "            channels = layer.out_channels\n",
        "\n",
        "        elif isinstance(layer, nn.MaxPool2d):\n",
        "            kernel_size = layer.kernel_size\n",
        "            stride = layer.stride if layer.stride else kernel_size\n",
        "            h = h // stride\n",
        "            w = w // stride\n",
        "\n",
        "    return channels * h * w\n",
        "\n",
        "\n",
        "\n",
        "def test_effective_pruning(model, importance_dict, trn_dl, val_dl, loss_fn, keep_ratios=[0.8, 0.6, 0.4, 0.2]):\n",
        "    \"\"\"\n",
        "    Test de pruning avec réduction EFFECTIVE des paramètres.\n",
        "    \"\"\"\n",
        "    print(\"Test de Pruning avec Réduction Effective des Paramètres\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Baseline\n",
        "    orig_params = sum(p.numel() for p in model.parameters())\n",
        "    orig_loss, orig_acc = evaluate_model(model, val_dl, loss_fn)\n",
        "\n",
        "    print(f\"Modèle original: {orig_acc:.4f} accuracy, {orig_params:,} paramètres\")\n",
        "    print()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for keep_ratio in keep_ratios:\n",
        "        print(f\"Test avec keep_ratio = {keep_ratio} ({keep_ratio*100:.0f}% des canaux)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        try:\n",
        "            # Pruning structuré par canaux\n",
        "            top_indices = random_channel_pruning(model, importance_dict, keep_ratio, seed=42)\n",
        "\n",
        "            print(f\"Filtres sélectionnés: {len(top_indices)}\")\n",
        "\n",
        "            # Appliquer le pruning EFFECTIF\n",
        "            pruned_model = prune_model_by_filters_removal(model, top_indices, input_size=(3, 32, 32))\n",
        "\n",
        "            # Vérifier la réduction\n",
        "            pruned_params = sum(p.numel() for p in pruned_model.parameters())\n",
        "            actual_reduction = (orig_params - pruned_params) / orig_params * 100\n",
        "\n",
        "            print(f\"Paramètres avant: {orig_params:,}\")\n",
        "            print(f\"Paramètres après: {pruned_params:,}\")\n",
        "            print(f\"Réduction RÉELLE: {actual_reduction:.1f}%\")\n",
        "\n",
        "            # Test du modèle pruné\n",
        "            val_loss_before, val_acc_before = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "            print(f\"Accuracy avant fine-tuning: {val_acc_before:.4f}\")\n",
        "\n",
        "            # Fine-tuning\n",
        "            print(\"Fine-tuning...\")\n",
        "            pruned_model = fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=5, lr=1e-3)\n",
        "\n",
        "            val_loss_final, val_acc_final = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "\n",
        "            accuracy_retention = (val_acc_final / orig_acc) * 100\n",
        "            compression_ratio = orig_params / pruned_params\n",
        "\n",
        "            print(f\"Accuracy finale: {val_acc_final:.4f}\")\n",
        "            print(f\"Rétention accuracy: {accuracy_retention:.1f}%\")\n",
        "            print(f\"Ratio de compression: {compression_ratio:.1f}x\")\n",
        "            print()\n",
        "\n",
        "            results.append({\n",
        "                'keep_ratio': keep_ratio,\n",
        "                'actual_reduction': actual_reduction,\n",
        "                'final_accuracy': val_acc_final,\n",
        "                'accuracy_retention': accuracy_retention,\n",
        "                'compression_ratio': compression_ratio,\n",
        "                'pruned_params': pruned_params\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur avec keep_ratio {keep_ratio}: {e}\")\n",
        "            print()\n",
        "\n",
        "    # Résumé des résultats\n",
        "    print(\"RÉSUMÉ DES RÉSULTATS\")\n",
        "    print(\"=\"*40)\n",
        "    for r in results:\n",
        "        print(f\"Keep {r['keep_ratio']*100:.0f}%: {r['actual_reduction']:.1f}% réduction, \"\n",
        "              f\"{r['accuracy_retention']:.1f}% accuracy, {r['compression_ratio']:.1f}x compression\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Fonction d'évaluation (si pas déjà définie)\n",
        "def evaluate_model(model, val_dl, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            device = next(model.parameters()).device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            total_loss += loss_fn(pred, y).item() * x.size(0)\n",
        "            total_correct += (pred.argmax(1) == y).sum().item()\n",
        "            total_samples += x.size(0)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "def fine_tune_pruned_model(pruned_model, trn_dl, val_dl, loss_fn, epochs=10, lr=1e-4):\n",
        "    \"\"\"Fine-tune le modèle pruné pour récupérer l'accuracy.\"\"\"\n",
        "    from torch.optim import Adam\n",
        "\n",
        "    device = next(pruned_model.parameters()).device\n",
        "    optimizer = Adam(pruned_model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pruned_model.train()\n",
        "        for x, y in trn_dl:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = pruned_model(x)\n",
        "            loss = loss_fn(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation check\n",
        "        val_loss, val_acc = evaluate_model(pruned_model, val_dl, loss_fn)\n",
        "        if epoch == 0 or (epoch + 1) % 2 == 0:\n",
        "            print(f\"  Epoch {epoch+1}: Val Acc = {val_acc:.4f}\")\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "# Usage example:\n",
        "# Remplacer votre appel par:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyvjgo6gajdQ",
        "outputId": "333c463d-4010-477b-c696-a4ee1c4e49ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de Pruning avec Réduction Effective des Paramètres\n",
            "============================================================\n",
            "Modèle original: 0.7409 accuracy, 120,858 paramètres\n",
            "\n",
            "Test avec keep_ratio = 0.8 (80% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1428\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 88,081\n",
            "Réduction RÉELLE: 27.1%\n",
            "Accuracy avant fine-tuning: 0.2663\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6811\n",
            "  Epoch 2: Val Acc = 0.7152\n",
            "  Epoch 4: Val Acc = 0.7196\n",
            "Accuracy finale: 0.7319\n",
            "Rétention accuracy: 98.8%\n",
            "Ratio de compression: 1.4x\n",
            "\n",
            "Test avec keep_ratio = 0.6 (60% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1083\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 64,114\n",
            "Réduction RÉELLE: 47.0%\n",
            "Accuracy avant fine-tuning: 0.0688\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6416\n",
            "  Epoch 2: Val Acc = 0.6711\n",
            "  Epoch 4: Val Acc = 0.6932\n",
            "Accuracy finale: 0.6965\n",
            "Rétention accuracy: 94.0%\n",
            "Ratio de compression: 1.9x\n",
            "\n",
            "Test avec keep_ratio = 0.4 (40% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 690\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 40,468\n",
            "Réduction RÉELLE: 66.5%\n",
            "Accuracy avant fine-tuning: 0.0969\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.5665\n",
            "  Epoch 2: Val Acc = 0.6167\n",
            "  Epoch 4: Val Acc = 0.6462\n",
            "Accuracy finale: 0.6453\n",
            "Rétention accuracy: 87.1%\n",
            "Ratio de compression: 3.0x\n",
            "\n",
            "Test avec keep_ratio = 0.2 (20% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 345\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 23,176\n",
            "Réduction RÉELLE: 80.8%\n",
            "Accuracy avant fine-tuning: 0.0983\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.4368\n",
            "  Epoch 2: Val Acc = 0.4989\n",
            "  Epoch 4: Val Acc = 0.5180\n",
            "Accuracy finale: 0.5358\n",
            "Rétention accuracy: 72.3%\n",
            "Ratio de compression: 5.2x\n",
            "\n",
            "RÉSUMÉ DES RÉSULTATS\n",
            "========================================\n",
            "Keep 80%: 27.1% réduction, 98.8% accuracy, 1.4x compression\n",
            "Keep 60%: 47.0% réduction, 94.0% accuracy, 1.9x compression\n",
            "Keep 40%: 66.5% réduction, 87.1% accuracy, 3.0x compression\n",
            "Keep 20%: 80.8% réduction, 72.3% accuracy, 5.2x compression\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'keep_ratio': 0.8,\n",
              "  'actual_reduction': 27.120256830329808,\n",
              "  'final_accuracy': 0.7319,\n",
              "  'accuracy_retention': 98.78526116884869,\n",
              "  'compression_ratio': 1.372123386428401,\n",
              "  'pruned_params': 88081},\n",
              " {'keep_ratio': 0.6,\n",
              "  'actual_reduction': 46.950967250823275,\n",
              "  'final_accuracy': 0.6965,\n",
              "  'accuracy_retention': 94.00728843298691,\n",
              "  'compression_ratio': 1.8850485073462895,\n",
              "  'pruned_params': 64114},\n",
              " {'keep_ratio': 0.4,\n",
              "  'actual_reduction': 66.51607671813203,\n",
              "  'final_accuracy': 0.6453,\n",
              "  'accuracy_retention': 87.09677419354838,\n",
              "  'compression_ratio': 2.98650785806069,\n",
              "  'pruned_params': 40468},\n",
              " {'keep_ratio': 0.2,\n",
              "  'actual_reduction': 80.82377666352248,\n",
              "  'final_accuracy': 0.5358,\n",
              "  'accuracy_retention': 72.31745174787422,\n",
              "  'compression_ratio': 5.214791163272351,\n",
              "  'pruned_params': 23176}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_effective_pruning(model_test,filter_ranking,trn_dl, val_dl, loss_fn) #gardant 50 plus régulière"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70nA-O9NAxG2",
        "outputId": "b92f723c-0bcf-4d11-fb11-2d883858c39d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test de Pruning avec Réduction Effective des Paramètres\n",
            "============================================================\n",
            "Modèle original: 0.7409 accuracy, 120,858 paramètres\n",
            "\n",
            "Test avec keep_ratio = 0.8 (80% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1428\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 88,081\n",
            "Réduction RÉELLE: 27.1%\n",
            "Accuracy avant fine-tuning: 0.1443\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6796\n",
            "  Epoch 2: Val Acc = 0.6841\n",
            "  Epoch 4: Val Acc = 0.7129\n",
            "Accuracy finale: 0.7271\n",
            "Rétention accuracy: 98.1%\n",
            "Ratio de compression: 1.4x\n",
            "\n",
            "Test avec keep_ratio = 0.6 (60% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 1083\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 64,114\n",
            "Réduction RÉELLE: 47.0%\n",
            "Accuracy avant fine-tuning: 0.0966\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.6367\n",
            "  Epoch 2: Val Acc = 0.6618\n",
            "  Epoch 4: Val Acc = 0.6960\n",
            "Accuracy finale: 0.6973\n",
            "Rétention accuracy: 94.1%\n",
            "Ratio de compression: 1.9x\n",
            "\n",
            "Test avec keep_ratio = 0.4 (40% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 690\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 40,468\n",
            "Réduction RÉELLE: 66.5%\n",
            "Accuracy avant fine-tuning: 0.1115\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.5514\n",
            "  Epoch 2: Val Acc = 0.6090\n",
            "  Epoch 4: Val Acc = 0.6388\n",
            "Accuracy finale: 0.6517\n",
            "Rétention accuracy: 88.0%\n",
            "Ratio de compression: 3.0x\n",
            "\n",
            "Test avec keep_ratio = 0.2 (20% des canaux)\n",
            "----------------------------------------\n",
            "Filtres sélectionnés: 345\n",
            "Paramètres avant: 120,858\n",
            "Paramètres après: 23,176\n",
            "Réduction RÉELLE: 80.8%\n",
            "Accuracy avant fine-tuning: 0.1232\n",
            "Fine-tuning...\n",
            "  Epoch 1: Val Acc = 0.4249\n",
            "  Epoch 2: Val Acc = 0.4735\n",
            "  Epoch 4: Val Acc = 0.5115\n",
            "Accuracy finale: 0.5286\n",
            "Rétention accuracy: 71.3%\n",
            "Ratio de compression: 5.2x\n",
            "\n",
            "RÉSUMÉ DES RÉSULTATS\n",
            "========================================\n",
            "Keep 80%: 27.1% réduction, 98.1% accuracy, 1.4x compression\n",
            "Keep 60%: 47.0% réduction, 94.1% accuracy, 1.9x compression\n",
            "Keep 40%: 66.5% réduction, 88.0% accuracy, 3.0x compression\n",
            "Keep 20%: 80.8% réduction, 71.3% accuracy, 5.2x compression\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'keep_ratio': 0.8,\n",
              "  'actual_reduction': 27.120256830329808,\n",
              "  'final_accuracy': 0.7271,\n",
              "  'accuracy_retention': 98.13740045890134,\n",
              "  'compression_ratio': 1.372123386428401,\n",
              "  'pruned_params': 88081},\n",
              " {'keep_ratio': 0.6,\n",
              "  'actual_reduction': 46.950967250823275,\n",
              "  'final_accuracy': 0.6973,\n",
              "  'accuracy_retention': 94.11526521797813,\n",
              "  'compression_ratio': 1.8850485073462895,\n",
              "  'pruned_params': 64114},\n",
              " {'keep_ratio': 0.4,\n",
              "  'actual_reduction': 66.51607671813203,\n",
              "  'final_accuracy': 0.6517,\n",
              "  'accuracy_retention': 87.9605884734782,\n",
              "  'compression_ratio': 2.98650785806069,\n",
              "  'pruned_params': 40468},\n",
              " {'keep_ratio': 0.2,\n",
              "  'actual_reduction': 80.82377666352248,\n",
              "  'final_accuracy': 0.5286,\n",
              "  'accuracy_retention': 71.34566068295317,\n",
              "  'compression_ratio': 5.214791163272351,\n",
              "  'pruned_params': 23176}]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_effective_pruning(model_test,filter_ranking,trn_dl, val_dl, loss_fn) #gardant 20 plus régulière"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
